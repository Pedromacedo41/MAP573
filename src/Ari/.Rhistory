order2 = dd[order(-dd2$spec),]
ttop2 = head(order2, 9)
ttime = 1/ttop2$f
print(cbind(ttop2, ttime))
})
getPage<-function() {
return(includeHTML("./../src/Ari/TSMarkdown.html"))
}
output$inc<-renderUI({getPage()})
}
shinyApp(ui = ui, server = server)
TST= fread("./../Data/TST.csv", sep=",")
TS= fread("./../Data/TS.csv", sep=",")
load_table= data.frame(TS)
TST= fread("./../Data/TST.csv", sep=",")
temp_table= data.frame(TST)
xd= fread("./../Data/Load_prediction.csv", sep=",")
xd= data.frame(xd)
knitr::opts_knit$set(root.dir = getwd())
knitr::opts_chunk$set(echo = T)
library(grid)
library(gridExtra)
library(rmarkdown)
TS <- read.csv("./../../Data/Complete_TS.csv")
TST <- read.csv("./../..//Data/TST.csv")
row.names(TST) <- TST$datetime
TST = subset(TST, select = -c(X, datetime))
row.names(TS) <- TS$datetime
TS = subset(TS, select = -c(X, datetime, V10))  #Remove Z10 which is V11 because it behaves strangely
TS_sum <- rowSums(TS[(1:dim(TST)[1]), ])
TST_mean <- rowMeans(TST[(1:dim(TST)[1]), ])
data <- as.data.frame(cbind(TST_mean, TS_sum))
plot(TST_mean, TS_sum/1000000,
main = "Relationship between energy load and temperature",
xlab = "Temperature [F]",
ylab = "Load [GW]",
cex = 0.1,
panel.first = grid(nx = NULL, ny = NULL, col = "red", lty = "dotted"))
library(zoo)
library(xts)
library(ggplot2)
times <- as.POSIXct(row.names(data), format = "%Y-%m-%d %H:%M:")
timesNAomit <- na.omit(times) #for NA values we omit
load_zoo_zones <- zoo( # all zones
x         = TS,
order.by  = timesNAomit,
frequency = 24
)
load_zoo <- zoo( #sum of the zones
x         = data$TS_sum,
order.by  = timesNAomit,
frequency = 24
)
temperature_zoo <- zoo(
x         = data$TST_mean,
order.by  = timesNAomit,
frequency = 24
)
data_zoo <- cbind(load_zoo, temperature_zoo)
load_ts <- ts(TS_sum, start = as.numeric(times[1]), frequency = 24)
years <- c("2004", "2005", "2006", "2007", "2008")
year = years[1]
temp_start <-  paste(c(year, "-01-", "01 01:00:00"), collapse = "")
temp_end <-  paste(c(year, "-12-", "31 24:00:00"), collapse = "")
as.POSIXct(temp_start)
ystart <- which(as.POSIXct(temp_start) == index(load_zoo_zones))
yend <- which(as.POSIXct(temp_end) == index(load_zoo_zones))-1 #-1 til þess að losna við firsta value á næsta ári
year_zoo_zones <- load_zoo_zones[ystart:yend]
TS_year <- as.matrix(coredata(year_zoo_zones[1:dim(year_zoo_zones)[1],1:dim(year_zoo_zones)[2]]))
par(mfrow=c(1,2))
image(x = 1:dim(year_zoo_zones)[1],
y = 1:dim(year_zoo_zones)[2],
z = TS_year,
xlab = "The first year [hours]", ylab = "Zones", main = "'Heatmap' of zones for the first year")
ts_st <- matrix(data=NA,nrow=20,ncol=1)
for (i in 1:dim(TS_year)[2]){
temp <- sd(TS_year[,i])
ts_st[i] <- temp
}
for (i in 1:dim(TS_year)[2]){ #skipta um zone
for (j in 1:dim(TS_year)[1]){ #dagar í einu zoni
TS_year[j,i] <- TS_year[j,i]/ts_st[i]
}
}
image(x = 1:dim(year_zoo_zones)[1],
y = 1:dim(year_zoo_zones)[2],
z = TS_year,
ylab = "zones",
xlab = "Hours",
main = "Standardized 'Heatmap' of zones for the first year")
#sum everything and compare years
smoothpars <- c(0,24,24*7, 24*30) #0 fyrir klukkustund, 24 fyrir dag, 24*7 fyrir vikur
size_year = c(0,0,0,0,0)
for (i in (1:(length(years)))){
year = years[i]
temp_start <-  paste(c(year, "-01-", "01 01:00:00"), collapse = "")
temp_end <-  paste(c(year, "-12-", "31 24:00:00"), collapse = "")
if (i == 5){yend = length(load_zoo)} else {yend <- which(as.POSIXct(temp_end) == index(load_zoo))-1} #-1 til þess að losna við firsta value á næsta ári
ystart <- which(as.POSIXct(temp_start) == index(load_zoo))
size_year[i] <- length(load_zoo[ystart:yend])
}
counter <- 1
labels <- c("Hours", "Days", "Weeks", "Months")
titles <- c("At each hour", "Average load over the day", "Average load over the week", "Average load over the months")
for (s in smoothpars){
year_zoo <- matrix(data = NA, nrow = 5, ncol = max(size_year))
for (i in (1:(length(years)))){
year = years[i]
temp_start <-  paste(c(year, "-01-", "01 01:00:00"), collapse = "")
temp_end <-  paste(c(year, "-12-", "31 24:00:00"), collapse = "")
as.POSIXct(temp_start)
if (i == 5){yend = length(load_zoo)} else {yend <- (which(as.POSIXct(temp_end) == index(load_zoo))-1)} #-1 til þess að losna við firsta value á næsta ári
ystart <- which(as.POSIXct(temp_start) == index(load_zoo))
temp <-  coredata(load_zoo[ystart:yend])
year_zoo[i,1:length(temp)] <- temp
}
year_zoo <- as.matrix(coredata(year_zoo))
if (s > 0){
##Average accross 24 horys
year_zoo_smooth <- matrix(data = NA, nrow = 5, ncol = ceiling(max(size_year)/s))
idx1 <- 1
idx2 <- 1
while (idx2 <= dim(year_zoo)[2]-(s-1)){
temp <- year_zoo[,(idx2:(idx2+(s-1)))]
temp <- rowMeans(temp)
year_zoo_smooth[,idx1] <- coredata(temp)
idx2 <- idx2+s
idx1 <- idx1+1
}
year_zoo <- year_zoo_smooth
}
p1 <- image(x = 1:dim(year_zoo)[1],
y = 1:dim(year_zoo)[2],
z = year_zoo,
xlab = "The first year [hours]", ylab = "Zones", main = "'Heatmap' of zones for the first year")
year_zoo <- t(year_zoo)
colnames(year_zoo) <- c("year1", "year2", "year3", "year4", "year5")
year_zoo <- as.data.frame(year_zoo)
p2 <- ggplot(data=year_zoo, aes(x=index(year_zoo))) +
geom_line(aes(y=year1, color = "2004")) +
geom_line(aes(y=year2, color = "2005")) +
geom_line(aes(y=year3, color = "2006")) +
geom_line(aes(y=year4, color = "2007")) +
geom_line(aes(y=year5, color = "2008")) +
scale_colour_manual("",
breaks = c("2004", "2005", "2006", "2007", "2008"),
values = c("2004"="yellow", "2005"="red", "2006"="green", "2007"="blue", "2008"= "black"))+
xlab(labels[counter]) +
ylab('Load')+
labs(title = "Load over the time", subtitle = titles[counter])+
scale_fill_discrete(name="Year")
p1
print(p2)
counter <- counter + 1
}
load.means.diff <- diff(TS_sum)/1000000
d <- coredata(load.means.diff)
d <- as.data.frame(cbind(1:length(d), d))
colnames(d) <- c("Idx", "Difference")
p1 <- ggplot(d,aes(Idx, Difference))+geom_line()+
theme_bw()+
labs(title = "Difference in load between time steps", xlav="Time", ylab="Difference")
d <- as.matrix(load.means.diff)
bw <- 2 * IQR(d) / length(d)^(1/3) #Freedman-Diaconis rule
d <- as.data.frame(d)
colnames(d) <- c("Difference")
p2 <- ggplot(d, aes(x = Difference)) +
labs(title= "Histogram of the difference between each time step ",
y="Count",
x = "Difference [GW]")+
theme_bw()+
geom_histogram(binwidth = bw)
mean(as.matrix(d))
sd(as.matrix(d))
d <- coredata(TS_sum)/1000000
bw <- 2 * IQR(d) / length(d)^(1/3) #Freedman-Diaconis rule
p3 <- ggplot(, mapping = aes(x = d)) +
labs(title= "Histogram of load",
y="Count",
x = "Load [GW]")+
theme_bw()+
geom_histogram(binwidth = bw)
grid.arrange(p3, p1, p2, nrow = 3)
p1 <- ggplot(data_zoo, aes(timesNAomit)) +
geom_line(aes(y = load_zoo)) +
labs(title= "Correlation of load and temperature (no units)",
y="Load", x = "Year")
p2 <- ggplot(data_zoo, aes(timesNAomit))+
geom_line(aes(y = temperature_zoo))+
labs(y="Temperature", x = "Year")
grid.arrange(p1, p2, nrow = 2)
library(forecast)
#gglagplot(TS_sum, do.lines = FALSE, set.lags = 1:30, cex=0.1, colour = FALSE)
library(forecast)
p1 <- ggAcf(TS_sum, lag.max = 48) + labs(title="Autocorrelations for lags 48 hours")+theme_bw()
p2 <- ggAcf(TS_sum, lag.max = 24*35) + labs(title="Autocorrelations for lags 840 hours (35 days)")+theme_bw()
grid.arrange(p1, p2, nrow = 2)
p1 <- ggAcf(TS_sum, type = "partial")+theme_bw()+labs(title="PACF for 24 hours")
p2 <- ggAcf(TS_sum, type = "partial", lag.max = 24*7)+theme_bw()+labs(title="PACF for a week")
p3 <- ggAcf(TS_sum, type = "partial", lag.max = 24*7*4)+theme_bw()+labs(title="PACF for a month")
grid.arrange(p1, p2, p3, ncol = 2, layout_matrix = rbind(c(1,2), c(3,3)))
#Which PACF are the greatest
temp <- ggAcf(TS_sum, type = "partial", plot=F, lag.max = 24*7*4)
temp <- as.data.frame(temp$acf)
temp$idx  <- 1:nrow(temp)
colnames(temp) <- c("PACF", "IDX")
signs <- temp[c("IDX", "PACF")]
nosigns <- abs(signs)
maxPACF <- order(nosigns$PACF, decreasing=T)
maxPACF[1:15]
results <- signs[maxPACF,]
#Now check for 4 years, years seem to be less autocorrelated than within year
temp <- ggAcf(TS_sum, type = "partial", plot=F, lag.max = 24*7*4*12*2)
temp <- as.data.frame(temp$acf)
temp$idx  <- 1:nrow(temp)
colnames(temp) <- c("PACF", "IDX")
signs <- temp[c("IDX", "PACF")]
nosigns <- abs(signs)
maxPACF <- order(nosigns$PACF, decreasing=T)
maxPACF[1:15]
results <- signs[maxPACF,]
p1 <- autoplot(ts(load_ts[1:24]), main="24 hours from baseline")+xlab("Time")+ylab("Load")
p2 <- autoplot(load_zoo[1:24*7], main="week from baseline")+xlab("Time")+ylab("Load")
p3 <- autoplot(load_zoo[1:24*7*4], main="month from baseline")+xlab("Time")+ylab("Load")
grid.arrange(p1, p2, p3,  ncol = 2, layout_matrix = rbind(c(1,2), c(3,3)))
N_obs <- sum(size_year)
D <- matrix(data=NA,nrow=N_obs,ncol=12)
colnames(D) <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
years = c("2004-", "2005-", "2006-", "2007-", "2008-", "2009-") #2009 ekki í datasetti
months = c("01-", "02-", "03-", "04-", "05-", "06-", "07-", "08-", "09-", "10-", "11-", "12-", "01-")
MaxIndex <- 1
for (y in 1:5){
year <- years[y]
for (m in 1:12){
MaxIndex_month <- 1
month <- months[m]
nextmonth <- months[m+1]
if (m == 12)
{
nextyear <- years[y+1]
temp_start <-  paste(c(year, month, "01"), collapse = "")
temp_end  <-  paste(c(nextyear, nextmonth, "01"), collapse = "")
}
else{
temp_start <-  paste(c(year, month, "01"), collapse = "")
temp_end  <-  paste(c(year, nextmonth, "01"), collapse = "")
}
sDay <- temp_start
eDay <-temp_end
monthData <- coredata(window(load_zoo, start = as.POSIXct(sDay), end = as.POSIXct(eDay)))
lengthMonth <- length(monthData)
D[MaxIndex:(MaxIndex+lengthMonth-1),m] <- monthData[1:lengthMonth]
if (lengthMonth > MaxIndex_month) {MaxIndex_month <- lengthMonth}
}
MaxIndex <- MaxIndex_month + MaxIndex
}
#Now boxplot with D
boxplot(D/1000000,
main = "Total energy demand per hour",
na.action = NULL,
xlab = "Months",
ylab = "Load (GW)",
col = "orange",
border = "black")
N <- ceiling(length(load_zoo)/24)
D <- matrix(data = NA, ncol = 24, nrow = N)
colnames(D) <- as.character(1:24)
counter <- 1
for (i in 1:(N)){
for (j in 1:24){
D[i,j] <- coredata(load_zoo[counter])
counter = counter + 1
}
}
#Now boxplot with D
boxplot(D/1000000,
main = "Total energy demand per hour",
na.action = NULL,
xlab = "Hours",
ylab = "Load (GW)",
col = "orange",
border = "black")
N_obs <- max(size_year)+1
D <- matrix(data=NA,nrow=N_obs,ncol=5)
colnames(D) <- c("2004", "2005", "2006", "2007", "2008")
years <-  c("2004-", "2005-", "2006-", "2007-", "2008-", "2009-")
for (y in 1:5){
year <- years[y]
sDay <-  paste(c(year, "01-", "01"), collapse = "")
eDay  <-  paste(c(years[y+1], "01-", "01"), collapse = "")
yearData <- coredata(window(load_zoo, start = as.POSIXct(sDay), end = as.POSIXct(eDay)))
lengthYear <- length(yearData)
D[(1:lengthYear),y] <- yearData[1:lengthYear]
}
#Now boxplot with D
boxplot(D/1000000,
main = "Total energy demand per hour",
na.action = NULL,
xlab = "Months",
ylab = "Load (GW)",
col = "orange",
border = "black")
Transformation <- function(TS, Lambda)
{
w <- vector()
for(i in 1:length(TS)){
if (Lambda == 0){
w[i] <- log(TS[i])
}
else{
w[i] <- (((TS[i])^Lambda)-1)/Lambda
}
}
return(w)
}
BackTransform <- function(TS, Lambda){
w <- vector()
for(i in 1:length(TS)){
if (Lambda == 0){
w[i] <- exp(TS[i])
}
else{
w[i] <- (Lambda*TS[i]+1)^(1/Lambda)
}
}
return(w)
}
Lambda <- c(-1, 0, 1, 2)*2
for (i in Lambda){
TS_sum_transformed <- Transformation(TS_sum, i)
plot.zoo(TS_sum_transformed)
}
Lambda <- BoxCox.lambda(TS_sum)
TS_sum_transformed <- Transformation(TS_sum, Lambda)
plot.zoo(TS_sum_transformed)
TS_sum_backtransformed <- BackTransform(TS_sum_transformed, Lambda)
plot.zoo(TS_sum_backtransformed)
N_obs <- max(size_year)+1
D <- matrix(data=NA,nrow=N_obs,ncol=5)
colnames(D) <- c("2004", "2005", "2006", "2007", "2008")
years <-  c("2004-", "2005-", "2006-", "2007-", "2008-", "2009-")
for (y in 1:5){
year <- years[y]
sDay <-  paste(c(year, "01-", "01"), collapse = "")
eDay  <-  paste(c(years[y+1], "01-", "01"), collapse = "")
yearData <- coredata(window(load_zoo, start = as.POSIXct(sDay), end = as.POSIXct(eDay)))
lengthYear <- length(yearData)
D[(1:lengthYear),y] <- yearData[1:lengthYear]
}
#Now boxplot with D
boxplot(D/1000000,
main = "Total energy demand per hour",
na.action = NULL,
xlab = "Years",
ylab = "Load (GW)",
col = "orange",
border = "black")
library(fields)
library(gplots)
dataLoad <- function(){
TS <- read.csv("./../../Data/Complete_TS.csv")
TST <- read.csv("./../../Data/TST.csv")
row.names(TST) <- TST$datetime
TST = subset(TST, select = -c(X, datetime))
row.names(TS) <- TS$datetime
TS = subset(TS, select = -c(X, datetime, V10))  #Remove Z10 which is V11 because it behaves strangely
colnames(TS) <- c("L1", "L2", "L3", "L4", "L5", "L6", "L7", "L8", "L10", "L11", "L12", "L13", "L14", "L15", "L16", "L17", "L18", "L19", "L20")
colnames(TST) <- c("T1", "T2", "T3", "T4", "T5", "T6", "T7", "T8", "T9", "T10", "T11")
return(list(TS, TST))
}
correlation <- function(TS, TST){
D <- matrix(data=NA, nrow = dim(TS)[2], ncol = dim(TST)[2])
for(i in 1:dim(TS)[2]){ #The rows are i
for(j in 1:dim(TST)[2]){ #The columns are j
x <- TS[,i]
y <- TST[,j]
#temp <-  cor(x,y)
D[i,j] <-cor(x,y)#temp$distance
}
}
return(D)
}
#temperature data
temp <- dataLoad()
TS <- as.matrix(temp[[1]])
TST <- as.matrix(temp[[2]])
TST <- TST[1:39412,] #remove last na values in TST
D <- matrix(data=NA, nrow = dim(TST)[2], ncol = dim(TST)[2])
for (i in 1:(dim(TST)[2])){
for (j in 1:(dim(TST)[2])){
temp1 <- TST[,i]
temp2 <- TST[,j]
D[i,j] <- cor(temp1, temp2)
}
}
par(mfrow=c(1,2))
colors <- colorpanel(100, "white", "grey", "black")
N<- length(colors)
breaks <- (seq(0, max(D),  length.out= N+1))
image.plot(x=1:dim(D)[1], y=1:dim(D)[2], ((D)), col = colors, breaks=breaks,
xlab="Zones", ylab="Zones",
main = "Correlation of temperature stations")
#load data
temp <- dataLoad()
TS <- as.matrix(temp[[1]])
TST <- as.matrix(temp[[2]])
TS <- TS[1:39575,] #remove last na values in TST
D <- matrix(data=NA, nrow = dim(TS)[2], ncol = dim(TS)[2])
for (i in 1:(dim(TS)[2])){
for (j in 1:(dim(TS)[2])){
temp1 <- TS[,i]
temp2 <- TS[,j]
D[i,j] <- cor(temp1, temp2)
}
}
colors <- colorpanel(100, "white","grey", "black")
N<- length(colors)
breaks <- (seq(0, max(D),  length.out= N+1))
image.plot(x=1:dim(D)[1], y=1:dim(D)[2], ((D)), col = colors, breaks=breaks,
xlab="Zones", ylab="Zones",
main = "Correlation of load stations")
setwd("~/Documents/Skóli/École Polytechnique/Data Analysis and Unsupervised Learning /Project/MAP573/src/Ari")
library(fields)
library(gplots)
dataLoad <- function(){
TS <- read.csv("./../../Data/Complete_TS.csv")
TST <- read.csv("./../../Data/TST.csv")
row.names(TST) <- TST$datetime
TST = subset(TST, select = -c(X, datetime))
row.names(TS) <- TS$datetime
TS = subset(TS, select = -c(X, datetime, V10))  #Remove Z10 which is V11 because it behaves strangely
colnames(TS) <- c("L1", "L2", "L3", "L4", "L5", "L6", "L7", "L8", "L10", "L11", "L12", "L13", "L14", "L15", "L16", "L17", "L18", "L19", "L20")
colnames(TST) <- c("T1", "T2", "T3", "T4", "T5", "T6", "T7", "T8", "T9", "T10", "T11")
return(list(TS, TST))
}
correlation <- function(TS, TST){
D <- matrix(data=NA, nrow = dim(TS)[2], ncol = dim(TST)[2])
for(i in 1:dim(TS)[2]){ #The rows are i
for(j in 1:dim(TST)[2]){ #The columns are j
x <- TS[,i]
y <- TST[,j]
#temp <-  cor(x,y)
D[i,j] <-cor(x,y)#temp$distance
}
}
return(D)
}
#temperature data
temp <- dataLoad()
TS <- as.matrix(temp[[1]])
TST <- as.matrix(temp[[2]])
TST <- TST[1:39412,] #remove last na values in TST
D <- matrix(data=NA, nrow = dim(TST)[2], ncol = dim(TST)[2])
for (i in 1:(dim(TST)[2])){
for (j in 1:(dim(TST)[2])){
temp1 <- TST[,i]
temp2 <- TST[,j]
D[i,j] <- cor(temp1, temp2)
}
}
par(mfrow=c(1,2))
colors <- colorpanel(100, "white", "grey", "black")
N<- length(colors)
breaks <- (seq(0, max(D),  length.out= N+1))
image.plot(x=1:dim(D)[1], y=1:dim(D)[2], ((D)), col = colors, breaks=breaks,
xlab="Zones", ylab="Zones",
main = "Correlation of temperature stations")
#load data
temp <- dataLoad()
TS <- as.matrix(temp[[1]])
TST <- as.matrix(temp[[2]])
TS <- TS[1:39575,] #remove last na values in TST
D <- matrix(data=NA, nrow = dim(TS)[2], ncol = dim(TS)[2])
for (i in 1:(dim(TS)[2])){
for (j in 1:(dim(TS)[2])){
temp1 <- TS[,i]
temp2 <- TS[,j]
D[i,j] <- cor(temp1, temp2)
}
}
colors <- colorpanel(100, "white","grey", "black")
N<- length(colors)
breaks <- (seq(0, max(D),  length.out= N+1))
image.plot(x=1:dim(D)[1], y=1:dim(D)[2], ((D)), col = colors, breaks=breaks,
xlab="Zones", ylab="Zones",
main = "Correlation of load stations")
TS <- read.csv("./../../Data/Complete_TS.csv")
TST <- read.csv("./../../Data/TST.csv")
TST = subset(TST, select = -c(X, datetime))
TS = subset(TS, select = -c(X, datetime, V10))  #Remove Z10 which is V11 because it behaves strangely
TS_sum <- rowSums(TS[(1:dim(TS)[1]), ])
TST_mean <- rowMeans(TST[(1:dim(TS)[1]), ])
n <- 15000
TST_mean <- as.matrix(TST_mean[1:n])
TS_sum <- as.matrix(TS_sum[1:n])
counter <- 1
Imax <- 24*2
C <- matrix(data=NA, nrow = Imax+1, ncol = 2)
for (i in (0:(length(C)-1))){
TS_sum_lagged <- as.matrix(TS_sum[(i+1):length(TS_sum)])
TST_mean_lagged <- as.matrix(TST_mean[1:(length(TST_mean)-i)])
C[counter,1] <- i
C[counter,2] <- cor(TST_mean_lagged, TS_sum_lagged)
counter = counter + 1
}
C <- as.data.frame(C)
colnames(C) <- c("Lag", "Correlation")
library(ggplot2)
ggplot(C, aes(x=Lag, y=Correlation)) +
theme_bw() +
geom_point() +
labs(title="Correlation between temperature and load")
