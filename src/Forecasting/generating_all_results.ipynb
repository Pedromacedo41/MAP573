{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for Report and Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script runs through each of the models discussed in the results and calculates. The purpose of this script is not to be optimal in terms of efficiency but to calculate all the results sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import math\n",
    "from keras.layers import LSTM, Bidirectional, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from keras import callbacks\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2004</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>16853.0</td>\n",
       "      <td>126259.0</td>\n",
       "      <td>136233.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>6829.0</td>\n",
       "      <td>133088.0</td>\n",
       "      <td>136233.0</td>\n",
       "      <td>3124.0</td>\n",
       "      <td>75243.0</td>\n",
       "      <td>23339.0</td>\n",
       "      <td>90700.0</td>\n",
       "      <td>118378.0</td>\n",
       "      <td>20673.0</td>\n",
       "      <td>21791.0</td>\n",
       "      <td>65970.0</td>\n",
       "      <td>28752.0</td>\n",
       "      <td>30645.0</td>\n",
       "      <td>200946.0</td>\n",
       "      <td>82298.0</td>\n",
       "      <td>79830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16450.0</td>\n",
       "      <td>123313.0</td>\n",
       "      <td>133055.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>6596.0</td>\n",
       "      <td>129909.0</td>\n",
       "      <td>133055.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>67368.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>86699.0</td>\n",
       "      <td>112480.0</td>\n",
       "      <td>19666.0</td>\n",
       "      <td>21400.0</td>\n",
       "      <td>64600.0</td>\n",
       "      <td>27851.0</td>\n",
       "      <td>30461.0</td>\n",
       "      <td>195835.0</td>\n",
       "      <td>79827.0</td>\n",
       "      <td>77429.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1         2         3      4       5         6         7   \\\n",
       "2004 1 1 1  16853.0  126259.0  136233.0  484.0  6829.0  133088.0  136233.0   \n",
       "         2  16450.0  123313.0  133055.0  457.0  6596.0  129909.0  133055.0   \n",
       "\n",
       "                8        9        10       11        12       13       14  \\\n",
       "2004 1 1 1  3124.0  75243.0  23339.0  90700.0  118378.0  20673.0  21791.0   \n",
       "         2  2956.0  67368.0  22100.0  86699.0  112480.0  19666.0  21400.0   \n",
       "\n",
       "                 15       16       17        18       19       20  \n",
       "2004 1 1 1  65970.0  28752.0  30645.0  200946.0  82298.0  79830.0  \n",
       "         2  64600.0  27851.0  30461.0  195835.0  79827.0  77429.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv which is already in a convenient format and make some more changes, final result is shown below\n",
    "PATH = r\"../../Data/completeLoad.csv\"\n",
    "df = pd.read_csv(PATH)\n",
    "temp = df.set_index(['zone_id', 'year', 'month', 'day'])\n",
    "\n",
    "# change column names to integer hours\n",
    "colname_to_int = {}\n",
    "for i in list(temp.columns):\n",
    "    colname_to_int[i] = int(i[1:])\n",
    "\n",
    "# reshape the array to manageable format, result is shown below\n",
    "temp = temp.rename(columns=colname_to_int)\n",
    "temp = temp.stack()\n",
    "temp = temp.unstack(level=0)\n",
    "temp.columns.names = [None]\n",
    "temp.index.names = [None, None, None, None]\n",
    "df_zone = temp\n",
    "temp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples training set: 31660\n",
      "Number of samples test set: 7916\n"
     ]
    }
   ],
   "source": [
    "# use data for zone 1.\n",
    "data = df_zone[1].values.reshape(-1, 1)\n",
    "\n",
    "# normalize data with min max normalization.\n",
    "normalizer = MinMaxScaler(feature_range = (0, 1))\n",
    "dataset = normalizer.fit_transform(data)\n",
    "\n",
    "# Using 80% of data for training, 20% for validation.\n",
    "TRAINING_PERCENT = 0.80\n",
    "\n",
    "train_size = int(len(dataset) * TRAINING_PERCENT)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(\"Number of samples training set: \" + str((len(train))))\n",
    "print(\"Number of samples test set: \" + str((len(test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Naive -1 hour) Training data error: 1443.82 MSE\n",
      "(Naive -1 hour) Test data error: 1499.18 MSE\n",
      "(Naive -1 day) Training data error: 3021.37 MSE\n",
      "(Naive -1 day) Test data error: 3289.53 MSE\n",
      "(Naive -1 week) Training data error: 4569.05 MSE\n",
      "(Naive -1 week) Test data error: 5267.30 MSE\n"
     ]
    }
   ],
   "source": [
    "# function that computes the mean squared error from predi\n",
    "def get_naive_week_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24*7], Y[0:-24*7])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_day_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24], Y[0:-24])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_hour_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0, :].reshape(1, -1), Y[0:-1])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "mse_train_naive_hour, train_predict_naive_hour = get_naive_hour_predict_and_score_multi(0, train_Y)\n",
    "mse_test_naive_hour, test_predict_naive_hour = get_naive_hour_predict_and_score_multi(0, test_Y)\n",
    "mse_train_naive_day, train_predict_naive_day = get_naive_day_predict_and_score_multi(0, train_Y)\n",
    "mse_test_naive_day, test_predict_naive_day = get_naive_day_predict_and_score_multi(0, test_Y)\n",
    "mse_train_naive_week, train_predict_naive_week = get_naive_week_predict_and_score_multi(0, train_Y)\n",
    "mse_test_naive_week, test_predict_naive_week = get_naive_week_predict_and_score_multi(0, test_Y)\n",
    "\n",
    "print(\"(Naive -1 hour) Training data error: %.2f MSE\" % mse_train_naive_hour)\n",
    "print(\"(Naive -1 hour) Test data error: %.2f MSE\" % mse_test_naive_hour)\n",
    "print(\"(Naive -1 day) Training data error: %.2f MSE\" % mse_train_naive_day)\n",
    "print(\"(Naive -1 day) Test data error: %.2f MSE\" % mse_test_naive_day)\n",
    "print(\"(Naive -1 week) Training data error: %.2f MSE\" % mse_train_naive_week)\n",
    "print(\"(Naive -1 week) Test data error: %.2f MSE\" % mse_test_naive_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Naive -1 hour) Training data error: 33.63 MSE\n",
      "(Naive -1 hour) Test data error: 34.12 MSE\n",
      "(Naive -1 day) Training data error: 45.77 MSE\n",
      "(Naive -1 day) Test data error: 48.00 MSE\n",
      "(Naive -1 week) Training data error: 57.22 MSE\n",
      "(Naive -1 week) Test data error: 61.12 MSE\n"
     ]
    }
   ],
   "source": [
    "def get_naive_week_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24*7], Y[0:-24*7])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_day_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24], Y[0:-24])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_hour_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0, :].reshape(1, -1), Y[0:-1])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "mse_train_naive_hour, train_predict_naive_hour = get_naive_hour_predict_and_score_multi(0, train_Y)\n",
    "mse_test_naive_hour, test_predict_naive_hour = get_naive_hour_predict_and_score_multi(0, test_Y)\n",
    "mse_train_naive_day, train_predict_naive_day = get_naive_day_predict_and_score_multi(0, train_Y)\n",
    "mse_test_naive_day, test_predict_naive_day = get_naive_day_predict_and_score_multi(0, test_Y)\n",
    "mse_train_naive_week, train_predict_naive_week = get_naive_week_predict_and_score_multi(0, train_Y)\n",
    "mse_test_naive_week, test_predict_naive_week = get_naive_week_predict_and_score_multi(0, test_Y)\n",
    "\n",
    "print(\"(Naive -1 hour) Training data error: %.2f MSE\" % mse_train_naive_hour)\n",
    "print(\"(Naive -1 hour) Test data error: %.2f MSE\" % mse_test_naive_hour)\n",
    "print(\"(Naive -1 day) Training data error: %.2f MSE\" % mse_train_naive_day)\n",
    "print(\"(Naive -1 day) Test data error: %.2f MSE\" % mse_test_naive_day)\n",
    "print(\"(Naive -1 week) Training data error: %.2f MSE\" % mse_train_naive_week)\n",
    "print(\"(Naive -1 week) Test data error: %.2f MSE\" % mse_test_naive_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM for Future Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to read data and preprocess it so that it feeds into Keras. \n",
    "# this create dataset function gives data_y as vector with nstep values i.e. n-day ahead prediciton\n",
    "def create_dataset_nstep(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        sample = dataset[i:(i + window_size), 0]\n",
    "        data_x.append(sample)\n",
    "        data_y.append(dataset[(i + window_size):(i + window_size + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26900 samples, validate on 4748 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0546 - val_loss: 0.0017 - val_mean_squared_error: 0.0017 - val_mean_absolute_error: 0.0328\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.0012 - mean_squared_error: 0.0012 - mean_absolute_error: 0.0270 - val_loss: 0.0011 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0259\n",
      "Epoch 3/100\n",
      " - 2s - loss: 8.5878e-04 - mean_squared_error: 8.5878e-04 - mean_absolute_error: 0.0225 - val_loss: 9.0430e-04 - val_mean_squared_error: 9.0430e-04 - val_mean_absolute_error: 0.0233\n",
      "Epoch 4/100\n",
      " - 2s - loss: 7.0867e-04 - mean_squared_error: 7.0867e-04 - mean_absolute_error: 0.0202 - val_loss: 7.6932e-04 - val_mean_squared_error: 7.6932e-04 - val_mean_absolute_error: 0.0211\n",
      "Epoch 5/100\n",
      " - 3s - loss: 6.2716e-04 - mean_squared_error: 6.2716e-04 - mean_absolute_error: 0.0188 - val_loss: 6.9540e-04 - val_mean_squared_error: 6.9540e-04 - val_mean_absolute_error: 0.0197\n",
      "Epoch 6/100\n",
      " - 3s - loss: 5.8201e-04 - mean_squared_error: 5.8201e-04 - mean_absolute_error: 0.0180 - val_loss: 6.4265e-04 - val_mean_squared_error: 6.4265e-04 - val_mean_absolute_error: 0.0189\n",
      "Epoch 7/100\n",
      " - 2s - loss: 5.3792e-04 - mean_squared_error: 5.3792e-04 - mean_absolute_error: 0.0173 - val_loss: 6.6139e-04 - val_mean_squared_error: 6.6139e-04 - val_mean_absolute_error: 0.0193\n",
      "Epoch 8/100\n",
      " - 3s - loss: 5.2500e-04 - mean_squared_error: 5.2500e-04 - mean_absolute_error: 0.0171 - val_loss: 6.0732e-04 - val_mean_squared_error: 6.0732e-04 - val_mean_absolute_error: 0.0185\n",
      "Epoch 9/100\n",
      " - 3s - loss: 4.9601e-04 - mean_squared_error: 4.9601e-04 - mean_absolute_error: 0.0166 - val_loss: 5.6644e-04 - val_mean_squared_error: 5.6644e-04 - val_mean_absolute_error: 0.0176\n",
      "Epoch 10/100\n",
      " - 3s - loss: 4.9254e-04 - mean_squared_error: 4.9254e-04 - mean_absolute_error: 0.0166 - val_loss: 5.9935e-04 - val_mean_squared_error: 5.9935e-04 - val_mean_absolute_error: 0.0184\n",
      "Epoch 11/100\n",
      " - 2s - loss: 4.7099e-04 - mean_squared_error: 4.7099e-04 - mean_absolute_error: 0.0162 - val_loss: 6.7769e-04 - val_mean_squared_error: 6.7769e-04 - val_mean_absolute_error: 0.0199\n",
      "Epoch 12/100\n",
      " - 2s - loss: 4.6876e-04 - mean_squared_error: 4.6876e-04 - mean_absolute_error: 0.0162 - val_loss: 6.8674e-04 - val_mean_squared_error: 6.8674e-04 - val_mean_absolute_error: 0.0200\n",
      "Epoch 13/100\n",
      " - 3s - loss: 4.5513e-04 - mean_squared_error: 4.5513e-04 - mean_absolute_error: 0.0159 - val_loss: 5.9479e-04 - val_mean_squared_error: 5.9479e-04 - val_mean_absolute_error: 0.0182\n",
      "Epoch 14/100\n",
      " - 3s - loss: 4.5287e-04 - mean_squared_error: 4.5287e-04 - mean_absolute_error: 0.0158 - val_loss: 5.5620e-04 - val_mean_squared_error: 5.5620e-04 - val_mean_absolute_error: 0.0175\n",
      "Epoch 15/100\n",
      " - 3s - loss: 4.5704e-04 - mean_squared_error: 4.5704e-04 - mean_absolute_error: 0.0160 - val_loss: 5.7991e-04 - val_mean_squared_error: 5.7991e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 16/100\n",
      " - 2s - loss: 4.3651e-04 - mean_squared_error: 4.3651e-04 - mean_absolute_error: 0.0155 - val_loss: 5.2877e-04 - val_mean_squared_error: 5.2877e-04 - val_mean_absolute_error: 0.0171\n",
      "Epoch 17/100\n",
      " - 2s - loss: 4.3914e-04 - mean_squared_error: 4.3914e-04 - mean_absolute_error: 0.0156 - val_loss: 5.1146e-04 - val_mean_squared_error: 5.1146e-04 - val_mean_absolute_error: 0.0166\n",
      "Epoch 18/100\n",
      " - 2s - loss: 4.3309e-04 - mean_squared_error: 4.3309e-04 - mean_absolute_error: 0.0155 - val_loss: 5.3046e-04 - val_mean_squared_error: 5.3046e-04 - val_mean_absolute_error: 0.0170\n",
      "Epoch 19/100\n",
      " - 2s - loss: 4.3879e-04 - mean_squared_error: 4.3879e-04 - mean_absolute_error: 0.0156 - val_loss: 6.1882e-04 - val_mean_squared_error: 6.1882e-04 - val_mean_absolute_error: 0.0188\n",
      "Epoch 20/100\n",
      " - 2s - loss: 4.3058e-04 - mean_squared_error: 4.3058e-04 - mean_absolute_error: 0.0154 - val_loss: 5.0857e-04 - val_mean_squared_error: 5.0857e-04 - val_mean_absolute_error: 0.0166\n",
      "Epoch 21/100\n",
      " - 2s - loss: 4.3080e-04 - mean_squared_error: 4.3080e-04 - mean_absolute_error: 0.0154 - val_loss: 5.2953e-04 - val_mean_squared_error: 5.2953e-04 - val_mean_absolute_error: 0.0173\n",
      "Epoch 22/100\n",
      " - 2s - loss: 4.2696e-04 - mean_squared_error: 4.2696e-04 - mean_absolute_error: 0.0153 - val_loss: 5.2120e-04 - val_mean_squared_error: 5.2120e-04 - val_mean_absolute_error: 0.0168\n",
      "Epoch 23/100\n",
      " - 2s - loss: 4.2409e-04 - mean_squared_error: 4.2409e-04 - mean_absolute_error: 0.0153 - val_loss: 5.3437e-04 - val_mean_squared_error: 5.3437e-04 - val_mean_absolute_error: 0.0171\n",
      "Epoch 24/100\n",
      " - 2s - loss: 4.2268e-04 - mean_squared_error: 4.2268e-04 - mean_absolute_error: 0.0152 - val_loss: 5.0565e-04 - val_mean_squared_error: 5.0565e-04 - val_mean_absolute_error: 0.0165\n",
      "Epoch 25/100\n",
      " - 2s - loss: 4.2488e-04 - mean_squared_error: 4.2488e-04 - mean_absolute_error: 0.0153 - val_loss: 4.9312e-04 - val_mean_squared_error: 4.9312e-04 - val_mean_absolute_error: 0.0163\n",
      "Epoch 26/100\n",
      " - 2s - loss: 4.2252e-04 - mean_squared_error: 4.2252e-04 - mean_absolute_error: 0.0152 - val_loss: 5.0817e-04 - val_mean_squared_error: 5.0817e-04 - val_mean_absolute_error: 0.0168\n",
      "Epoch 27/100\n",
      " - 2s - loss: 4.1565e-04 - mean_squared_error: 4.1565e-04 - mean_absolute_error: 0.0151 - val_loss: 5.0244e-04 - val_mean_squared_error: 5.0244e-04 - val_mean_absolute_error: 0.0163\n",
      "Epoch 28/100\n",
      " - 2s - loss: 4.0966e-04 - mean_squared_error: 4.0966e-04 - mean_absolute_error: 0.0150 - val_loss: 5.0720e-04 - val_mean_squared_error: 5.0720e-04 - val_mean_absolute_error: 0.0168\n",
      "Epoch 29/100\n",
      " - 2s - loss: 4.1963e-04 - mean_squared_error: 4.1963e-04 - mean_absolute_error: 0.0152 - val_loss: 4.9424e-04 - val_mean_squared_error: 4.9424e-04 - val_mean_absolute_error: 0.0164\n",
      "Epoch 30/100\n",
      " - 2s - loss: 4.1306e-04 - mean_squared_error: 4.1306e-04 - mean_absolute_error: 0.0150 - val_loss: 5.1126e-04 - val_mean_squared_error: 5.1126e-04 - val_mean_absolute_error: 0.0168\n",
      "Epoch 00030: early stopping\n",
      "Training data error: 794.47 MSE\n",
      "Test data error: 833.51 MSE\n",
      "Training data error: 24.32 MAE\n",
      "Test data error: 24.86 MAE\n"
     ]
    }
   ],
   "source": [
    "# define a Keras model which will be trained\n",
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    # defining a sequential layer means that more layers can simply be added on\n",
    "    vanilla_rnn = Sequential()\n",
    "    # add an LSTM layer\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (1, window_size)))\n",
    "    # add a dense layer to aggregate the dimension 20 hidden layer into nstep outputs\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    # chose the loss function, the optimizer and the metrics\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "# define the lookback perdiod which is used for training\n",
    "window_size = 50\n",
    "# define the prediciton perdiod which is used\n",
    "nstep = 1\n",
    "\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "# instantiate the model\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "#SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "\n",
    "# train the model with the early stopping callback which stops training if the validation loss does not decrease \n",
    "# for \"patience\" amount of epochs\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "# calculate the MSE and MAE for each set of predicitons and true values\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                2480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 2,501\n",
      "Trainable params: 2,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# show Keras model summary\n",
    "vanilla_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some metrics over the training time\n",
    "metrics = [['loss', 'val_loss'], ['mean_absolute_error', \n",
    "           'val_mean_absolute_error']]\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "for i, x in enumerate(metrics):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.plot(history.history[x[0]])\n",
    "    plt.plot(history.history[x[1]])\n",
    "    plt.legend(['Train', 'Val'], loc='best')\n",
    "    string_metric = (' ').join(x[0].split('_'))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.title('Model {}'.format(string_metric))\n",
    "    plt.ylabel(string_metric)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the code that follows is the same as before but with different window sizes for lookback periods and prediction lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25917 samples, validate on 4574 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.0126 - mse: 0.0126 - mae: 0.0820 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0789\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0081 - mse: 0.0081 - mae: 0.0677 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0802\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0079 - mse: 0.0079 - mae: 0.0668 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0825\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0077 - mse: 0.0077 - mae: 0.0659 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0799\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0076 - mse: 0.0076 - mae: 0.0651 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0803\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - mae: 0.0639 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0829\n",
      "Epoch 00006: early stopping\n",
      "Training data error: 3435.35 MSE\n",
      "Test data error: 4369.16 MSE\n",
      "Training data error: 50.11 MAE\n",
      "Test data error: 55.95 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "#SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_rnn.save(\"./../../Data/Models/lstm_1000_168.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 1000\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "#SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_rnn.save(\"./../../Data/Models/lstm_100_24.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM for Future Predicitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is very similar to before, the difference is in the model definition which uses a bidirectional LSTM instead of a regular LSTM or GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset by looking at values either side of a gap and concatenating them. \n",
    "# this function is not used yet, only in the next section (bidirectional LSTM for gap prediciton)\n",
    "def create_dataset_nstep_bidir(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        ws_2 = int(window_size/2)\n",
    "        s1 = dataset[i:(i + ws_2), 0]\n",
    "        s2 = dataset[(i + ws_2 + nstep):(i + window_size + nstep), 0]\n",
    "        data_x.append(np.concatenate((s1, s2)))\n",
    "        data_y.append(dataset[(i + ws_2):(i + ws_2 + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26866 samples, validate on 4742 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0395 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0258\n",
      "Epoch 2/100\n",
      " - 3s - loss: 7.6091e-04 - mean_squared_error: 7.6091e-04 - mean_absolute_error: 0.0207 - val_loss: 9.7557e-04 - val_mean_squared_error: 9.7557e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 3/100\n",
      " - 3s - loss: 5.4092e-04 - mean_squared_error: 5.4092e-04 - mean_absolute_error: 0.0172 - val_loss: 8.3982e-04 - val_mean_squared_error: 8.3982e-04 - val_mean_absolute_error: 0.0219\n",
      "Epoch 4/100\n",
      " - 3s - loss: 4.6916e-04 - mean_squared_error: 4.6916e-04 - mean_absolute_error: 0.0160 - val_loss: 6.2432e-04 - val_mean_squared_error: 6.2432e-04 - val_mean_absolute_error: 0.0184\n",
      "Epoch 5/100\n",
      " - 3s - loss: 4.1323e-04 - mean_squared_error: 4.1323e-04 - mean_absolute_error: 0.0149 - val_loss: 4.5517e-04 - val_mean_squared_error: 4.5517e-04 - val_mean_absolute_error: 0.0156\n",
      "Epoch 6/100\n",
      " - 3s - loss: 3.7108e-04 - mean_squared_error: 3.7108e-04 - mean_absolute_error: 0.0141 - val_loss: 4.1627e-04 - val_mean_squared_error: 4.1627e-04 - val_mean_absolute_error: 0.0146\n",
      "Epoch 7/100\n",
      " - 3s - loss: 3.4438e-04 - mean_squared_error: 3.4438e-04 - mean_absolute_error: 0.0136 - val_loss: 3.9721e-04 - val_mean_squared_error: 3.9721e-04 - val_mean_absolute_error: 0.0149\n",
      "Epoch 8/100\n",
      " - 3s - loss: 3.2622e-04 - mean_squared_error: 3.2622e-04 - mean_absolute_error: 0.0132 - val_loss: 4.6570e-04 - val_mean_squared_error: 4.6570e-04 - val_mean_absolute_error: 0.0162\n",
      "Epoch 9/100\n",
      " - 3s - loss: 3.1169e-04 - mean_squared_error: 3.1169e-04 - mean_absolute_error: 0.0129 - val_loss: 3.4235e-04 - val_mean_squared_error: 3.4235e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 10/100\n",
      " - 3s - loss: 2.9640e-04 - mean_squared_error: 2.9640e-04 - mean_absolute_error: 0.0125 - val_loss: 3.2271e-04 - val_mean_squared_error: 3.2271e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 11/100\n",
      " - 3s - loss: 2.8950e-04 - mean_squared_error: 2.8950e-04 - mean_absolute_error: 0.0124 - val_loss: 3.3864e-04 - val_mean_squared_error: 3.3864e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 12/100\n",
      " - 3s - loss: 2.8270e-04 - mean_squared_error: 2.8270e-04 - mean_absolute_error: 0.0123 - val_loss: 4.1346e-04 - val_mean_squared_error: 4.1346e-04 - val_mean_absolute_error: 0.0147\n",
      "Epoch 13/100\n",
      " - 3s - loss: 2.8301e-04 - mean_squared_error: 2.8301e-04 - mean_absolute_error: 0.0123 - val_loss: 3.1633e-04 - val_mean_squared_error: 3.1633e-04 - val_mean_absolute_error: 0.0127\n",
      "Epoch 14/100\n",
      " - 3s - loss: 2.7063e-04 - mean_squared_error: 2.7063e-04 - mean_absolute_error: 0.0120 - val_loss: 4.7877e-04 - val_mean_squared_error: 4.7877e-04 - val_mean_absolute_error: 0.0173\n",
      "Epoch 15/100\n",
      " - 3s - loss: 2.6850e-04 - mean_squared_error: 2.6850e-04 - mean_absolute_error: 0.0120 - val_loss: 3.1146e-04 - val_mean_squared_error: 3.1146e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 16/100\n",
      " - 3s - loss: 2.5777e-04 - mean_squared_error: 2.5777e-04 - mean_absolute_error: 0.0117 - val_loss: 3.9421e-04 - val_mean_squared_error: 3.9421e-04 - val_mean_absolute_error: 0.0154\n",
      "Epoch 17/100\n",
      " - 3s - loss: 2.6340e-04 - mean_squared_error: 2.6340e-04 - mean_absolute_error: 0.0119 - val_loss: 3.3287e-04 - val_mean_squared_error: 3.3287e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 18/100\n",
      " - 3s - loss: 2.5883e-04 - mean_squared_error: 2.5883e-04 - mean_absolute_error: 0.0117 - val_loss: 4.5251e-04 - val_mean_squared_error: 4.5251e-04 - val_mean_absolute_error: 0.0157\n",
      "Epoch 19/100\n",
      " - 3s - loss: 2.5980e-04 - mean_squared_error: 2.5980e-04 - mean_absolute_error: 0.0118 - val_loss: 2.8554e-04 - val_mean_squared_error: 2.8554e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 20/100\n",
      " - 3s - loss: 2.4757e-04 - mean_squared_error: 2.4757e-04 - mean_absolute_error: 0.0114 - val_loss: 3.2158e-04 - val_mean_squared_error: 3.2158e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 21/100\n",
      " - 3s - loss: 2.5326e-04 - mean_squared_error: 2.5326e-04 - mean_absolute_error: 0.0116 - val_loss: 3.3845e-04 - val_mean_squared_error: 3.3845e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 22/100\n",
      " - 4s - loss: 2.5307e-04 - mean_squared_error: 2.5307e-04 - mean_absolute_error: 0.0117 - val_loss: 3.0899e-04 - val_mean_squared_error: 3.0899e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 23/100\n",
      " - 4s - loss: 2.5163e-04 - mean_squared_error: 2.5163e-04 - mean_absolute_error: 0.0116 - val_loss: 2.8337e-04 - val_mean_squared_error: 2.8337e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 24/100\n",
      " - 4s - loss: 2.4596e-04 - mean_squared_error: 2.4596e-04 - mean_absolute_error: 0.0114 - val_loss: 4.5868e-04 - val_mean_squared_error: 4.5868e-04 - val_mean_absolute_error: 0.0161\n",
      "Epoch 25/100\n",
      " - 4s - loss: 2.4330e-04 - mean_squared_error: 2.4330e-04 - mean_absolute_error: 0.0114 - val_loss: 3.1868e-04 - val_mean_squared_error: 3.1868e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 26/100\n",
      " - 3s - loss: 2.4204e-04 - mean_squared_error: 2.4204e-04 - mean_absolute_error: 0.0113 - val_loss: 2.7648e-04 - val_mean_squared_error: 2.7648e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 27/100\n",
      " - 3s - loss: 2.4054e-04 - mean_squared_error: 2.4054e-04 - mean_absolute_error: 0.0113 - val_loss: 2.8984e-04 - val_mean_squared_error: 2.8984e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 28/100\n",
      " - 3s - loss: 2.4582e-04 - mean_squared_error: 2.4582e-04 - mean_absolute_error: 0.0115 - val_loss: 6.3928e-04 - val_mean_squared_error: 6.3928e-04 - val_mean_absolute_error: 0.0194\n",
      "Epoch 29/100\n",
      " - 3s - loss: 2.3671e-04 - mean_squared_error: 2.3671e-04 - mean_absolute_error: 0.0112 - val_loss: 2.9586e-04 - val_mean_squared_error: 2.9586e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 30/100\n",
      " - 4s - loss: 2.3986e-04 - mean_squared_error: 2.3986e-04 - mean_absolute_error: 0.0113 - val_loss: 3.1958e-04 - val_mean_squared_error: 3.1958e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 31/100\n",
      " - 6s - loss: 2.3282e-04 - mean_squared_error: 2.3282e-04 - mean_absolute_error: 0.0111 - val_loss: 3.0452e-04 - val_mean_squared_error: 3.0452e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 00031: early stopping\n",
      "Training data error: 580.17 MSE\n",
      "Test data error: 625.73 MSE\n",
      "Training data error: 20.35 MAE\n",
      "Test data error: 21.26 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_dataset_nstep_bidir(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        ws_2 = int(window_size/2)\n",
    "        s1 = dataset[i:(i + ws_2), 0]\n",
    "        s2 = dataset[(i + ws_2 + nstep):(i + window_size + nstep), 0]\n",
    "        data_x.append(np.concatenate((s1, s2)))\n",
    "        data_y.append(dataset[(i + ws_2):(i + ws_2 + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))\n",
    "\n",
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26196 samples, validate on 4623 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.0108 - mse: 0.0108 - mae: 0.0767 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0797\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.0082 - mse: 0.0082 - mae: 0.0677 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0790\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.0081 - mse: 0.0081 - mae: 0.0672 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0789\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.0079 - mse: 0.0079 - mae: 0.0665 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0796\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.0078 - mse: 0.0078 - mae: 0.0661 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0787\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.0077 - mse: 0.0077 - mae: 0.0654 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0790\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0074 - mse: 0.0074 - mae: 0.0644 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0801\n",
      "Epoch 00007: early stopping\n",
      "Training data error: 3388.78 MSE\n",
      "Test data error: 4105.26 MSE\n",
      "Training data error: 50.83 MAE\n",
      "Test data error: 55.60 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 672\n",
    "nstep = 168\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "#SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_rnn.save(\"./../../Data/Models/lstm_672_168.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM for Gap Predicitons (Concatenating Data Before & After)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26866 samples, validate on 4742 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - mean_absolute_error: 0.0231 - val_loss: 3.3682e-04 - val_mean_squared_error: 3.3682e-04 - val_mean_absolute_error: 0.0138\n",
      "Epoch 2/100\n",
      " - 3s - loss: 2.0768e-04 - mean_squared_error: 2.0768e-04 - mean_absolute_error: 0.0108 - val_loss: 2.3936e-04 - val_mean_squared_error: 2.3936e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.2895e-04 - mean_squared_error: 1.2895e-04 - mean_absolute_error: 0.0084 - val_loss: 1.1996e-04 - val_mean_squared_error: 1.1996e-04 - val_mean_absolute_error: 0.0077\n",
      "Epoch 4/100\n",
      " - 3s - loss: 9.8269e-05 - mean_squared_error: 9.8269e-05 - mean_absolute_error: 0.0073 - val_loss: 1.1271e-04 - val_mean_squared_error: 1.1271e-04 - val_mean_absolute_error: 0.0076\n",
      "Epoch 5/100\n",
      " - 3s - loss: 8.6943e-05 - mean_squared_error: 8.6943e-05 - mean_absolute_error: 0.0069 - val_loss: 9.4470e-05 - val_mean_squared_error: 9.4470e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 6/100\n",
      " - 3s - loss: 7.5603e-05 - mean_squared_error: 7.5603e-05 - mean_absolute_error: 0.0064 - val_loss: 9.9345e-05 - val_mean_squared_error: 9.9345e-05 - val_mean_absolute_error: 0.0071\n",
      "Epoch 7/100\n",
      " - 3s - loss: 7.6895e-05 - mean_squared_error: 7.6895e-05 - mean_absolute_error: 0.0065 - val_loss: 9.0644e-05 - val_mean_squared_error: 9.0644e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 8/100\n",
      " - 3s - loss: 7.4740e-05 - mean_squared_error: 7.4740e-05 - mean_absolute_error: 0.0064 - val_loss: 8.5053e-05 - val_mean_squared_error: 8.5053e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 9/100\n",
      " - 3s - loss: 6.5595e-05 - mean_squared_error: 6.5595e-05 - mean_absolute_error: 0.0060 - val_loss: 7.6845e-05 - val_mean_squared_error: 7.6845e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 10/100\n",
      " - 3s - loss: 6.5920e-05 - mean_squared_error: 6.5920e-05 - mean_absolute_error: 0.0060 - val_loss: 7.9803e-05 - val_mean_squared_error: 7.9803e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 11/100\n",
      " - 3s - loss: 6.4626e-05 - mean_squared_error: 6.4626e-05 - mean_absolute_error: 0.0059 - val_loss: 1.3463e-04 - val_mean_squared_error: 1.3463e-04 - val_mean_absolute_error: 0.0091\n",
      "Epoch 12/100\n",
      " - 3s - loss: 6.4589e-05 - mean_squared_error: 6.4589e-05 - mean_absolute_error: 0.0060 - val_loss: 7.9422e-05 - val_mean_squared_error: 7.9422e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 13/100\n",
      " - 3s - loss: 6.0914e-05 - mean_squared_error: 6.0914e-05 - mean_absolute_error: 0.0058 - val_loss: 7.8383e-05 - val_mean_squared_error: 7.8383e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 14/100\n",
      " - 3s - loss: 6.2361e-05 - mean_squared_error: 6.2361e-05 - mean_absolute_error: 0.0059 - val_loss: 1.2972e-04 - val_mean_squared_error: 1.2972e-04 - val_mean_absolute_error: 0.0086\n",
      "Epoch 00014: early stopping\n",
      "Training data error: 364.47 MSE\n",
      "Test data error: 395.08 MSE\n",
      "Training data error: 16.75 MAE\n",
      "Test data error: 17.46 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biriectional LSTM (Long Time Period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there are a few experiments that were not added to the final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 4000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 4000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariable LSTM and Temperature Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = r\"../../Data/temperature_history.csv\"\n",
    "df_T = pd.read_csv(PATH)\n",
    "h_df_T = df_T.set_index(['station_id', 'year', 'month', 'day'])\n",
    "trans_dict = {}\n",
    "for i in list(h_df_T.columns):\n",
    "    trans_dict[i] = int(i[1:])\n",
    "h_df_T = h_df_T.rename(columns=trans_dict)\n",
    "h_df_T = h_df_T.stack()\n",
    "h_df_T = h_df_T.unstack(level=0)\n",
    "h_df_T.columns = h_df_T.columns.get_level_values(0)\n",
    "h_df_T.columns.names = [None]\n",
    "h_df_T.index.names = [None, None, None, None]\n",
    "\n",
    "PATH = r\"../../Data/temperature_solution.csv\"\n",
    "df_T_Sol = pd.read_csv(PATH)\n",
    "h_df_T_Sol = df_T_Sol.set_index(['station_id', 'year', 'month', 'day', 'hour'])\n",
    "h_df_T_Sol = h_df_T_Sol.drop(['datetime', 'date'], axis=1)\n",
    "h_df_T_Sol = h_df_T_Sol.unstack(level=0)\n",
    "h_df_T_Sol.columns = h_df_T_Sol.columns.get_level_values(1)\n",
    "h_df_T_Sol.columns.names = [None]\n",
    "h_df_T_Sol.index.names = [None, None, None, None]\n",
    "\n",
    "zone_T = pd.concat([h_df_T, h_df_T_Sol], axis=0, join='outer', ignore_index=False, keys=None, \n",
    "          levels=None, names=None, verify_integrity=True, copy=True)\n",
    "\n",
    "T_mean = zone_T.mean(axis=1)\n",
    "#temp['T'] = T_mean\n",
    "temp['T'] = pd.Series(np.concatenate([T_mean[:12].values, T_mean[0:-12].values]) , index = (T_mean.index))\n",
    "\n",
    "zone_T.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[[1, 'T']].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(temp[[1, 'T']])\n",
    "\n",
    "# Using 80% of data for training, 20% for validation.\n",
    "TRAINING_PERCENT = 0.80\n",
    "\n",
    "train_size = int(len(scaled) * TRAINING_PERCENT)\n",
    "test_size = len(scaled) - train_size\n",
    "train_multi, test_multi = scaled[0:train_size, :], scaled[train_size:len(scaled), :]\n",
    "print(\"Number of samples training set: \" + str((len(train_multi))))\n",
    "print(\"Number of samples test set: \" + str((len(test_multi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_nstep_multi(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        sample = dataset[i:(i + window_size), :]\n",
    "        data_x.append(sample)\n",
    "        data_y.append(dataset[(i + window_size):(i + window_size + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
