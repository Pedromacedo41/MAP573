{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import math\n",
    "from keras.layers import LSTM, Bidirectional, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from keras import callbacks\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2004</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>16853.0</td>\n",
       "      <td>126259.0</td>\n",
       "      <td>136233.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>6829.0</td>\n",
       "      <td>133088.0</td>\n",
       "      <td>136233.0</td>\n",
       "      <td>3124.0</td>\n",
       "      <td>75243.0</td>\n",
       "      <td>23339.0</td>\n",
       "      <td>90700.0</td>\n",
       "      <td>118378.0</td>\n",
       "      <td>20673.0</td>\n",
       "      <td>21791.0</td>\n",
       "      <td>65970.0</td>\n",
       "      <td>28752.0</td>\n",
       "      <td>30645.0</td>\n",
       "      <td>200946.0</td>\n",
       "      <td>82298.0</td>\n",
       "      <td>79830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16450.0</td>\n",
       "      <td>123313.0</td>\n",
       "      <td>133055.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>6596.0</td>\n",
       "      <td>129909.0</td>\n",
       "      <td>133055.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>67368.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>86699.0</td>\n",
       "      <td>112480.0</td>\n",
       "      <td>19666.0</td>\n",
       "      <td>21400.0</td>\n",
       "      <td>64600.0</td>\n",
       "      <td>27851.0</td>\n",
       "      <td>30461.0</td>\n",
       "      <td>195835.0</td>\n",
       "      <td>79827.0</td>\n",
       "      <td>77429.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1         2         3      4       5         6         7   \\\n",
       "2004 1 1 1  16853.0  126259.0  136233.0  484.0  6829.0  133088.0  136233.0   \n",
       "         2  16450.0  123313.0  133055.0  457.0  6596.0  129909.0  133055.0   \n",
       "\n",
       "                8        9        10       11        12       13       14  \\\n",
       "2004 1 1 1  3124.0  75243.0  23339.0  90700.0  118378.0  20673.0  21791.0   \n",
       "         2  2956.0  67368.0  22100.0  86699.0  112480.0  19666.0  21400.0   \n",
       "\n",
       "                 15       16       17        18       19       20  \n",
       "2004 1 1 1  65970.0  28752.0  30645.0  200946.0  82298.0  79830.0  \n",
       "         2  64600.0  27851.0  30461.0  195835.0  79827.0  77429.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = r\"../../Data/completeLoad.csv\"\n",
    "df = pd.read_csv(PATH)\n",
    "temp = df.set_index(['zone_id', 'year', 'month', 'day'])\n",
    "colname_to_int = {}\n",
    "for i in list(temp.columns):\n",
    "    colname_to_int[i] = int(i[1:])\n",
    "\n",
    "temp = temp.rename(columns=colname_to_int)\n",
    "temp = temp.stack()\n",
    "temp = temp.unstack(level=0)\n",
    "temp.columns.names = [None]\n",
    "temp.index.names = [None, None, None, None]\n",
    "df_zone = temp\n",
    "temp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-37bccd2d1c76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmse_train_naive_hour\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_predict_naive_hour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_naive_hour_predict_and_score_multi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mmse_test_naive_hour\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict_naive_hour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_naive_hour_predict_and_score_multi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mmse_train_naive_day\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_predict_naive_day\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_naive_day_predict_and_score_multi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "def get_naive_week_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24*7], Y[0:-24*7])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_day_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24], Y[0:-24])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_hour_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0, :].reshape(1, -1), Y[0:-1])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "mse_train_naive_hour, train_predict_naive_hour = get_naive_hour_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_hour, test_predict_naive_hour = get_naive_hour_predict_and_score_multi(test_X, test_Y)\n",
    "mse_train_naive_day, train_predict_naive_day = get_naive_day_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_day, test_predict_naive_day = get_naive_day_predict_and_score_multi(test_X, test_Y)\n",
    "mse_train_naive_week, train_predict_naive_week = get_naive_week_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_week, test_predict_naive_week = get_naive_week_predict_and_score_multi(test_X, test_Y)\n",
    "\n",
    "print(\"(Naive -1 hour) Training data error: %.2f MSE\" % mse_train_naive_hour)\n",
    "print(\"(Naive -1 hour) Test data error: %.2f MSE\" % mse_test_naive_hour)\n",
    "print(\"(Naive -1 day) Training data error: %.2f MSE\" % mse_train_naive_day)\n",
    "print(\"(Naive -1 day) Test data error: %.2f MSE\" % mse_test_naive_day)\n",
    "print(\"(Naive -1 week) Training data error: %.2f MSE\" % mse_train_naive_week)\n",
    "print(\"(Naive -1 week) Test data error: %.2f MSE\" % mse_test_naive_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-12ff1bd0b3fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmse_train_naive_hour\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_predict_naive_hour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_naive_hour_predict_and_score_multi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mmse_test_naive_hour\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict_naive_hour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_naive_hour_predict_and_score_multi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mmse_train_naive_day\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_predict_naive_day\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_naive_day_predict_and_score_multi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "def get_naive_week_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24*7], Y[0:-24*7])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_day_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24], Y[0:-24])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_hour_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0, :].reshape(1, -1), Y[0:-1])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "mse_train_naive_hour, train_predict_naive_hour = get_naive_hour_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_hour, test_predict_naive_hour = get_naive_hour_predict_and_score_multi(test_X, test_Y)\n",
    "mse_train_naive_day, train_predict_naive_day = get_naive_day_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_day, test_predict_naive_day = get_naive_day_predict_and_score_multi(test_X, test_Y)\n",
    "mse_train_naive_week, train_predict_naive_week = get_naive_week_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_week, test_predict_naive_week = get_naive_week_predict_and_score_multi(test_X, test_Y)\n",
    "\n",
    "print(\"(Naive -1 hour) Training data error: %.2f MSE\" % mse_train_naive_hour)\n",
    "print(\"(Naive -1 hour) Test data error: %.2f MSE\" % mse_test_naive_hour)\n",
    "print(\"(Naive -1 day) Training data error: %.2f MSE\" % mse_train_naive_day)\n",
    "print(\"(Naive -1 day) Test data error: %.2f MSE\" % mse_test_naive_day)\n",
    "print(\"(Naive -1 week) Training data error: %.2f MSE\" % mse_train_naive_week)\n",
    "print(\"(Naive -1 week) Test data error: %.2f MSE\" % mse_test_naive_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples training set: 31660\n",
      "Number of samples test set: 7916\n"
     ]
    }
   ],
   "source": [
    "# use data for zone 1.\n",
    "data = df_zone[1].values.reshape(-1, 1)\n",
    "\n",
    "# normalize data with min max normalization.\n",
    "normalizer = MinMaxScaler(feature_range = (0, 1))\n",
    "dataset = normalizer.fit_transform(data)\n",
    "\n",
    "# Using 80% of data for training, 20% for validation.\n",
    "TRAINING_PERCENT = 0.80\n",
    "\n",
    "train_size = int(len(dataset) * TRAINING_PERCENT)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(\"Number of samples training set: \" + str((len(train))))\n",
    "print(\"Number of samples test set: \" + str((len(test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_nstep(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        sample = dataset[i:(i + window_size), 0]\n",
    "        data_x.append(sample)\n",
    "        data_y.append(dataset[(i + window_size):(i + window_size + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26866 samples, validate on 4742 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.0028 - mean_squared_error: 0.0028 - mean_absolute_error: 0.0312 - val_loss: 6.0377e-04 - val_mean_squared_error: 6.0377e-04 - val_mean_absolute_error: 0.0190\n",
      "Epoch 2/100\n",
      " - 3s - loss: 3.3333e-04 - mean_squared_error: 3.3333e-04 - mean_absolute_error: 0.0139 - val_loss: 2.8379e-04 - val_mean_squared_error: 2.8379e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.9561e-04 - mean_squared_error: 1.9561e-04 - mean_absolute_error: 0.0105 - val_loss: 2.0449e-04 - val_mean_squared_error: 2.0449e-04 - val_mean_absolute_error: 0.0103\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.3714e-04 - mean_squared_error: 1.3714e-04 - mean_absolute_error: 0.0087 - val_loss: 1.3369e-04 - val_mean_squared_error: 1.3369e-04 - val_mean_absolute_error: 0.0082\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0398e-04 - mean_squared_error: 1.0398e-04 - mean_absolute_error: 0.0075 - val_loss: 1.2689e-04 - val_mean_squared_error: 1.2689e-04 - val_mean_absolute_error: 0.0084\n",
      "Epoch 6/100\n",
      " - 3s - loss: 8.8353e-05 - mean_squared_error: 8.8353e-05 - mean_absolute_error: 0.0069 - val_loss: 1.2453e-04 - val_mean_squared_error: 1.2453e-04 - val_mean_absolute_error: 0.0084\n",
      "Epoch 7/100\n",
      " - 3s - loss: 8.0345e-05 - mean_squared_error: 8.0345e-05 - mean_absolute_error: 0.0066 - val_loss: 1.1328e-04 - val_mean_squared_error: 1.1328e-04 - val_mean_absolute_error: 0.0074\n",
      "Epoch 8/100\n",
      " - 3s - loss: 7.0902e-05 - mean_squared_error: 7.0902e-05 - mean_absolute_error: 0.0062 - val_loss: 2.0559e-04 - val_mean_squared_error: 2.0559e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 9/100\n",
      " - 3s - loss: 6.7986e-05 - mean_squared_error: 6.7986e-05 - mean_absolute_error: 0.0061 - val_loss: 8.5071e-05 - val_mean_squared_error: 8.5071e-05 - val_mean_absolute_error: 0.0065\n",
      "Epoch 10/100\n",
      " - 3s - loss: 6.6245e-05 - mean_squared_error: 6.6245e-05 - mean_absolute_error: 0.0060 - val_loss: 7.6665e-05 - val_mean_squared_error: 7.6665e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 11/100\n",
      " - 4s - loss: 6.3244e-05 - mean_squared_error: 6.3244e-05 - mean_absolute_error: 0.0059 - val_loss: 9.1114e-05 - val_mean_squared_error: 9.1114e-05 - val_mean_absolute_error: 0.0069\n",
      "Epoch 12/100\n",
      " - 4s - loss: 6.0857e-05 - mean_squared_error: 6.0857e-05 - mean_absolute_error: 0.0057 - val_loss: 9.2642e-05 - val_mean_squared_error: 9.2642e-05 - val_mean_absolute_error: 0.0069\n",
      "Epoch 13/100\n",
      " - 4s - loss: 6.0967e-05 - mean_squared_error: 6.0967e-05 - mean_absolute_error: 0.0057 - val_loss: 8.1844e-05 - val_mean_squared_error: 8.1844e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 14/100\n",
      " - 4s - loss: 5.8353e-05 - mean_squared_error: 5.8353e-05 - mean_absolute_error: 0.0056 - val_loss: 7.5470e-05 - val_mean_squared_error: 7.5470e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 15/100\n",
      " - 5s - loss: 6.1329e-05 - mean_squared_error: 6.1329e-05 - mean_absolute_error: 0.0058 - val_loss: 6.8685e-05 - val_mean_squared_error: 6.8685e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 16/100\n",
      " - 5s - loss: 5.7097e-05 - mean_squared_error: 5.7097e-05 - mean_absolute_error: 0.0055 - val_loss: 9.8659e-05 - val_mean_squared_error: 9.8659e-05 - val_mean_absolute_error: 0.0077\n",
      "Epoch 17/100\n",
      " - 5s - loss: 5.6742e-05 - mean_squared_error: 5.6742e-05 - mean_absolute_error: 0.0055 - val_loss: 1.4866e-04 - val_mean_squared_error: 1.4866e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 18/100\n",
      " - 5s - loss: 5.5378e-05 - mean_squared_error: 5.5378e-05 - mean_absolute_error: 0.0055 - val_loss: 1.0305e-04 - val_mean_squared_error: 1.0305e-04 - val_mean_absolute_error: 0.0077\n",
      "Epoch 19/100\n",
      " - 4s - loss: 5.6499e-05 - mean_squared_error: 5.6499e-05 - mean_absolute_error: 0.0055 - val_loss: 6.7036e-05 - val_mean_squared_error: 6.7036e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 20/100\n",
      " - 4s - loss: 5.6458e-05 - mean_squared_error: 5.6458e-05 - mean_absolute_error: 0.0055 - val_loss: 7.8691e-05 - val_mean_squared_error: 7.8691e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 21/100\n",
      " - 2s - loss: 5.6238e-05 - mean_squared_error: 5.6238e-05 - mean_absolute_error: 0.0055 - val_loss: 7.8938e-05 - val_mean_squared_error: 7.8938e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 22/100\n",
      " - 2s - loss: 5.4737e-05 - mean_squared_error: 5.4737e-05 - mean_absolute_error: 0.0054 - val_loss: 7.4350e-05 - val_mean_squared_error: 7.4350e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 23/100\n",
      " - 2s - loss: 5.2521e-05 - mean_squared_error: 5.2521e-05 - mean_absolute_error: 0.0053 - val_loss: 6.3946e-05 - val_mean_squared_error: 6.3946e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 24/100\n",
      " - 2s - loss: 5.1413e-05 - mean_squared_error: 5.1413e-05 - mean_absolute_error: 0.0053 - val_loss: 7.6213e-05 - val_mean_squared_error: 7.6213e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 25/100\n",
      " - 3s - loss: 5.2758e-05 - mean_squared_error: 5.2758e-05 - mean_absolute_error: 0.0053 - val_loss: 6.2971e-05 - val_mean_squared_error: 6.2971e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 26/100\n",
      " - 5s - loss: 5.2988e-05 - mean_squared_error: 5.2988e-05 - mean_absolute_error: 0.0054 - val_loss: 7.3576e-05 - val_mean_squared_error: 7.3576e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 27/100\n",
      " - 4s - loss: 5.3783e-05 - mean_squared_error: 5.3783e-05 - mean_absolute_error: 0.0054 - val_loss: 1.0133e-04 - val_mean_squared_error: 1.0133e-04 - val_mean_absolute_error: 0.0075\n",
      "Epoch 28/100\n",
      " - 3s - loss: 5.2658e-05 - mean_squared_error: 5.2658e-05 - mean_absolute_error: 0.0054 - val_loss: 6.4201e-05 - val_mean_squared_error: 6.4201e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 29/100\n",
      " - 3s - loss: 5.1955e-05 - mean_squared_error: 5.1955e-05 - mean_absolute_error: 0.0053 - val_loss: 6.4381e-05 - val_mean_squared_error: 6.4381e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 30/100\n",
      " - 3s - loss: 5.2070e-05 - mean_squared_error: 5.2070e-05 - mean_absolute_error: 0.0053 - val_loss: 7.2900e-05 - val_mean_squared_error: 7.2900e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 00030: early stopping\n",
      "Training data error: 274.69 MSE\n",
      "Test data error: 297.58 MSE\n",
      "Training data error: 14.05 MAE\n",
      "Test data error: 14.65 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 20)                5680      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 5,701\n",
      "Trainable params: 5,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vanilla_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = [['loss', 'val_loss'], ['mean_absolute_error', \n",
    "           'val_mean_absolute_error']]\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "for i, x in enumerate(metrics):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.plot(history.history[x[0]])\n",
    "    plt.plot(history.history[x[1]])\n",
    "    plt.legend(['Train', 'Val'], loc='best')\n",
    "    string_metric = (' ').join(x[0].split('_'))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.title('Model {}'.format(string_metric))\n",
    "    plt.ylabel(string_metric)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26824 samples, validate on 4734 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0353 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0267\n",
      "Epoch 2/100\n",
      " - 4s - loss: 7.0284e-04 - mean_squared_error: 7.0284e-04 - mean_absolute_error: 0.0199 - val_loss: 6.4824e-04 - val_mean_squared_error: 6.4824e-04 - val_mean_absolute_error: 0.0192\n",
      "Epoch 3/100\n",
      " - 4s - loss: 5.3343e-04 - mean_squared_error: 5.3343e-04 - mean_absolute_error: 0.0172 - val_loss: 5.2700e-04 - val_mean_squared_error: 5.2700e-04 - val_mean_absolute_error: 0.0171\n",
      "Epoch 4/100\n",
      " - 4s - loss: 4.5272e-04 - mean_squared_error: 4.5272e-04 - mean_absolute_error: 0.0157 - val_loss: 7.0722e-04 - val_mean_squared_error: 7.0722e-04 - val_mean_absolute_error: 0.0209\n",
      "Epoch 5/100\n",
      " - 4s - loss: 4.1717e-04 - mean_squared_error: 4.1717e-04 - mean_absolute_error: 0.0151 - val_loss: 4.0633e-04 - val_mean_squared_error: 4.0633e-04 - val_mean_absolute_error: 0.0146\n",
      "Epoch 6/100\n",
      " - 4s - loss: 3.8553e-04 - mean_squared_error: 3.8553e-04 - mean_absolute_error: 0.0145 - val_loss: 4.0167e-04 - val_mean_squared_error: 4.0167e-04 - val_mean_absolute_error: 0.0146\n",
      "Epoch 7/100\n",
      " - 4s - loss: 3.9842e-04 - mean_squared_error: 3.9842e-04 - mean_absolute_error: 0.0148 - val_loss: 4.3540e-04 - val_mean_squared_error: 4.3540e-04 - val_mean_absolute_error: 0.0155\n",
      "Epoch 8/100\n",
      " - 4s - loss: 3.4659e-04 - mean_squared_error: 3.4659e-04 - mean_absolute_error: 0.0137 - val_loss: 4.2282e-04 - val_mean_squared_error: 4.2282e-04 - val_mean_absolute_error: 0.0154\n",
      "Epoch 9/100\n",
      " - 5s - loss: 3.4169e-04 - mean_squared_error: 3.4169e-04 - mean_absolute_error: 0.0136 - val_loss: 3.6513e-04 - val_mean_squared_error: 3.6513e-04 - val_mean_absolute_error: 0.0138\n",
      "Epoch 10/100\n",
      " - 4s - loss: 3.5000e-04 - mean_squared_error: 3.5000e-04 - mean_absolute_error: 0.0138 - val_loss: 4.3095e-04 - val_mean_squared_error: 4.3095e-04 - val_mean_absolute_error: 0.0157\n",
      "Epoch 11/100\n",
      " - 3s - loss: 3.2447e-04 - mean_squared_error: 3.2447e-04 - mean_absolute_error: 0.0133 - val_loss: 3.3849e-04 - val_mean_squared_error: 3.3849e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 12/100\n",
      " - 6s - loss: 3.1518e-04 - mean_squared_error: 3.1518e-04 - mean_absolute_error: 0.0130 - val_loss: 4.4155e-04 - val_mean_squared_error: 4.4155e-04 - val_mean_absolute_error: 0.0156\n",
      "Epoch 13/100\n",
      " - 4s - loss: 3.0689e-04 - mean_squared_error: 3.0689e-04 - mean_absolute_error: 0.0129 - val_loss: 4.0967e-04 - val_mean_squared_error: 4.0967e-04 - val_mean_absolute_error: 0.0150\n",
      "Epoch 14/100\n",
      " - 4s - loss: 2.9861e-04 - mean_squared_error: 2.9861e-04 - mean_absolute_error: 0.0127 - val_loss: 6.0876e-04 - val_mean_squared_error: 6.0876e-04 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/100\n",
      " - 4s - loss: 2.9789e-04 - mean_squared_error: 2.9789e-04 - mean_absolute_error: 0.0127 - val_loss: 3.4802e-04 - val_mean_squared_error: 3.4802e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 16/100\n",
      " - 4s - loss: 2.9983e-04 - mean_squared_error: 2.9983e-04 - mean_absolute_error: 0.0128 - val_loss: 3.8024e-04 - val_mean_squared_error: 3.8024e-04 - val_mean_absolute_error: 0.0146\n",
      "Epoch 00016: early stopping\n",
      "Training data error: 655.76 MSE\n",
      "Test data error: 702.24 MSE\n",
      "Training data error: 22.04 MAE\n",
      "Test data error: 22.81 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26059 samples, validate on 4599 samples\n",
      "Epoch 1/100\n",
      " - 27s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0457 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0329\n",
      "Epoch 2/100\n",
      " - 14s - loss: 0.0015 - mean_squared_error: 0.0015 - mean_absolute_error: 0.0291 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0257\n",
      "Epoch 3/100\n",
      " - 13s - loss: 0.0010 - mean_squared_error: 0.0010 - mean_absolute_error: 0.0245 - val_loss: 0.0013 - val_mean_squared_error: 0.0013 - val_mean_absolute_error: 0.0272\n",
      "Epoch 4/100\n",
      " - 14s - loss: 8.5775e-04 - mean_squared_error: 8.5775e-04 - mean_absolute_error: 0.0223 - val_loss: 0.0016 - val_mean_squared_error: 0.0016 - val_mean_absolute_error: 0.0330\n",
      "Epoch 5/100\n",
      " - 13s - loss: 7.8668e-04 - mean_squared_error: 7.8668e-04 - mean_absolute_error: 0.0213 - val_loss: 9.1250e-04 - val_mean_squared_error: 9.1250e-04 - val_mean_absolute_error: 0.0227\n",
      "Epoch 6/100\n",
      " - 14s - loss: 7.1447e-04 - mean_squared_error: 7.1447e-04 - mean_absolute_error: 0.0203 - val_loss: 6.7610e-04 - val_mean_squared_error: 6.7610e-04 - val_mean_absolute_error: 0.0191\n",
      "Epoch 7/100\n",
      " - 16s - loss: 6.7266e-04 - mean_squared_error: 6.7266e-04 - mean_absolute_error: 0.0196 - val_loss: 8.2983e-04 - val_mean_squared_error: 8.2983e-04 - val_mean_absolute_error: 0.0212\n",
      "Epoch 8/100\n",
      " - 16s - loss: 6.3013e-04 - mean_squared_error: 6.3013e-04 - mean_absolute_error: 0.0191 - val_loss: 0.0010 - val_mean_squared_error: 0.0010 - val_mean_absolute_error: 0.0248\n",
      "Epoch 9/100\n",
      " - 14s - loss: 5.6642e-04 - mean_squared_error: 5.6642e-04 - mean_absolute_error: 0.0180 - val_loss: 6.5419e-04 - val_mean_squared_error: 6.5419e-04 - val_mean_absolute_error: 0.0184\n",
      "Epoch 10/100\n",
      " - 15s - loss: 5.2488e-04 - mean_squared_error: 5.2488e-04 - mean_absolute_error: 0.0173 - val_loss: 9.7425e-04 - val_mean_squared_error: 9.7425e-04 - val_mean_absolute_error: 0.0249\n",
      "Epoch 11/100\n",
      " - 13s - loss: 5.2339e-04 - mean_squared_error: 5.2339e-04 - mean_absolute_error: 0.0173 - val_loss: 9.7126e-04 - val_mean_squared_error: 9.7126e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 12/100\n",
      " - 14s - loss: 5.3928e-04 - mean_squared_error: 5.3928e-04 - mean_absolute_error: 0.0176 - val_loss: 8.6727e-04 - val_mean_squared_error: 8.6727e-04 - val_mean_absolute_error: 0.0221\n",
      "Epoch 13/100\n",
      " - 14s - loss: 4.8628e-04 - mean_squared_error: 4.8628e-04 - mean_absolute_error: 0.0166 - val_loss: 8.0747e-04 - val_mean_squared_error: 8.0747e-04 - val_mean_absolute_error: 0.0205\n",
      "Epoch 14/100\n",
      " - 15s - loss: 4.4866e-04 - mean_squared_error: 4.4866e-04 - mean_absolute_error: 0.0160 - val_loss: 5.6060e-04 - val_mean_squared_error: 5.6060e-04 - val_mean_absolute_error: 0.0172\n",
      "Epoch 15/100\n",
      " - 15s - loss: 4.7270e-04 - mean_squared_error: 4.7270e-04 - mean_absolute_error: 0.0164 - val_loss: 5.4163e-04 - val_mean_squared_error: 5.4163e-04 - val_mean_absolute_error: 0.0169\n",
      "Epoch 16/100\n",
      " - 15s - loss: 4.4381e-04 - mean_squared_error: 4.4381e-04 - mean_absolute_error: 0.0160 - val_loss: 5.7130e-04 - val_mean_squared_error: 5.7130e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 17/100\n",
      " - 14s - loss: 4.0306e-04 - mean_squared_error: 4.0306e-04 - mean_absolute_error: 0.0151 - val_loss: 9.0251e-04 - val_mean_squared_error: 9.0251e-04 - val_mean_absolute_error: 0.0240\n",
      "Epoch 18/100\n",
      " - 13s - loss: 4.2691e-04 - mean_squared_error: 4.2691e-04 - mean_absolute_error: 0.0156 - val_loss: 5.5616e-04 - val_mean_squared_error: 5.5616e-04 - val_mean_absolute_error: 0.0168\n",
      "Epoch 19/100\n",
      " - 14s - loss: 3.6550e-04 - mean_squared_error: 3.6550e-04 - mean_absolute_error: 0.0144 - val_loss: 5.4813e-04 - val_mean_squared_error: 5.4813e-04 - val_mean_absolute_error: 0.0166\n",
      "Epoch 20/100\n",
      " - 14s - loss: 3.9407e-04 - mean_squared_error: 3.9407e-04 - mean_absolute_error: 0.0149 - val_loss: 7.7169e-04 - val_mean_squared_error: 7.7169e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 00020: early stopping\n",
      "Training data error: 913.63 MSE\n",
      "Test data error: 1000.53 MSE\n",
      "Training data error: 27.20 MAE\n",
      "Test data error: 28.39 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 1000\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26847 samples, validate on 4738 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 0.0104 - mean_squared_error: 0.0104 - mean_absolute_error: 0.0730 - val_loss: 0.0069 - val_mean_squared_error: 0.0069 - val_mean_absolute_error: 0.0612\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0049 - mean_squared_error: 0.0049 - mean_absolute_error: 0.0514 - val_loss: 0.0065 - val_mean_squared_error: 0.0065 - val_mean_absolute_error: 0.0583\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0047 - mean_squared_error: 0.0047 - mean_absolute_error: 0.0497 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_mean_absolute_error: 0.0570\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0046 - mean_squared_error: 0.0046 - mean_absolute_error: 0.0490 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_mean_absolute_error: 0.0566\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0045 - mean_squared_error: 0.0045 - mean_absolute_error: 0.0484 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0557\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0480 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0555\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0479 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0553\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0477 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - val_mean_absolute_error: 0.0561\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0474 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0554\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0473 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0551\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0472 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0547\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0469 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0546\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0469 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0552\n",
      "Epoch 14/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0469 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0542\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0468 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0549\n",
      "Epoch 16/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0466 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0541\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0465 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0549\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0464 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0539\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0463 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0547\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0463 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0536\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0463 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0539\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0461 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0539\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0461 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0537\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0460 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0540\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0460 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0554\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0459 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0538\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0459 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0550\n",
      "Epoch 00027: early stopping\n",
      "Training data error: 2546.89 MSE\n",
      "Test data error: 2737.39 MSE\n",
      "Training data error: 42.58 MAE\n",
      "Test data error: 44.11 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26719 samples, validate on 4716 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 0.0085 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0660 - val_loss: 0.0067 - val_mean_squared_error: 0.0067 - val_mean_absolute_error: 0.0596\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0045 - mean_squared_error: 0.0045 - mean_absolute_error: 0.0495 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_mean_absolute_error: 0.0567\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0481 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0562\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0471 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0557\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0041 - mean_squared_error: 0.0041 - mean_absolute_error: 0.0465 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0539\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0040 - mean_squared_error: 0.0040 - mean_absolute_error: 0.0461 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0535\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0040 - mean_squared_error: 0.0040 - mean_absolute_error: 0.0458 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0541\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0454 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0543\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0453 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0541\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0450 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0537\n",
      "Epoch 00010: early stopping\n",
      "Training data error: 2429.30 MSE\n",
      "Test data error: 2700.48 MSE\n",
      "Training data error: 41.68 MAE\n",
      "Test data error: 43.79 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26039 samples, validate on 4596 samples\n",
      "Epoch 1/100\n",
      " - 29s - loss: 0.0072 - mean_squared_error: 0.0072 - mean_absolute_error: 0.0628 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_mean_absolute_error: 0.0596\n",
      "Epoch 2/100\n",
      " - 13s - loss: 0.0046 - mean_squared_error: 0.0046 - mean_absolute_error: 0.0507 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0581\n",
      "Epoch 3/100\n",
      " - 14s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0490 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0572\n",
      "Epoch 4/100\n",
      " - 13s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0483 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0551\n",
      "Epoch 5/100\n",
      " - 14s - loss: 0.0041 - mean_squared_error: 0.0041 - mean_absolute_error: 0.0472 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0558\n",
      "Epoch 6/100\n",
      " - 17s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0464 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0574\n",
      "Epoch 7/100\n",
      " - 14s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0465 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0550\n",
      "Epoch 8/100\n",
      " - 13s - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0454 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0546\n",
      "Epoch 9/100\n",
      " - 12s - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0448 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0558\n",
      "Epoch 10/100\n",
      " - 12s - loss: 0.0036 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0443 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_mean_absolute_error: 0.0646\n",
      "Epoch 11/100\n",
      " - 12s - loss: 0.0036 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0442 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0553\n",
      "Epoch 12/100\n",
      " - 12s - loss: 0.0035 - mean_squared_error: 0.0035 - mean_absolute_error: 0.0436 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0578\n",
      "Epoch 13/100\n",
      " - 12s - loss: 0.0034 - mean_squared_error: 0.0034 - mean_absolute_error: 0.0431 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0543\n",
      "Epoch 14/100\n",
      " - 12s - loss: 0.0034 - mean_squared_error: 0.0034 - mean_absolute_error: 0.0430 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0543\n",
      "Epoch 15/100\n",
      " - 13s - loss: 0.0033 - mean_squared_error: 0.0033 - mean_absolute_error: 0.0425 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0541\n",
      "Epoch 16/100\n",
      " - 13s - loss: 0.0033 - mean_squared_error: 0.0033 - mean_absolute_error: 0.0424 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0554\n",
      "Epoch 17/100\n",
      " - 12s - loss: 0.0032 - mean_squared_error: 0.0032 - mean_absolute_error: 0.0420 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0556\n",
      "Epoch 18/100\n",
      " - 12s - loss: 0.0032 - mean_squared_error: 0.0032 - mean_absolute_error: 0.0417 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0544\n",
      "Epoch 19/100\n",
      " - 14s - loss: 0.0031 - mean_squared_error: 0.0031 - mean_absolute_error: 0.0417 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0569\n",
      "Epoch 00019: early stopping\n",
      "Training data error: 2229.49 MSE\n",
      "Test data error: 3064.17 MSE\n",
      "Training data error: 40.37 MAE\n",
      "Test data error: 46.53 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 1000\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26597 samples, validate on 4694 samples\n",
      "Epoch 1/100\n",
      " - 19s - loss: 0.0132 - mean_squared_error: 0.0132 - mean_absolute_error: 0.0840 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0797\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0084 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0683 - val_loss: 0.0112 - val_mean_squared_error: 0.0112 - val_mean_absolute_error: 0.0796\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0083 - mean_squared_error: 0.0083 - mean_absolute_error: 0.0678 - val_loss: 0.0108 - val_mean_squared_error: 0.0108 - val_mean_absolute_error: 0.0801\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0674 - val_loss: 0.0108 - val_mean_squared_error: 0.0108 - val_mean_absolute_error: 0.0793\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0672 - val_loss: 0.0114 - val_mean_squared_error: 0.0114 - val_mean_absolute_error: 0.0795\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0671 - val_loss: 0.0116 - val_mean_squared_error: 0.0116 - val_mean_absolute_error: 0.0799\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0670 - val_loss: 0.0114 - val_mean_squared_error: 0.0114 - val_mean_absolute_error: 0.0789\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0670 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0795\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0668 - val_loss: 0.0109 - val_mean_squared_error: 0.0109 - val_mean_absolute_error: 0.0790\n",
      "Epoch 00009: early stopping\n",
      "Training data error: 3530.33 MSE\n",
      "Test data error: 4013.92 MSE\n",
      "Training data error: 51.61 MAE\n",
      "Test data error: 54.47 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26342 samples, validate on 4649 samples\n",
      "Epoch 1/100\n",
      " - 31s - loss: 0.0126 - mean_squared_error: 0.0126 - mean_absolute_error: 0.0827 - val_loss: 0.0112 - val_mean_squared_error: 0.0112 - val_mean_absolute_error: 0.0800\n",
      "Epoch 2/100\n",
      " - 9s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0679 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0787\n",
      "Epoch 3/100\n",
      " - 16s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0674 - val_loss: 0.0111 - val_mean_squared_error: 0.0111 - val_mean_absolute_error: 0.0790\n",
      "Epoch 4/100\n",
      " - 15s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0670 - val_loss: 0.0111 - val_mean_squared_error: 0.0111 - val_mean_absolute_error: 0.0790\n",
      "Epoch 5/100\n",
      " - 11s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0665 - val_loss: 0.0112 - val_mean_squared_error: 0.0112 - val_mean_absolute_error: 0.0789\n",
      "Epoch 6/100\n",
      " - 11s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0663 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0783\n",
      "Epoch 7/100\n",
      " - 10s - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0659 - val_loss: 0.0108 - val_mean_squared_error: 0.0108 - val_mean_absolute_error: 0.0779\n",
      "Epoch 8/100\n",
      " - 10s - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0657 - val_loss: 0.0119 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0805\n",
      "Epoch 9/100\n",
      " - 13s - loss: 0.0077 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0654 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0796\n",
      "Epoch 10/100\n",
      " - 11s - loss: 0.0076 - mean_squared_error: 0.0076 - mean_absolute_error: 0.0651 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0782\n",
      "Epoch 11/100\n",
      " - 10s - loss: 0.0075 - mean_squared_error: 0.0075 - mean_absolute_error: 0.0648 - val_loss: 0.0108 - val_mean_squared_error: 0.0108 - val_mean_absolute_error: 0.0787\n",
      "Epoch 12/100\n",
      " - 9s - loss: 0.0074 - mean_squared_error: 0.0074 - mean_absolute_error: 0.0645 - val_loss: 0.0113 - val_mean_squared_error: 0.0113 - val_mean_absolute_error: 0.0796\n",
      "Epoch 00012: early stopping\n",
      "Training data error: 3390.50 MSE\n",
      "Test data error: 4157.22 MSE\n",
      "Training data error: 50.28 MAE\n",
      "Test data error: 55.25 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25917 samples, validate on 4574 samples\n",
      "Epoch 1/100\n",
      " - 29s - loss: 0.0125 - mean_squared_error: 0.0125 - mean_absolute_error: 0.0819 - val_loss: 0.0107 - val_mean_squared_error: 0.0107 - val_mean_absolute_error: 0.0780\n",
      "Epoch 2/100\n",
      " - 15s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0676 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0785\n",
      "Epoch 3/100\n",
      " - 15s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0665 - val_loss: 0.0108 - val_mean_squared_error: 0.0108 - val_mean_absolute_error: 0.0776\n",
      "Epoch 4/100\n",
      " - 14s - loss: 0.0077 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0659 - val_loss: 0.0109 - val_mean_squared_error: 0.0109 - val_mean_absolute_error: 0.0803\n",
      "Epoch 5/100\n",
      " - 16s - loss: 0.0076 - mean_squared_error: 0.0076 - mean_absolute_error: 0.0653 - val_loss: 0.0116 - val_mean_squared_error: 0.0116 - val_mean_absolute_error: 0.0800\n",
      "Epoch 6/100\n",
      " - 14s - loss: 0.0074 - mean_squared_error: 0.0074 - mean_absolute_error: 0.0645 - val_loss: 0.0124 - val_mean_squared_error: 0.0124 - val_mean_absolute_error: 0.0824\n",
      "Epoch 00006: early stopping\n",
      "Training data error: 3463.77 MSE\n",
      "Test data error: 4375.15 MSE\n",
      "Training data error: 50.38 MAE\n",
      "Test data error: 55.91 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 1000\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_nstep_bidir(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        ws_2 = int(window_size/2)\n",
    "        s1 = dataset[i:(i + ws_2), 0]\n",
    "        s2 = dataset[(i + ws_2 + nstep):(i + window_size + nstep), 0]\n",
    "        data_x.append(np.concatenate((s1, s2)))\n",
    "        data_y.append(dataset[(i + ws_2):(i + ws_2 + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset_nstep_bidir(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        ws_2 = int(window_size/2)\n",
    "        s1 = dataset[i:(i + ws_2), 0]\n",
    "        s2 = dataset[(i + ws_2 + nstep):(i + window_size + nstep), 0]\n",
    "        data_x.append(np.concatenate((s1, s2)))\n",
    "        data_y.append(dataset[(i + ws_2):(i + ws_2 + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26866 samples, validate on 4742 samples\n",
      "Epoch 1/100\n",
      " - 24s - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0349 - val_loss: 9.3123e-04 - val_mean_squared_error: 9.3123e-04 - val_mean_absolute_error: 0.0231\n",
      "Epoch 2/100\n",
      " - 5s - loss: 6.1612e-04 - mean_squared_error: 6.1612e-04 - mean_absolute_error: 0.0185 - val_loss: 6.6360e-04 - val_mean_squared_error: 6.6360e-04 - val_mean_absolute_error: 0.0197\n",
      "Epoch 3/100\n",
      " - 5s - loss: 4.6358e-04 - mean_squared_error: 4.6358e-04 - mean_absolute_error: 0.0158 - val_loss: 5.1465e-04 - val_mean_squared_error: 5.1465e-04 - val_mean_absolute_error: 0.0166\n",
      "Epoch 4/100\n",
      " - 5s - loss: 4.1431e-04 - mean_squared_error: 4.1431e-04 - mean_absolute_error: 0.0149 - val_loss: 4.3151e-04 - val_mean_squared_error: 4.3151e-04 - val_mean_absolute_error: 0.0148\n",
      "Epoch 5/100\n",
      " - 4s - loss: 3.6583e-04 - mean_squared_error: 3.6583e-04 - mean_absolute_error: 0.0139 - val_loss: 4.1994e-04 - val_mean_squared_error: 4.1994e-04 - val_mean_absolute_error: 0.0147\n",
      "Epoch 6/100\n",
      " - 5s - loss: 3.4014e-04 - mean_squared_error: 3.4014e-04 - mean_absolute_error: 0.0134 - val_loss: 4.0329e-04 - val_mean_squared_error: 4.0329e-04 - val_mean_absolute_error: 0.0144\n",
      "Epoch 7/100\n",
      " - 5s - loss: 3.2941e-04 - mean_squared_error: 3.2941e-04 - mean_absolute_error: 0.0133 - val_loss: 3.4797e-04 - val_mean_squared_error: 3.4797e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 8/100\n",
      " - 5s - loss: 3.0758e-04 - mean_squared_error: 3.0758e-04 - mean_absolute_error: 0.0128 - val_loss: 4.0508e-04 - val_mean_squared_error: 4.0508e-04 - val_mean_absolute_error: 0.0145\n",
      "Epoch 9/100\n",
      " - 5s - loss: 3.0435e-04 - mean_squared_error: 3.0435e-04 - mean_absolute_error: 0.0127 - val_loss: 4.6312e-04 - val_mean_squared_error: 4.6312e-04 - val_mean_absolute_error: 0.0160\n",
      "Epoch 10/100\n",
      " - 5s - loss: 2.9609e-04 - mean_squared_error: 2.9609e-04 - mean_absolute_error: 0.0126 - val_loss: 4.0294e-04 - val_mean_squared_error: 4.0294e-04 - val_mean_absolute_error: 0.0149\n",
      "Epoch 11/100\n",
      " - 5s - loss: 2.8664e-04 - mean_squared_error: 2.8664e-04 - mean_absolute_error: 0.0124 - val_loss: 3.8230e-04 - val_mean_squared_error: 3.8230e-04 - val_mean_absolute_error: 0.0144\n",
      "Epoch 12/100\n",
      " - 5s - loss: 2.7223e-04 - mean_squared_error: 2.7223e-04 - mean_absolute_error: 0.0120 - val_loss: 4.2823e-04 - val_mean_squared_error: 4.2823e-04 - val_mean_absolute_error: 0.0156\n",
      "Epoch 00012: early stopping\n",
      "Training data error: 688.28 MSE\n",
      "Test data error: 739.65 MSE\n",
      "Training data error: 22.73 MAE\n",
      "Test data error: 23.58 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26824 samples, validate on 4734 samples\n",
      "Epoch 1/100\n",
      " - 22s - loss: 0.0028 - mean_squared_error: 0.0028 - mean_absolute_error: 0.0360 - val_loss: 9.4662e-04 - val_mean_squared_error: 9.4662e-04 - val_mean_absolute_error: 0.0232\n",
      "Epoch 2/100\n",
      " - 6s - loss: 7.2613e-04 - mean_squared_error: 7.2613e-04 - mean_absolute_error: 0.0202 - val_loss: 7.0665e-04 - val_mean_squared_error: 7.0665e-04 - val_mean_absolute_error: 0.0206\n",
      "Epoch 3/100\n",
      " - 7s - loss: 5.4685e-04 - mean_squared_error: 5.4685e-04 - mean_absolute_error: 0.0175 - val_loss: 5.2715e-04 - val_mean_squared_error: 5.2715e-04 - val_mean_absolute_error: 0.0170\n",
      "Epoch 4/100\n",
      " - 6s - loss: 4.8682e-04 - mean_squared_error: 4.8682e-04 - mean_absolute_error: 0.0164 - val_loss: 4.6533e-04 - val_mean_squared_error: 4.6533e-04 - val_mean_absolute_error: 0.0158\n",
      "Epoch 5/100\n",
      " - 7s - loss: 4.1990e-04 - mean_squared_error: 4.1990e-04 - mean_absolute_error: 0.0152 - val_loss: 4.9523e-04 - val_mean_squared_error: 4.9523e-04 - val_mean_absolute_error: 0.0163\n",
      "Epoch 6/100\n",
      " - 6s - loss: 3.9937e-04 - mean_squared_error: 3.9937e-04 - mean_absolute_error: 0.0148 - val_loss: 5.4209e-04 - val_mean_squared_error: 5.4209e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 7/100\n",
      " - 6s - loss: 3.5858e-04 - mean_squared_error: 3.5858e-04 - mean_absolute_error: 0.0140 - val_loss: 3.9728e-04 - val_mean_squared_error: 3.9728e-04 - val_mean_absolute_error: 0.0144\n",
      "Epoch 8/100\n",
      " - 6s - loss: 3.6827e-04 - mean_squared_error: 3.6827e-04 - mean_absolute_error: 0.0143 - val_loss: 7.8074e-04 - val_mean_squared_error: 7.8074e-04 - val_mean_absolute_error: 0.0215\n",
      "Epoch 9/100\n",
      " - 6s - loss: 3.3739e-04 - mean_squared_error: 3.3739e-04 - mean_absolute_error: 0.0135 - val_loss: 4.4464e-04 - val_mean_squared_error: 4.4464e-04 - val_mean_absolute_error: 0.0156\n",
      "Epoch 10/100\n",
      " - 6s - loss: 3.2069e-04 - mean_squared_error: 3.2069e-04 - mean_absolute_error: 0.0132 - val_loss: 3.4906e-04 - val_mean_squared_error: 3.4906e-04 - val_mean_absolute_error: 0.0134\n",
      "Epoch 11/100\n",
      " - 6s - loss: 3.2402e-04 - mean_squared_error: 3.2402e-04 - mean_absolute_error: 0.0133 - val_loss: 4.6217e-04 - val_mean_squared_error: 4.6217e-04 - val_mean_absolute_error: 0.0157\n",
      "Epoch 12/100\n",
      " - 6s - loss: 3.2345e-04 - mean_squared_error: 3.2345e-04 - mean_absolute_error: 0.0133 - val_loss: 5.8297e-04 - val_mean_squared_error: 5.8297e-04 - val_mean_absolute_error: 0.0180\n",
      "Epoch 13/100\n",
      " - 6s - loss: 3.0847e-04 - mean_squared_error: 3.0847e-04 - mean_absolute_error: 0.0130 - val_loss: 3.3085e-04 - val_mean_squared_error: 3.3085e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 14/100\n",
      " - 7s - loss: 3.0294e-04 - mean_squared_error: 3.0294e-04 - mean_absolute_error: 0.0129 - val_loss: 3.4893e-04 - val_mean_squared_error: 3.4893e-04 - val_mean_absolute_error: 0.0136\n",
      "Epoch 15/100\n",
      " - 6s - loss: 2.9217e-04 - mean_squared_error: 2.9217e-04 - mean_absolute_error: 0.0127 - val_loss: 3.4061e-04 - val_mean_squared_error: 3.4061e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 16/100\n",
      " - 5s - loss: 2.9437e-04 - mean_squared_error: 2.9437e-04 - mean_absolute_error: 0.0127 - val_loss: 3.2919e-04 - val_mean_squared_error: 3.2919e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 17/100\n",
      " - 7s - loss: 2.8067e-04 - mean_squared_error: 2.8067e-04 - mean_absolute_error: 0.0124 - val_loss: 3.1604e-04 - val_mean_squared_error: 3.1604e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 18/100\n",
      " - 6s - loss: 2.8202e-04 - mean_squared_error: 2.8202e-04 - mean_absolute_error: 0.0124 - val_loss: 3.3896e-04 - val_mean_squared_error: 3.3896e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 19/100\n",
      " - 5s - loss: 2.8560e-04 - mean_squared_error: 2.8560e-04 - mean_absolute_error: 0.0124 - val_loss: 5.3841e-04 - val_mean_squared_error: 5.3841e-04 - val_mean_absolute_error: 0.0176\n",
      "Epoch 20/100\n",
      " - 6s - loss: 2.7805e-04 - mean_squared_error: 2.7805e-04 - mean_absolute_error: 0.0123 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0286\n",
      "Epoch 21/100\n",
      " - 5s - loss: 2.7562e-04 - mean_squared_error: 2.7562e-04 - mean_absolute_error: 0.0123 - val_loss: 3.0689e-04 - val_mean_squared_error: 3.0689e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 22/100\n",
      " - 7s - loss: 2.7537e-04 - mean_squared_error: 2.7537e-04 - mean_absolute_error: 0.0122 - val_loss: 2.9648e-04 - val_mean_squared_error: 2.9648e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 23/100\n",
      " - 7s - loss: 2.5384e-04 - mean_squared_error: 2.5384e-04 - mean_absolute_error: 0.0117 - val_loss: 3.1560e-04 - val_mean_squared_error: 3.1560e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 24/100\n",
      " - 6s - loss: 2.7034e-04 - mean_squared_error: 2.7034e-04 - mean_absolute_error: 0.0122 - val_loss: 4.4158e-04 - val_mean_squared_error: 4.4158e-04 - val_mean_absolute_error: 0.0166\n",
      "Epoch 25/100\n",
      " - 6s - loss: 2.5470e-04 - mean_squared_error: 2.5470e-04 - mean_absolute_error: 0.0118 - val_loss: 3.5443e-04 - val_mean_squared_error: 3.5443e-04 - val_mean_absolute_error: 0.0142\n",
      "Epoch 26/100\n",
      " - 6s - loss: 2.5856e-04 - mean_squared_error: 2.5856e-04 - mean_absolute_error: 0.0119 - val_loss: 7.0579e-04 - val_mean_squared_error: 7.0579e-04 - val_mean_absolute_error: 0.0206\n",
      "Epoch 27/100\n",
      " - 5s - loss: 2.5604e-04 - mean_squared_error: 2.5604e-04 - mean_absolute_error: 0.0118 - val_loss: 3.4413e-04 - val_mean_squared_error: 3.4413e-04 - val_mean_absolute_error: 0.0139\n",
      "Epoch 00027: early stopping\n",
      "Training data error: 616.46 MSE\n",
      "Test data error: 663.49 MSE\n",
      "Training data error: 21.52 MAE\n",
      "Test data error: 22.34 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26847 samples, validate on 4738 samples\n",
      "Epoch 1/100\n",
      " - 27s - loss: 0.0087 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0661 - val_loss: 0.0065 - val_mean_squared_error: 0.0065 - val_mean_absolute_error: 0.0587\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0047 - mean_squared_error: 0.0047 - mean_absolute_error: 0.0502 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_mean_absolute_error: 0.0572\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0046 - mean_squared_error: 0.0046 - mean_absolute_error: 0.0490 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_mean_absolute_error: 0.0567\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0045 - mean_squared_error: 0.0045 - mean_absolute_error: 0.0485 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0556\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0480 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0555\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0477 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0551\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0475 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0546\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0472 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0547\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0470 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0541\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0468 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0544\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0467 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0544\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0466 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0536\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0465 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0543\n",
      "Epoch 14/100\n",
      " - 5s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0464 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0548\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0462 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0540\n",
      "Epoch 16/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0463 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0536\n",
      "Epoch 17/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0461 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0543\n",
      "Epoch 00017: early stopping\n",
      "Training data error: 2546.81 MSE\n",
      "Test data error: 2737.35 MSE\n",
      "Training data error: 42.70 MAE\n",
      "Test data error: 44.19 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26719 samples, validate on 4716 samples\n",
      "Epoch 1/100\n",
      " - 25s - loss: 0.0073 - mean_squared_error: 0.0073 - mean_absolute_error: 0.0612 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0575\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0487 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0569\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0473 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0547\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.0041 - mean_squared_error: 0.0041 - mean_absolute_error: 0.0465 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0546\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.0040 - mean_squared_error: 0.0040 - mean_absolute_error: 0.0462 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0535\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0455 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0535\n",
      "Epoch 7/100\n",
      " - 8s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0452 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0546\n",
      "Epoch 8/100\n",
      " - 9s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0451 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0533\n",
      "Epoch 9/100\n",
      " - 8s - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0447 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0549\n",
      "Epoch 10/100\n",
      " - 8s - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0448 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0539\n",
      "Epoch 00010: early stopping\n",
      "Training data error: 2426.07 MSE\n",
      "Test data error: 2722.66 MSE\n",
      "Training data error: 41.53 MAE\n",
      "Test data error: 43.78 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26597 samples, validate on 4694 samples\n",
      "Epoch 1/100\n",
      " - 28s - loss: 0.0114 - mean_squared_error: 0.0114 - mean_absolute_error: 0.0781 - val_loss: 0.0111 - val_mean_squared_error: 0.0111 - val_mean_absolute_error: 0.0794\n",
      "Epoch 2/100\n",
      " - 8s - loss: 0.0083 - mean_squared_error: 0.0083 - mean_absolute_error: 0.0677 - val_loss: 0.0112 - val_mean_squared_error: 0.0112 - val_mean_absolute_error: 0.0796\n",
      "Epoch 3/100\n",
      " - 9s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0672 - val_loss: 0.0111 - val_mean_squared_error: 0.0111 - val_mean_absolute_error: 0.0793\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0668 - val_loss: 0.0121 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0815\n",
      "Epoch 5/100\n",
      " - 9s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0666 - val_loss: 0.0114 - val_mean_squared_error: 0.0114 - val_mean_absolute_error: 0.0809\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0665 - val_loss: 0.0121 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0810\n",
      "Epoch 7/100\n",
      " - 8s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0662 - val_loss: 0.0112 - val_mean_squared_error: 0.0112 - val_mean_absolute_error: 0.0798\n",
      "Epoch 8/100\n",
      " - 9s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0660 - val_loss: 0.0132 - val_mean_squared_error: 0.0132 - val_mean_absolute_error: 0.0848\n",
      "Epoch 00008: early stopping\n",
      "Training data error: 3670.45 MSE\n",
      "Test data error: 4209.39 MSE\n",
      "Training data error: 51.76 MAE\n",
      "Test data error: 54.72 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26342 samples, validate on 4649 samples\n",
      "Epoch 1/100\n",
      " - 37s - loss: 0.0112 - mean_squared_error: 0.0112 - mean_absolute_error: 0.0777 - val_loss: 0.0107 - val_mean_squared_error: 0.0107 - val_mean_absolute_error: 0.0790\n",
      "Epoch 2/100\n",
      " - 20s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0676 - val_loss: 0.0114 - val_mean_squared_error: 0.0114 - val_mean_absolute_error: 0.0791\n",
      "Epoch 3/100\n",
      " - 20s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0670 - val_loss: 0.0107 - val_mean_squared_error: 0.0107 - val_mean_absolute_error: 0.0794\n",
      "Epoch 4/100\n",
      " - 19s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0665 - val_loss: 0.0108 - val_mean_squared_error: 0.0108 - val_mean_absolute_error: 0.0784\n",
      "Epoch 5/100\n",
      " - 18s - loss: 0.0077 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0657 - val_loss: 0.0108 - val_mean_squared_error: 0.0108 - val_mean_absolute_error: 0.0792\n",
      "Epoch 6/100\n",
      " - 20s - loss: 0.0077 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0655 - val_loss: 0.0113 - val_mean_squared_error: 0.0113 - val_mean_absolute_error: 0.0790\n",
      "Epoch 00006: early stopping\n",
      "Training data error: 3426.25 MSE\n",
      "Test data error: 4100.67 MSE\n",
      "Training data error: 50.45 MAE\n",
      "Test data error: 54.66 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26866 samples, validate on 4742 samples\n",
      "Epoch 1/100\n",
      " - 35s - loss: 0.0012 - mean_squared_error: 0.0012 - mean_absolute_error: 0.0216 - val_loss: 3.1007e-04 - val_mean_squared_error: 3.1007e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 2/100\n",
      " - 7s - loss: 1.9599e-04 - mean_squared_error: 1.9599e-04 - mean_absolute_error: 0.0105 - val_loss: 2.6108e-04 - val_mean_squared_error: 2.6108e-04 - val_mean_absolute_error: 0.0123\n",
      "Epoch 3/100\n",
      " - 7s - loss: 1.3397e-04 - mean_squared_error: 1.3397e-04 - mean_absolute_error: 0.0087 - val_loss: 1.3561e-04 - val_mean_squared_error: 1.3561e-04 - val_mean_absolute_error: 0.0083\n",
      "Epoch 4/100\n",
      " - 7s - loss: 1.0455e-04 - mean_squared_error: 1.0455e-04 - mean_absolute_error: 0.0075 - val_loss: 1.0703e-04 - val_mean_squared_error: 1.0703e-04 - val_mean_absolute_error: 0.0072\n",
      "Epoch 5/100\n",
      " - 7s - loss: 9.1152e-05 - mean_squared_error: 9.1152e-05 - mean_absolute_error: 0.0071 - val_loss: 1.3149e-04 - val_mean_squared_error: 1.3149e-04 - val_mean_absolute_error: 0.0087\n",
      "Epoch 6/100\n",
      " - 7s - loss: 7.7831e-05 - mean_squared_error: 7.7831e-05 - mean_absolute_error: 0.0065 - val_loss: 9.0706e-05 - val_mean_squared_error: 9.0706e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 7/100\n",
      " - 7s - loss: 7.3454e-05 - mean_squared_error: 7.3454e-05 - mean_absolute_error: 0.0063 - val_loss: 1.2194e-04 - val_mean_squared_error: 1.2194e-04 - val_mean_absolute_error: 0.0082\n",
      "Epoch 8/100\n",
      " - 6s - loss: 7.9117e-05 - mean_squared_error: 7.9117e-05 - mean_absolute_error: 0.0066 - val_loss: 9.5477e-05 - val_mean_squared_error: 9.5477e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 9/100\n",
      " - 7s - loss: 6.5649e-05 - mean_squared_error: 6.5649e-05 - mean_absolute_error: 0.0060 - val_loss: 8.6588e-05 - val_mean_squared_error: 8.6588e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 10/100\n",
      " - 6s - loss: 6.3541e-05 - mean_squared_error: 6.3541e-05 - mean_absolute_error: 0.0059 - val_loss: 9.3207e-05 - val_mean_squared_error: 9.3207e-05 - val_mean_absolute_error: 0.0069\n",
      "Epoch 11/100\n",
      " - 8s - loss: 6.7478e-05 - mean_squared_error: 6.7478e-05 - mean_absolute_error: 0.0061 - val_loss: 9.2099e-05 - val_mean_squared_error: 9.2099e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 12/100\n",
      " - 7s - loss: 6.2537e-05 - mean_squared_error: 6.2537e-05 - mean_absolute_error: 0.0059 - val_loss: 6.7934e-05 - val_mean_squared_error: 6.7934e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 13/100\n",
      " - 7s - loss: 6.2269e-05 - mean_squared_error: 6.2269e-05 - mean_absolute_error: 0.0059 - val_loss: 1.0132e-04 - val_mean_squared_error: 1.0132e-04 - val_mean_absolute_error: 0.0074\n",
      "Epoch 14/100\n",
      " - 7s - loss: 5.8454e-05 - mean_squared_error: 5.8454e-05 - mean_absolute_error: 0.0056 - val_loss: 7.1771e-05 - val_mean_squared_error: 7.1771e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 15/100\n",
      " - 7s - loss: 5.8770e-05 - mean_squared_error: 5.8770e-05 - mean_absolute_error: 0.0057 - val_loss: 8.1645e-05 - val_mean_squared_error: 8.1645e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 16/100\n",
      " - 7s - loss: 5.7913e-05 - mean_squared_error: 5.7913e-05 - mean_absolute_error: 0.0056 - val_loss: 6.5774e-05 - val_mean_squared_error: 6.5774e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 17/100\n",
      " - 7s - loss: 5.8721e-05 - mean_squared_error: 5.8721e-05 - mean_absolute_error: 0.0057 - val_loss: 1.0885e-04 - val_mean_squared_error: 1.0885e-04 - val_mean_absolute_error: 0.0081\n",
      "Epoch 18/100\n",
      " - 6s - loss: 5.7755e-05 - mean_squared_error: 5.7755e-05 - mean_absolute_error: 0.0056 - val_loss: 8.1477e-05 - val_mean_squared_error: 8.1477e-05 - val_mean_absolute_error: 0.0065\n",
      "Epoch 19/100\n",
      " - 7s - loss: 5.4065e-05 - mean_squared_error: 5.4065e-05 - mean_absolute_error: 0.0054 - val_loss: 6.9955e-05 - val_mean_squared_error: 6.9955e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 20/100\n",
      " - 7s - loss: 5.5827e-05 - mean_squared_error: 5.5827e-05 - mean_absolute_error: 0.0055 - val_loss: 6.5387e-05 - val_mean_squared_error: 6.5387e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 21/100\n",
      " - 6s - loss: 5.4263e-05 - mean_squared_error: 5.4263e-05 - mean_absolute_error: 0.0054 - val_loss: 8.8250e-05 - val_mean_squared_error: 8.8250e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 22/100\n",
      " - 7s - loss: 5.9229e-05 - mean_squared_error: 5.9229e-05 - mean_absolute_error: 0.0057 - val_loss: 6.5408e-05 - val_mean_squared_error: 6.5408e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 23/100\n",
      " - 7s - loss: 5.5367e-05 - mean_squared_error: 5.5367e-05 - mean_absolute_error: 0.0055 - val_loss: 6.4424e-05 - val_mean_squared_error: 6.4424e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 24/100\n",
      " - 8s - loss: 5.1962e-05 - mean_squared_error: 5.1962e-05 - mean_absolute_error: 0.0053 - val_loss: 1.5868e-04 - val_mean_squared_error: 1.5868e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 25/100\n",
      " - 6s - loss: 5.4788e-05 - mean_squared_error: 5.4788e-05 - mean_absolute_error: 0.0055 - val_loss: 8.3262e-05 - val_mean_squared_error: 8.3262e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 26/100\n",
      " - 6s - loss: 5.3205e-05 - mean_squared_error: 5.3205e-05 - mean_absolute_error: 0.0054 - val_loss: 6.1113e-05 - val_mean_squared_error: 6.1113e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 27/100\n",
      " - 6s - loss: 5.3118e-05 - mean_squared_error: 5.3118e-05 - mean_absolute_error: 0.0054 - val_loss: 1.3451e-04 - val_mean_squared_error: 1.3451e-04 - val_mean_absolute_error: 0.0089\n",
      "Epoch 28/100\n",
      " - 6s - loss: 5.3754e-05 - mean_squared_error: 5.3754e-05 - mean_absolute_error: 0.0054 - val_loss: 6.5128e-05 - val_mean_squared_error: 6.5128e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 29/100\n",
      " - 6s - loss: 5.3713e-05 - mean_squared_error: 5.3713e-05 - mean_absolute_error: 0.0054 - val_loss: 6.2706e-05 - val_mean_squared_error: 6.2706e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 30/100\n",
      " - 6s - loss: 5.3359e-05 - mean_squared_error: 5.3359e-05 - mean_absolute_error: 0.0054 - val_loss: 9.1908e-05 - val_mean_squared_error: 9.1908e-05 - val_mean_absolute_error: 0.0074\n",
      "Epoch 31/100\n",
      " - 6s - loss: 5.2253e-05 - mean_squared_error: 5.2253e-05 - mean_absolute_error: 0.0053 - val_loss: 1.8450e-04 - val_mean_squared_error: 1.8450e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 00031: early stopping\n",
      "Training data error: 457.51 MSE\n",
      "Test data error: 484.20 MSE\n",
      "Training data error: 19.72 MAE\n",
      "Test data error: 20.22 MAE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26824 samples, validate on 4734 samples\n",
      "Epoch 1/100\n",
      " - 26s - loss: 0.0015 - mean_squared_error: 0.0015 - mean_absolute_error: 0.0237 - val_loss: 3.5814e-04 - val_mean_squared_error: 3.5814e-04 - val_mean_absolute_error: 0.0143\n",
      "Epoch 2/100\n",
      " - 6s - loss: 2.2665e-04 - mean_squared_error: 2.2665e-04 - mean_absolute_error: 0.0112 - val_loss: 2.1280e-04 - val_mean_squared_error: 2.1280e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 3/100\n",
      " - 7s - loss: 1.6277e-04 - mean_squared_error: 1.6277e-04 - mean_absolute_error: 0.0095 - val_loss: 1.9647e-04 - val_mean_squared_error: 1.9647e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 4/100\n",
      " - 8s - loss: 1.2985e-04 - mean_squared_error: 1.2985e-04 - mean_absolute_error: 0.0084 - val_loss: 1.3444e-04 - val_mean_squared_error: 1.3444e-04 - val_mean_absolute_error: 0.0082\n",
      "Epoch 5/100\n",
      " - 8s - loss: 1.1322e-04 - mean_squared_error: 1.1322e-04 - mean_absolute_error: 0.0079 - val_loss: 1.1486e-04 - val_mean_squared_error: 1.1486e-04 - val_mean_absolute_error: 0.0075\n",
      "Epoch 6/100\n",
      " - 7s - loss: 9.9063e-05 - mean_squared_error: 9.9063e-05 - mean_absolute_error: 0.0074 - val_loss: 1.5227e-04 - val_mean_squared_error: 1.5227e-04 - val_mean_absolute_error: 0.0088\n",
      "Epoch 7/100\n",
      " - 6s - loss: 1.0017e-04 - mean_squared_error: 1.0017e-04 - mean_absolute_error: 0.0074 - val_loss: 9.4297e-05 - val_mean_squared_error: 9.4297e-05 - val_mean_absolute_error: 0.0067\n",
      "Epoch 8/100\n",
      " - 6s - loss: 9.4330e-05 - mean_squared_error: 9.4330e-05 - mean_absolute_error: 0.0072 - val_loss: 1.0525e-04 - val_mean_squared_error: 1.0525e-04 - val_mean_absolute_error: 0.0073\n",
      "Epoch 9/100\n",
      " - 7s - loss: 8.4354e-05 - mean_squared_error: 8.4354e-05 - mean_absolute_error: 0.0068 - val_loss: 1.1301e-04 - val_mean_squared_error: 1.1301e-04 - val_mean_absolute_error: 0.0078\n",
      "Epoch 10/100\n",
      " - 7s - loss: 8.0045e-05 - mean_squared_error: 8.0045e-05 - mean_absolute_error: 0.0066 - val_loss: 8.8456e-05 - val_mean_squared_error: 8.8456e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 11/100\n",
      " - 7s - loss: 8.2296e-05 - mean_squared_error: 8.2296e-05 - mean_absolute_error: 0.0067 - val_loss: 8.3924e-05 - val_mean_squared_error: 8.3924e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 12/100\n",
      " - 6s - loss: 7.1102e-05 - mean_squared_error: 7.1102e-05 - mean_absolute_error: 0.0062 - val_loss: 7.7304e-05 - val_mean_squared_error: 7.7304e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 13/100\n",
      " - 7s - loss: 7.4714e-05 - mean_squared_error: 7.4714e-05 - mean_absolute_error: 0.0064 - val_loss: 7.7990e-05 - val_mean_squared_error: 7.7990e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 14/100\n",
      " - 6s - loss: 7.1923e-05 - mean_squared_error: 7.1923e-05 - mean_absolute_error: 0.0063 - val_loss: 1.5371e-04 - val_mean_squared_error: 1.5371e-04 - val_mean_absolute_error: 0.0092\n",
      "Epoch 15/100\n",
      " - 6s - loss: 6.8252e-05 - mean_squared_error: 6.8252e-05 - mean_absolute_error: 0.0061 - val_loss: 7.9367e-05 - val_mean_squared_error: 7.9367e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 16/100\n",
      " - 7s - loss: 6.7828e-05 - mean_squared_error: 6.7828e-05 - mean_absolute_error: 0.0061 - val_loss: 1.6265e-04 - val_mean_squared_error: 1.6265e-04 - val_mean_absolute_error: 0.0099\n",
      "Epoch 17/100\n",
      " - 8s - loss: 7.5680e-05 - mean_squared_error: 7.5680e-05 - mean_absolute_error: 0.0065 - val_loss: 8.6154e-05 - val_mean_squared_error: 8.6154e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 00017: early stopping\n",
      "Training data error: 311.22 MSE\n",
      "Test data error: 330.07 MSE\n",
      "Training data error: 15.30 MAE\n",
      "Test data error: 15.86 MAE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26847 samples, validate on 4738 samples\n",
      "Epoch 1/100\n",
      " - 32s - loss: 0.0063 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0536 - val_loss: 0.0041 - val_mean_squared_error: 0.0041 - val_mean_absolute_error: 0.0456\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0373 - val_loss: 0.0036 - val_mean_squared_error: 0.0036 - val_mean_absolute_error: 0.0425\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0025 - mean_squared_error: 0.0025 - mean_absolute_error: 0.0356 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0407\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0348 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0402\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0342 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0400\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0338 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0400\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0335 - val_loss: 0.0031 - val_mean_squared_error: 0.0031 - val_mean_absolute_error: 0.0386\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0332 - val_loss: 0.0031 - val_mean_squared_error: 0.0031 - val_mean_absolute_error: 0.0386\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0330 - val_loss: 0.0031 - val_mean_squared_error: 0.0031 - val_mean_absolute_error: 0.0384\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0330 - val_loss: 0.0031 - val_mean_squared_error: 0.0031 - val_mean_absolute_error: 0.0387\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0327 - val_loss: 0.0032 - val_mean_squared_error: 0.0032 - val_mean_absolute_error: 0.0388\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0327 - val_loss: 0.0031 - val_mean_squared_error: 0.0031 - val_mean_absolute_error: 0.0384\n",
      "Epoch 13/100\n",
      " - 6s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0326 - val_loss: 0.0030 - val_mean_squared_error: 0.0030 - val_mean_absolute_error: 0.0386\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0323 - val_loss: 0.0030 - val_mean_squared_error: 0.0030 - val_mean_absolute_error: 0.0375\n",
      "Epoch 15/100\n",
      " - 8s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0323 - val_loss: 0.0030 - val_mean_squared_error: 0.0030 - val_mean_absolute_error: 0.0372\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0322 - val_loss: 0.0030 - val_mean_squared_error: 0.0030 - val_mean_absolute_error: 0.0375\n",
      "Epoch 17/100\n",
      " - 6s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0320 - val_loss: 0.0030 - val_mean_squared_error: 0.0030 - val_mean_absolute_error: 0.0374\n",
      "Epoch 18/100\n",
      " - 6s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0320 - val_loss: 0.0029 - val_mean_squared_error: 0.0029 - val_mean_absolute_error: 0.0368\n",
      "Epoch 19/100\n",
      " - 6s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0318 - val_loss: 0.0029 - val_mean_squared_error: 0.0029 - val_mean_absolute_error: 0.0374\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0319 - val_loss: 0.0030 - val_mean_squared_error: 0.0030 - val_mean_absolute_error: 0.0382\n",
      "Epoch 21/100\n",
      " - 6s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0318 - val_loss: 0.0029 - val_mean_squared_error: 0.0029 - val_mean_absolute_error: 0.0369\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0318 - val_loss: 0.0029 - val_mean_squared_error: 0.0029 - val_mean_absolute_error: 0.0368\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0317 - val_loss: 0.0029 - val_mean_squared_error: 0.0029 - val_mean_absolute_error: 0.0373\n",
      "Epoch 24/100\n",
      " - 7s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0316 - val_loss: 0.0029 - val_mean_squared_error: 0.0029 - val_mean_absolute_error: 0.0367\n",
      "Epoch 25/100\n",
      " - 6s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0318 - val_loss: 0.0030 - val_mean_squared_error: 0.0030 - val_mean_absolute_error: 0.0373\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0316 - val_loss: 0.0028 - val_mean_squared_error: 0.0028 - val_mean_absolute_error: 0.0363\n",
      "Epoch 27/100\n",
      " - 7s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0316 - val_loss: 0.0029 - val_mean_squared_error: 0.0029 - val_mean_absolute_error: 0.0365\n",
      "Epoch 28/100\n",
      " - 7s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0315 - val_loss: 0.0029 - val_mean_squared_error: 0.0029 - val_mean_absolute_error: 0.0367\n",
      "Epoch 29/100\n",
      " - 12s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0314 - val_loss: 0.0030 - val_mean_squared_error: 0.0030 - val_mean_absolute_error: 0.0376\n",
      "Epoch 30/100\n",
      " - 8s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0314 - val_loss: 0.0029 - val_mean_squared_error: 0.0029 - val_mean_absolute_error: 0.0368\n",
      "Epoch 31/100\n",
      " - 7s - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0313 - val_loss: 0.0029 - val_mean_squared_error: 0.0029 - val_mean_absolute_error: 0.0370\n",
      "Epoch 00031: early stopping\n",
      "Training data error: 1781.94 MSE\n",
      "Test data error: 1950.23 MSE\n",
      "Training data error: 35.12 MAE\n",
      "Test data error: 36.83 MAE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26719 samples, validate on 4716 samples\n",
      "Epoch 1/100\n",
      " - 31s - loss: 0.0050 - mean_squared_error: 0.0050 - mean_absolute_error: 0.0499 - val_loss: 0.0041 - val_mean_squared_error: 0.0041 - val_mean_absolute_error: 0.0461\n",
      "Epoch 2/100\n",
      " - 8s - loss: 0.0028 - mean_squared_error: 0.0028 - mean_absolute_error: 0.0385 - val_loss: 0.0038 - val_mean_squared_error: 0.0038 - val_mean_absolute_error: 0.0439\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.0026 - mean_squared_error: 0.0026 - mean_absolute_error: 0.0369 - val_loss: 0.0037 - val_mean_squared_error: 0.0037 - val_mean_absolute_error: 0.0425\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.0025 - mean_squared_error: 0.0025 - mean_absolute_error: 0.0359 - val_loss: 0.0035 - val_mean_squared_error: 0.0035 - val_mean_absolute_error: 0.0423\n",
      "Epoch 5/100\n",
      " - 10s - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0352 - val_loss: 0.0034 - val_mean_squared_error: 0.0034 - val_mean_absolute_error: 0.0410\n",
      "Epoch 6/100\n",
      " - 10s - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0348 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0404\n",
      "Epoch 7/100\n",
      " - 9s - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0344 - val_loss: 0.0034 - val_mean_squared_error: 0.0034 - val_mean_absolute_error: 0.0421\n",
      "Epoch 8/100\n",
      " - 10s - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0341 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0396\n",
      "Epoch 9/100\n",
      " - 11s - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0341 - val_loss: 0.0032 - val_mean_squared_error: 0.0032 - val_mean_absolute_error: 0.0394\n",
      "Epoch 10/100\n",
      " - 9s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0337 - val_loss: 0.0032 - val_mean_squared_error: 0.0032 - val_mean_absolute_error: 0.0400\n",
      "Epoch 11/100\n",
      " - 11s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0335 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0402\n",
      "Epoch 12/100\n",
      " - 10s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0334 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0409\n",
      "Epoch 13/100\n",
      " - 9s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0331 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0399\n",
      "Epoch 14/100\n",
      " - 10s - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0329 - val_loss: 0.0032 - val_mean_squared_error: 0.0032 - val_mean_absolute_error: 0.0403\n",
      "Epoch 00014: early stopping\n",
      "Training data error: 1863.56 MSE\n",
      "Test data error: 2054.10 MSE\n",
      "Training data error: 36.66 MAE\n",
      "Test data error: 38.57 MAE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26597 samples, validate on 4694 samples\n",
      "Epoch 1/100\n",
      " - 47s - loss: 0.0100 - mean_squared_error: 0.0100 - mean_absolute_error: 0.0724 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_mean_absolute_error: 0.0698\n",
      "Epoch 2/100\n",
      " - 13s - loss: 0.0066 - mean_squared_error: 0.0066 - mean_absolute_error: 0.0598 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_mean_absolute_error: 0.0719\n",
      "Epoch 3/100\n",
      " - 13s - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0593 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_mean_absolute_error: 0.0687\n",
      "Epoch 4/100\n",
      " - 13s - loss: 0.0064 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0590 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_mean_absolute_error: 0.0697\n",
      "Epoch 5/100\n",
      " - 12s - loss: 0.0063 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0585 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_mean_absolute_error: 0.0692\n",
      "Epoch 6/100\n",
      " - 14s - loss: 0.0063 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0583 - val_loss: 0.0086 - val_mean_squared_error: 0.0086 - val_mean_absolute_error: 0.0677\n",
      "Epoch 7/100\n",
      " - 12s - loss: 0.0062 - mean_squared_error: 0.0062 - mean_absolute_error: 0.0581 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_mean_absolute_error: 0.0683\n",
      "Epoch 8/100\n",
      " - 11s - loss: 0.0062 - mean_squared_error: 0.0062 - mean_absolute_error: 0.0578 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_mean_absolute_error: 0.0678\n",
      "Epoch 9/100\n",
      " - 11s - loss: 0.0061 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0575 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_mean_absolute_error: 0.0681\n",
      "Epoch 10/100\n",
      " - 11s - loss: 0.0061 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0573 - val_loss: 0.0086 - val_mean_squared_error: 0.0086 - val_mean_absolute_error: 0.0683\n",
      "Epoch 11/100\n",
      " - 10s - loss: 0.0060 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0572 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_mean_absolute_error: 0.0690\n",
      "Epoch 00011: early stopping\n",
      "Training data error: 3074.85 MSE\n",
      "Test data error: 3735.12 MSE\n",
      "Training data error: 47.80 MAE\n",
      "Test data error: 52.07 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26342 samples, validate on 4649 samples\n",
      "Epoch 1/100\n",
      " - 51s - loss: 0.0097 - mean_squared_error: 0.0097 - mean_absolute_error: 0.0711 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_mean_absolute_error: 0.0708\n",
      "Epoch 2/100\n",
      " - 25s - loss: 0.0064 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0594 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_mean_absolute_error: 0.0731\n",
      "Epoch 3/100\n",
      " - 21s - loss: 0.0062 - mean_squared_error: 0.0062 - mean_absolute_error: 0.0585 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_mean_absolute_error: 0.0697\n",
      "Epoch 4/100\n",
      " - 21s - loss: 0.0061 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0581 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_mean_absolute_error: 0.0709\n",
      "Epoch 5/100\n",
      " - 23s - loss: 0.0060 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0574 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_mean_absolute_error: 0.0706\n",
      "Epoch 6/100\n",
      " - 22s - loss: 0.0059 - mean_squared_error: 0.0059 - mean_absolute_error: 0.0569 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_mean_absolute_error: 0.0696\n",
      "Epoch 7/100\n",
      " - 21s - loss: 0.0058 - mean_squared_error: 0.0058 - mean_absolute_error: 0.0566 - val_loss: 0.0091 - val_mean_squared_error: 0.0091 - val_mean_absolute_error: 0.0706\n",
      "Epoch 8/100\n",
      " - 22s - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0561 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_mean_absolute_error: 0.0694\n",
      "Epoch 9/100\n",
      " - 22s - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0560 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_mean_absolute_error: 0.0721\n",
      "Epoch 10/100\n",
      " - 21s - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0556 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_mean_absolute_error: 0.0742\n",
      "Epoch 11/100\n",
      " - 22s - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0555 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_mean_absolute_error: 0.0699\n",
      "Epoch 00011: early stopping\n",
      "Training data error: 2972.87 MSE\n",
      "Test data error: 3750.16 MSE\n",
      "Training data error: 46.97 MAE\n",
      "Test data error: 52.29 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25488 samples, validate on 4499 samples\n",
      "Epoch 1/100\n",
      " - 59s - loss: 0.0123 - mean_squared_error: 0.0123 - mean_absolute_error: 0.0828 - val_loss: 0.0159 - val_mean_squared_error: 0.0159 - val_mean_absolute_error: 0.0930\n",
      "Epoch 2/100\n",
      " - 41s - loss: 0.0093 - mean_squared_error: 0.0093 - mean_absolute_error: 0.0728 - val_loss: 0.0159 - val_mean_squared_error: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 3/100\n",
      " - 39s - loss: 0.0089 - mean_squared_error: 0.0089 - mean_absolute_error: 0.0711 - val_loss: 0.0176 - val_mean_squared_error: 0.0176 - val_mean_absolute_error: 0.0957\n",
      "Epoch 4/100\n",
      " - 43s - loss: 0.0085 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0695 - val_loss: 0.0167 - val_mean_squared_error: 0.0167 - val_mean_absolute_error: 0.0938\n",
      "Epoch 5/100\n",
      " - 48s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0684 - val_loss: 0.0169 - val_mean_squared_error: 0.0169 - val_mean_absolute_error: 0.0942\n",
      "Epoch 6/100\n",
      " - 48s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0675 - val_loss: 0.0176 - val_mean_squared_error: 0.0176 - val_mean_absolute_error: 0.0961\n",
      "Epoch 7/100\n",
      " - 43s - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0667 - val_loss: 0.0170 - val_mean_squared_error: 0.0170 - val_mean_absolute_error: 0.0950\n",
      "Epoch 00007: early stopping\n",
      "Training data error: 3638.86 MSE\n",
      "Test data error: 4781.51 MSE\n",
      "Training data error: 51.74 MAE\n",
      "Test data error: 58.33 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 1000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25488 samples, validate on 4499 samples\n",
      "Epoch 1/100\n",
      " - 67s - loss: 0.0110 - mean_squared_error: 0.0110 - mean_absolute_error: 0.0776 - val_loss: 0.0130 - val_mean_squared_error: 0.0130 - val_mean_absolute_error: 0.0863\n",
      "Epoch 2/100\n",
      " - 41s - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0664 - val_loss: 0.0132 - val_mean_squared_error: 0.0132 - val_mean_absolute_error: 0.0862\n",
      "Epoch 3/100\n",
      " - 44s - loss: 0.0075 - mean_squared_error: 0.0075 - mean_absolute_error: 0.0649 - val_loss: 0.0131 - val_mean_squared_error: 0.0131 - val_mean_absolute_error: 0.0854\n",
      "Epoch 4/100\n",
      " - 43s - loss: 0.0073 - mean_squared_error: 0.0073 - mean_absolute_error: 0.0642 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_mean_absolute_error: 0.0874\n",
      "Epoch 5/100\n",
      " - 37s - loss: 0.0071 - mean_squared_error: 0.0071 - mean_absolute_error: 0.0635 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_mean_absolute_error: 0.0868\n",
      "Epoch 6/100\n",
      " - 41s - loss: 0.0069 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0625 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_mean_absolute_error: 0.0882\n",
      "Epoch 00006: early stopping\n",
      "Training data error: 3377.55 MSE\n",
      "Test data error: 4175.15 MSE\n",
      "Training data error: 50.23 MAE\n",
      "Test data error: 55.80 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 1000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22938 samples, validate on 4049 samples\n",
      "Epoch 1/100\n",
      " - 83s - loss: 0.0145 - mean_squared_error: 0.0145 - mean_absolute_error: 0.0906 - val_loss: 0.0118 - val_mean_squared_error: 0.0118 - val_mean_absolute_error: 0.0816\n",
      "Epoch 2/100\n",
      " - 53s - loss: 0.0087 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0701 - val_loss: 0.0129 - val_mean_squared_error: 0.0129 - val_mean_absolute_error: 0.0861\n",
      "Epoch 3/100\n",
      " - 62s - loss: 0.0077 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0658 - val_loss: 0.0124 - val_mean_squared_error: 0.0124 - val_mean_absolute_error: 0.0856\n",
      "Epoch 4/100\n",
      " - 58s - loss: 0.0071 - mean_squared_error: 0.0071 - mean_absolute_error: 0.0634 - val_loss: 0.0125 - val_mean_squared_error: 0.0125 - val_mean_absolute_error: 0.0854\n",
      "Epoch 5/100\n",
      " - 56s - loss: 0.0068 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0621 - val_loss: 0.0135 - val_mean_squared_error: 0.0135 - val_mean_absolute_error: 0.0892\n",
      "Epoch 6/100\n",
      " - 52s - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0609 - val_loss: 0.0135 - val_mean_squared_error: 0.0135 - val_mean_absolute_error: 0.0901\n",
      "Epoch 00006: early stopping\n",
      "Training data error: 3285.21 MSE\n",
      "Test data error: 4060.50 MSE\n",
      "Training data error: 49.78 MAE\n",
      "Test data error: 55.41 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 4000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22938 samples, validate on 4049 samples\n",
      "Epoch 1/100\n",
      " - 81s - loss: 0.0119 - mean_squared_error: 0.0119 - mean_absolute_error: 0.0804 - val_loss: 0.0178 - val_mean_squared_error: 0.0178 - val_mean_absolute_error: 0.1009\n",
      "Epoch 2/100\n",
      " - 56s - loss: 0.0074 - mean_squared_error: 0.0074 - mean_absolute_error: 0.0649 - val_loss: 0.0173 - val_mean_squared_error: 0.0173 - val_mean_absolute_error: 0.0997\n",
      "Epoch 3/100\n",
      " - 56s - loss: 0.0069 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0626 - val_loss: 0.0180 - val_mean_squared_error: 0.0180 - val_mean_absolute_error: 0.1021\n",
      "Epoch 4/100\n",
      " - 55s - loss: 0.0064 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0604 - val_loss: 0.0180 - val_mean_squared_error: 0.0180 - val_mean_absolute_error: 0.1021\n",
      "Epoch 5/100\n",
      " - 60s - loss: 0.0061 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0588 - val_loss: 0.0176 - val_mean_squared_error: 0.0176 - val_mean_absolute_error: 0.1009\n",
      "Epoch 6/100\n",
      " - 58s - loss: 0.0058 - mean_squared_error: 0.0058 - mean_absolute_error: 0.0578 - val_loss: 0.0184 - val_mean_squared_error: 0.0184 - val_mean_absolute_error: 0.1034\n",
      "Epoch 7/100\n",
      " - 62s - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0570 - val_loss: 0.0180 - val_mean_squared_error: 0.0180 - val_mean_absolute_error: 0.1021\n",
      "Epoch 00007: early stopping\n",
      "Training data error: 3300.41 MSE\n",
      "Test data error: 5087.82 MSE\n",
      "Training data error: 49.36 MAE\n",
      "Test data error: 62.29 MAE\n"
     ]
    }
   ],
   "source": [
    "window_size = 4000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26866 samples, validate on 4742 samples\n",
      "Epoch 1/100\n",
      " - 32s - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0357 - val_loss: 9.2737e-04 - val_mean_squared_error: 9.2737e-04 - val_mean_absolute_error: 0.0232\n",
      "Epoch 2/100\n",
      " - 6s - loss: 6.5833e-04 - mean_squared_error: 6.5833e-04 - mean_absolute_error: 0.0193 - val_loss: 6.9477e-04 - val_mean_squared_error: 6.9477e-04 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/100\n",
      " - 4s - loss: 5.1451e-04 - mean_squared_error: 5.1451e-04 - mean_absolute_error: 0.0169 - val_loss: 7.0256e-04 - val_mean_squared_error: 7.0256e-04 - val_mean_absolute_error: 0.0199\n",
      "Epoch 4/100\n",
      " - 5s - loss: 4.2764e-04 - mean_squared_error: 4.2764e-04 - mean_absolute_error: 0.0153 - val_loss: 4.2966e-04 - val_mean_squared_error: 4.2966e-04 - val_mean_absolute_error: 0.0151\n",
      "Epoch 5/100\n",
      " - 4s - loss: 3.7507e-04 - mean_squared_error: 3.7507e-04 - mean_absolute_error: 0.0142 - val_loss: 6.3646e-04 - val_mean_squared_error: 6.3646e-04 - val_mean_absolute_error: 0.0196\n",
      "Epoch 6/100\n",
      " - 5s - loss: 3.6462e-04 - mean_squared_error: 3.6462e-04 - mean_absolute_error: 0.0141 - val_loss: 4.2865e-04 - val_mean_squared_error: 4.2865e-04 - val_mean_absolute_error: 0.0152\n",
      "Epoch 7/100\n",
      " - 4s - loss: 3.2813e-04 - mean_squared_error: 3.2813e-04 - mean_absolute_error: 0.0133 - val_loss: 5.3683e-04 - val_mean_squared_error: 5.3683e-04 - val_mean_absolute_error: 0.0172\n",
      "Epoch 8/100\n",
      " - 4s - loss: 3.3243e-04 - mean_squared_error: 3.3243e-04 - mean_absolute_error: 0.0135 - val_loss: 4.7789e-04 - val_mean_squared_error: 4.7789e-04 - val_mean_absolute_error: 0.0167\n",
      "Epoch 9/100\n",
      " - 4s - loss: 3.0862e-04 - mean_squared_error: 3.0862e-04 - mean_absolute_error: 0.0129 - val_loss: 3.2933e-04 - val_mean_squared_error: 3.2933e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 10/100\n",
      " - 4s - loss: 2.9470e-04 - mean_squared_error: 2.9470e-04 - mean_absolute_error: 0.0125 - val_loss: 3.3423e-04 - val_mean_squared_error: 3.3423e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 11/100\n",
      " - 5s - loss: 2.8342e-04 - mean_squared_error: 2.8342e-04 - mean_absolute_error: 0.0123 - val_loss: 4.7721e-04 - val_mean_squared_error: 4.7721e-04 - val_mean_absolute_error: 0.0166\n",
      "Epoch 12/100\n",
      " - 5s - loss: 2.9337e-04 - mean_squared_error: 2.9337e-04 - mean_absolute_error: 0.0125 - val_loss: 4.0267e-04 - val_mean_squared_error: 4.0267e-04 - val_mean_absolute_error: 0.0145\n",
      "Epoch 13/100\n",
      " - 4s - loss: 2.7936e-04 - mean_squared_error: 2.7936e-04 - mean_absolute_error: 0.0122 - val_loss: 6.2966e-04 - val_mean_squared_error: 6.2966e-04 - val_mean_absolute_error: 0.0203\n",
      "Epoch 14/100\n",
      " - 4s - loss: 2.8336e-04 - mean_squared_error: 2.8336e-04 - mean_absolute_error: 0.0123 - val_loss: 3.0942e-04 - val_mean_squared_error: 3.0942e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 15/100\n",
      " - 5s - loss: 2.7682e-04 - mean_squared_error: 2.7682e-04 - mean_absolute_error: 0.0122 - val_loss: 3.2087e-04 - val_mean_squared_error: 3.2087e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 16/100\n",
      " - 4s - loss: 2.7569e-04 - mean_squared_error: 2.7569e-04 - mean_absolute_error: 0.0121 - val_loss: 3.1740e-04 - val_mean_squared_error: 3.1740e-04 - val_mean_absolute_error: 0.0127\n",
      "Epoch 17/100\n",
      " - 4s - loss: 2.6484e-04 - mean_squared_error: 2.6484e-04 - mean_absolute_error: 0.0118 - val_loss: 3.5452e-04 - val_mean_squared_error: 3.5452e-04 - val_mean_absolute_error: 0.0136\n",
      "Epoch 18/100\n",
      " - 4s - loss: 2.6430e-04 - mean_squared_error: 2.6430e-04 - mean_absolute_error: 0.0119 - val_loss: 2.9634e-04 - val_mean_squared_error: 2.9634e-04 - val_mean_absolute_error: 0.0121\n",
      "Epoch 19/100\n",
      " - 4s - loss: 2.6815e-04 - mean_squared_error: 2.6815e-04 - mean_absolute_error: 0.0120 - val_loss: 3.3703e-04 - val_mean_squared_error: 3.3703e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 20/100\n",
      " - 4s - loss: 2.6018e-04 - mean_squared_error: 2.6018e-04 - mean_absolute_error: 0.0118 - val_loss: 3.3066e-04 - val_mean_squared_error: 3.3066e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 21/100\n",
      " - 4s - loss: 2.5850e-04 - mean_squared_error: 2.5850e-04 - mean_absolute_error: 0.0117 - val_loss: 3.0073e-04 - val_mean_squared_error: 3.0073e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 22/100\n",
      " - 4s - loss: 2.5394e-04 - mean_squared_error: 2.5394e-04 - mean_absolute_error: 0.0116 - val_loss: 4.5433e-04 - val_mean_squared_error: 4.5433e-04 - val_mean_absolute_error: 0.0162\n",
      "Epoch 23/100\n",
      " - 4s - loss: 2.5169e-04 - mean_squared_error: 2.5169e-04 - mean_absolute_error: 0.0116 - val_loss: 4.6452e-04 - val_mean_squared_error: 4.6452e-04 - val_mean_absolute_error: 0.0161\n",
      "Epoch 00023: early stopping\n",
      "Training data error: 699.08 MSE\n",
      "Test data error: 753.37 MSE\n",
      "Training data error: 22.89 MAE\n",
      "Test data error: 23.83 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26824 samples, validate on 4734 samples\n",
      "Epoch 1/100\n",
      " - 33s - loss: 0.0017 - mean_squared_error: 0.0017 - mean_absolute_error: 0.0301 - val_loss: 0.0011 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0252\n",
      "Epoch 2/100\n",
      " - 5s - loss: 6.6078e-04 - mean_squared_error: 6.6078e-04 - mean_absolute_error: 0.0193 - val_loss: 9.3446e-04 - val_mean_squared_error: 9.3446e-04 - val_mean_absolute_error: 0.0242\n",
      "Epoch 3/100\n",
      " - 5s - loss: 5.3856e-04 - mean_squared_error: 5.3856e-04 - mean_absolute_error: 0.0174 - val_loss: 5.0615e-04 - val_mean_squared_error: 5.0615e-04 - val_mean_absolute_error: 0.0168\n",
      "Epoch 4/100\n",
      " - 5s - loss: 4.6107e-04 - mean_squared_error: 4.6107e-04 - mean_absolute_error: 0.0159 - val_loss: 4.8904e-04 - val_mean_squared_error: 4.8904e-04 - val_mean_absolute_error: 0.0162\n",
      "Epoch 5/100\n",
      " - 5s - loss: 4.1876e-04 - mean_squared_error: 4.1876e-04 - mean_absolute_error: 0.0151 - val_loss: 4.2357e-04 - val_mean_squared_error: 4.2357e-04 - val_mean_absolute_error: 0.0149\n",
      "Epoch 6/100\n",
      " - 5s - loss: 3.8240e-04 - mean_squared_error: 3.8240e-04 - mean_absolute_error: 0.0144 - val_loss: 4.9038e-04 - val_mean_squared_error: 4.9038e-04 - val_mean_absolute_error: 0.0170\n",
      "Epoch 7/100\n",
      " - 5s - loss: 4.0970e-04 - mean_squared_error: 4.0970e-04 - mean_absolute_error: 0.0150 - val_loss: 4.3306e-04 - val_mean_squared_error: 4.3306e-04 - val_mean_absolute_error: 0.0152\n",
      "Epoch 8/100\n",
      " - 5s - loss: 3.4653e-04 - mean_squared_error: 3.4653e-04 - mean_absolute_error: 0.0137 - val_loss: 5.4463e-04 - val_mean_squared_error: 5.4463e-04 - val_mean_absolute_error: 0.0184\n",
      "Epoch 9/100\n",
      " - 5s - loss: 3.3121e-04 - mean_squared_error: 3.3121e-04 - mean_absolute_error: 0.0134 - val_loss: 3.8648e-04 - val_mean_squared_error: 3.8648e-04 - val_mean_absolute_error: 0.0146\n",
      "Epoch 10/100\n",
      " - 6s - loss: 3.4938e-04 - mean_squared_error: 3.4938e-04 - mean_absolute_error: 0.0138 - val_loss: 3.5221e-04 - val_mean_squared_error: 3.5221e-04 - val_mean_absolute_error: 0.0137\n",
      "Epoch 11/100\n",
      " - 5s - loss: 3.1623e-04 - mean_squared_error: 3.1623e-04 - mean_absolute_error: 0.0131 - val_loss: 3.4378e-04 - val_mean_squared_error: 3.4378e-04 - val_mean_absolute_error: 0.0134\n",
      "Epoch 12/100\n",
      " - 5s - loss: 3.1790e-04 - mean_squared_error: 3.1790e-04 - mean_absolute_error: 0.0132 - val_loss: 3.5415e-04 - val_mean_squared_error: 3.5415e-04 - val_mean_absolute_error: 0.0139\n",
      "Epoch 13/100\n",
      " - 5s - loss: 3.1549e-04 - mean_squared_error: 3.1549e-04 - mean_absolute_error: 0.0131 - val_loss: 6.4922e-04 - val_mean_squared_error: 6.4922e-04 - val_mean_absolute_error: 0.0197\n",
      "Epoch 14/100\n",
      " - 5s - loss: 3.0622e-04 - mean_squared_error: 3.0622e-04 - mean_absolute_error: 0.0129 - val_loss: 3.6397e-04 - val_mean_squared_error: 3.6397e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 15/100\n",
      " - 5s - loss: 3.1014e-04 - mean_squared_error: 3.1014e-04 - mean_absolute_error: 0.0130 - val_loss: 3.4419e-04 - val_mean_squared_error: 3.4419e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 16/100\n",
      " - 5s - loss: 3.0018e-04 - mean_squared_error: 3.0018e-04 - mean_absolute_error: 0.0127 - val_loss: 5.8751e-04 - val_mean_squared_error: 5.8751e-04 - val_mean_absolute_error: 0.0187\n",
      "Epoch 00016: early stopping\n",
      "Training data error: 803.77 MSE\n",
      "Test data error: 854.61 MSE\n",
      "Training data error: 25.00 MAE\n",
      "Test data error: 25.74 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26847 samples, validate on 4738 samples\n",
      "Epoch 1/100\n",
      " - 32s - loss: 0.0102 - mean_squared_error: 0.0102 - mean_absolute_error: 0.0704 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_mean_absolute_error: 0.0591\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - mean_absolute_error: 0.0504 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_mean_absolute_error: 0.0578\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0046 - mean_squared_error: 0.0046 - mean_absolute_error: 0.0492 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_mean_absolute_error: 0.0569\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0045 - mean_squared_error: 0.0045 - mean_absolute_error: 0.0487 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_mean_absolute_error: 0.0574\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0045 - mean_squared_error: 0.0045 - mean_absolute_error: 0.0482 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0556\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0480 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_mean_absolute_error: 0.0565\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0479 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0553\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0477 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0550\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0476 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0545\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0474 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0551\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0474 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_mean_absolute_error: 0.0551\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0474 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0543\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0471 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0541\n",
      "Epoch 14/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0471 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0553\n",
      "Epoch 15/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0470 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0539\n",
      "Epoch 16/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0467 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0543\n",
      "Epoch 17/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0468 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_mean_absolute_error: 0.0548\n",
      "Epoch 18/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0468 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0537\n",
      "Epoch 19/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0466 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0543\n",
      "Epoch 20/100\n",
      " - 4s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0467 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0543\n",
      "Epoch 21/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0464 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0540\n",
      "Epoch 22/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0464 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0540\n",
      "Epoch 23/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0463 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0543\n",
      "Epoch 24/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0463 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0535\n",
      "Epoch 25/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0463 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0542\n",
      "Epoch 26/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0463 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0540\n",
      "Epoch 27/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0462 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0539\n",
      "Epoch 28/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0462 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0548\n",
      "Epoch 29/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0460 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0534\n",
      "Epoch 30/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0461 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0531\n",
      "Epoch 31/100\n",
      " - 4s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0461 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0537\n",
      "Epoch 00031: early stopping\n",
      "Training data error: 2535.07 MSE\n",
      "Test data error: 2733.19 MSE\n",
      "Training data error: 42.15 MAE\n",
      "Test data error: 43.73 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26719 samples, validate on 4716 samples\n",
      "Epoch 1/100\n",
      " - 37s - loss: 0.0075 - mean_squared_error: 0.0075 - mean_absolute_error: 0.0630 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_mean_absolute_error: 0.0588\n",
      "Epoch 2/100\n",
      " - 8s - loss: 0.0045 - mean_squared_error: 0.0045 - mean_absolute_error: 0.0494 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0552\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0481 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0556\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0472 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0552\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.0041 - mean_squared_error: 0.0041 - mean_absolute_error: 0.0467 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0538\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.0040 - mean_squared_error: 0.0040 - mean_absolute_error: 0.0461 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0532\n",
      "Epoch 7/100\n",
      " - 8s - loss: 0.0040 - mean_squared_error: 0.0040 - mean_absolute_error: 0.0461 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0538\n",
      "Epoch 8/100\n",
      " - 9s - loss: 0.0040 - mean_squared_error: 0.0040 - mean_absolute_error: 0.0457 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0533\n",
      "Epoch 9/100\n",
      " - 8s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0454 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0556\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0454 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0526\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0452 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0536\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0450 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0560\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0448 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0516\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0446 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0539\n",
      "Epoch 15/100\n",
      " - 6s - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0447 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0519\n",
      "Epoch 00015: early stopping\n",
      "Training data error: 2404.36 MSE\n",
      "Test data error: 2668.59 MSE\n",
      "Training data error: 41.31 MAE\n",
      "Test data error: 43.45 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26597 samples, validate on 4694 samples\n",
      "Epoch 1/100\n",
      " - 36s - loss: 0.0128 - mean_squared_error: 0.0128 - mean_absolute_error: 0.0826 - val_loss: 0.0115 - val_mean_squared_error: 0.0115 - val_mean_absolute_error: 0.0803\n",
      "Epoch 2/100\n",
      " - 8s - loss: 0.0083 - mean_squared_error: 0.0083 - mean_absolute_error: 0.0681 - val_loss: 0.0109 - val_mean_squared_error: 0.0109 - val_mean_absolute_error: 0.0802\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0677 - val_loss: 0.0123 - val_mean_squared_error: 0.0123 - val_mean_absolute_error: 0.0820\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0675 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0787\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0673 - val_loss: 0.0109 - val_mean_squared_error: 0.0109 - val_mean_absolute_error: 0.0785\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0672 - val_loss: 0.0115 - val_mean_squared_error: 0.0115 - val_mean_absolute_error: 0.0794\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0670 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0790\n",
      "Epoch 00007: early stopping\n",
      "Training data error: 3527.94 MSE\n",
      "Test data error: 4005.74 MSE\n",
      "Training data error: 51.37 MAE\n",
      "Test data error: 54.17 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26342 samples, validate on 4649 samples\n",
      "Epoch 1/100\n",
      " - 47s - loss: 0.0123 - mean_squared_error: 0.0123 - mean_absolute_error: 0.0815 - val_loss: 0.0116 - val_mean_squared_error: 0.0116 - val_mean_absolute_error: 0.0805\n",
      "Epoch 2/100\n",
      " - 16s - loss: 0.0083 - mean_squared_error: 0.0083 - mean_absolute_error: 0.0681 - val_loss: 0.0111 - val_mean_squared_error: 0.0111 - val_mean_absolute_error: 0.0790\n",
      "Epoch 3/100\n",
      " - 17s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0675 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0787\n",
      "Epoch 4/100\n",
      " - 16s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0671 - val_loss: 0.0111 - val_mean_squared_error: 0.0111 - val_mean_absolute_error: 0.0789\n",
      "Epoch 5/100\n",
      " - 16s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0669 - val_loss: 0.0107 - val_mean_squared_error: 0.0107 - val_mean_absolute_error: 0.0786\n",
      "Epoch 6/100\n",
      " - 12s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0667 - val_loss: 0.0106 - val_mean_squared_error: 0.0106 - val_mean_absolute_error: 0.0777\n",
      "Epoch 7/100\n",
      " - 12s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0666 - val_loss: 0.0113 - val_mean_squared_error: 0.0113 - val_mean_absolute_error: 0.0792\n",
      "Epoch 8/100\n",
      " - 12s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0664 - val_loss: 0.0109 - val_mean_squared_error: 0.0109 - val_mean_absolute_error: 0.0808\n",
      "Epoch 9/100\n",
      " - 12s - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0661 - val_loss: 0.0115 - val_mean_squared_error: 0.0115 - val_mean_absolute_error: 0.0797\n",
      "Epoch 10/100\n",
      " - 13s - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0659 - val_loss: 0.0112 - val_mean_squared_error: 0.0112 - val_mean_absolute_error: 0.0788\n",
      "Epoch 11/100\n",
      " - 13s - loss: 0.0077 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0657 - val_loss: 0.0111 - val_mean_squared_error: 0.0111 - val_mean_absolute_error: 0.0798\n",
      "Epoch 00011: early stopping\n",
      "Training data error: 3496.78 MSE\n",
      "Test data error: 4128.64 MSE\n",
      "Training data error: 51.39 MAE\n",
      "Test data error: 55.38 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariable LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2004</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1     2     3     4     5     6     7     8     9     10    11\n",
       "2004 1 1 1  46.0  38.0  44.0  45.0  42.0  44.0  45.0  43.0  41.0  42.0  36.0\n",
       "         2  46.0  36.0  42.0  43.0  42.0  43.0  44.0  44.0  39.0  43.0  32.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = r\"../../Data/temperature_history.csv\"\n",
    "df_T = pd.read_csv(PATH)\n",
    "h_df_T = df_T.set_index(['station_id', 'year', 'month', 'day'])\n",
    "trans_dict = {}\n",
    "for i in list(h_df_T.columns):\n",
    "    trans_dict[i] = int(i[1:])\n",
    "h_df_T = h_df_T.rename(columns=trans_dict)\n",
    "h_df_T = h_df_T.stack()\n",
    "h_df_T = h_df_T.unstack(level=0)\n",
    "h_df_T.columns = h_df_T.columns.get_level_values(0)\n",
    "h_df_T.columns.names = [None]\n",
    "h_df_T.index.names = [None, None, None, None]\n",
    "\n",
    "PATH = r\"../../Data/temperature_solution.csv\"\n",
    "df_T_Sol = pd.read_csv(PATH)\n",
    "h_df_T_Sol = df_T_Sol.set_index(['station_id', 'year', 'month', 'day', 'hour'])\n",
    "h_df_T_Sol = h_df_T_Sol.drop(['datetime', 'date'], axis=1)\n",
    "h_df_T_Sol = h_df_T_Sol.unstack(level=0)\n",
    "h_df_T_Sol.columns = h_df_T_Sol.columns.get_level_values(1)\n",
    "h_df_T_Sol.columns.names = [None]\n",
    "h_df_T_Sol.index.names = [None, None, None, None]\n",
    "\n",
    "zone_T = pd.concat([h_df_T, h_df_T_Sol], axis=0, join='outer', ignore_index=False, keys=None, \n",
    "          levels=None, names=None, verify_integrity=True, copy=True)\n",
    "\n",
    "T_mean = zone_T.mean(axis=1)\n",
    "#temp['T'] = T_mean\n",
    "temp['T'] = pd.Series(np.concatenate([T_mean[:12].values, T_mean[0:-12].values]) , index = (T_mean.index))\n",
    "\n",
    "zone_T.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x00000171610CCE88>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x00000171062A3948>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp[[1, 'T']].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples training set: 31660\n",
      "Number of samples test set: 7916\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(temp[[1, 'T']])\n",
    "\n",
    "# Using 80% of data for training, 20% for validation.\n",
    "TRAINING_PERCENT = 0.80\n",
    "\n",
    "train_size = int(len(scaled) * TRAINING_PERCENT)\n",
    "test_size = len(scaled) - train_size\n",
    "train_multi, test_multi = scaled[0:train_size, :], scaled[train_size:len(scaled), :]\n",
    "print(\"Number of samples training set: \" + str((len(train_multi))))\n",
    "print(\"Number of samples test set: \" + str((len(test_multi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_nstep_multi(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        sample = dataset[i:(i + window_size), :]\n",
    "        data_x.append(sample)\n",
    "        data_y.append(dataset[(i + window_size):(i + window_size + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26866 samples, validate on 4742 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - mean_absolute_error: 0.0361 - val_loss: 9.8162e-04 - val_mean_squared_error: 9.8162e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 2/100\n",
      " - 3s - loss: 6.5035e-04 - mean_squared_error: 6.5035e-04 - mean_absolute_error: 0.0192 - val_loss: 6.4304e-04 - val_mean_squared_error: 6.4304e-04 - val_mean_absolute_error: 0.0189\n",
      "Epoch 3/100\n",
      " - 2s - loss: 4.9880e-04 - mean_squared_error: 4.9880e-04 - mean_absolute_error: 0.0167 - val_loss: 5.0857e-04 - val_mean_squared_error: 5.0857e-04 - val_mean_absolute_error: 0.0165\n",
      "Epoch 4/100\n",
      " - 3s - loss: 4.1988e-04 - mean_squared_error: 4.1988e-04 - mean_absolute_error: 0.0152 - val_loss: 4.7597e-04 - val_mean_squared_error: 4.7597e-04 - val_mean_absolute_error: 0.0162\n",
      "Epoch 5/100\n",
      " - 2s - loss: 3.7865e-04 - mean_squared_error: 3.7865e-04 - mean_absolute_error: 0.0144 - val_loss: 3.9658e-04 - val_mean_squared_error: 3.9658e-04 - val_mean_absolute_error: 0.0142\n",
      "Epoch 6/100\n",
      " - 2s - loss: 3.5855e-04 - mean_squared_error: 3.5855e-04 - mean_absolute_error: 0.0140 - val_loss: 4.1097e-04 - val_mean_squared_error: 4.1097e-04 - val_mean_absolute_error: 0.0148\n",
      "Epoch 7/100\n",
      " - 2s - loss: 3.4328e-04 - mean_squared_error: 3.4328e-04 - mean_absolute_error: 0.0138 - val_loss: 3.6064e-04 - val_mean_squared_error: 3.6064e-04 - val_mean_absolute_error: 0.0136\n",
      "Epoch 8/100\n",
      " - 4s - loss: 3.1236e-04 - mean_squared_error: 3.1236e-04 - mean_absolute_error: 0.0130 - val_loss: 4.1034e-04 - val_mean_squared_error: 4.1034e-04 - val_mean_absolute_error: 0.0151\n",
      "Epoch 9/100\n",
      " - 2s - loss: 3.1103e-04 - mean_squared_error: 3.1103e-04 - mean_absolute_error: 0.0131 - val_loss: 3.4290e-04 - val_mean_squared_error: 3.4290e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 10/100\n",
      " - 2s - loss: 3.0690e-04 - mean_squared_error: 3.0690e-04 - mean_absolute_error: 0.0130 - val_loss: 3.3590e-04 - val_mean_squared_error: 3.3590e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 11/100\n",
      " - 2s - loss: 2.9244e-04 - mean_squared_error: 2.9244e-04 - mean_absolute_error: 0.0126 - val_loss: 3.3641e-04 - val_mean_squared_error: 3.3641e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 12/100\n",
      " - 3s - loss: 2.8230e-04 - mean_squared_error: 2.8230e-04 - mean_absolute_error: 0.0124 - val_loss: 4.0160e-04 - val_mean_squared_error: 4.0160e-04 - val_mean_absolute_error: 0.0154\n",
      "Epoch 13/100\n",
      " - 3s - loss: 2.7738e-04 - mean_squared_error: 2.7738e-04 - mean_absolute_error: 0.0123 - val_loss: 3.4078e-04 - val_mean_squared_error: 3.4078e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 14/100\n",
      " - 3s - loss: 2.7545e-04 - mean_squared_error: 2.7545e-04 - mean_absolute_error: 0.0122 - val_loss: 3.3397e-04 - val_mean_squared_error: 3.3397e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 15/100\n",
      " - 2s - loss: 2.7188e-04 - mean_squared_error: 2.7188e-04 - mean_absolute_error: 0.0122 - val_loss: 3.1316e-04 - val_mean_squared_error: 3.1316e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 16/100\n",
      " - 2s - loss: 2.7100e-04 - mean_squared_error: 2.7100e-04 - mean_absolute_error: 0.0122 - val_loss: 3.5280e-04 - val_mean_squared_error: 3.5280e-04 - val_mean_absolute_error: 0.0140\n",
      "Epoch 17/100\n",
      " - 2s - loss: 2.6173e-04 - mean_squared_error: 2.6173e-04 - mean_absolute_error: 0.0120 - val_loss: 3.6565e-04 - val_mean_squared_error: 3.6565e-04 - val_mean_absolute_error: 0.0143\n",
      "Epoch 18/100\n",
      " - 2s - loss: 2.6318e-04 - mean_squared_error: 2.6318e-04 - mean_absolute_error: 0.0120 - val_loss: 3.0635e-04 - val_mean_squared_error: 3.0635e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 19/100\n",
      " - 2s - loss: 2.5277e-04 - mean_squared_error: 2.5277e-04 - mean_absolute_error: 0.0117 - val_loss: 4.7808e-04 - val_mean_squared_error: 4.7808e-04 - val_mean_absolute_error: 0.0173\n",
      "Epoch 20/100\n",
      " - 2s - loss: 2.5483e-04 - mean_squared_error: 2.5483e-04 - mean_absolute_error: 0.0118 - val_loss: 3.2098e-04 - val_mean_squared_error: 3.2098e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 21/100\n",
      " - 2s - loss: 2.5332e-04 - mean_squared_error: 2.5332e-04 - mean_absolute_error: 0.0117 - val_loss: 5.4176e-04 - val_mean_squared_error: 5.4176e-04 - val_mean_absolute_error: 0.0185\n",
      "Epoch 22/100\n",
      " - 2s - loss: 2.5896e-04 - mean_squared_error: 2.5896e-04 - mean_absolute_error: 0.0119 - val_loss: 3.5272e-04 - val_mean_squared_error: 3.5272e-04 - val_mean_absolute_error: 0.0140\n",
      "Epoch 23/100\n",
      " - 2s - loss: 2.4309e-04 - mean_squared_error: 2.4309e-04 - mean_absolute_error: 0.0114 - val_loss: 3.3565e-04 - val_mean_squared_error: 3.3565e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 00023: early stopping\n",
      "Training data error: 606.47 MSE\n",
      "Test data error: 645.50 MSE\n",
      "Training data error: 21.05 MAE\n",
      "Test data error: 21.78 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26824 samples, validate on 4734 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - mean_absolute_error: 0.0351 - val_loss: 0.0011 - val_mean_squared_error: 0.0011 - val_mean_absolute_error: 0.0247\n",
      "Epoch 2/100\n",
      " - 2s - loss: 8.1269e-04 - mean_squared_error: 8.1269e-04 - mean_absolute_error: 0.0217 - val_loss: 0.0013 - val_mean_squared_error: 0.0013 - val_mean_absolute_error: 0.0284\n",
      "Epoch 3/100\n",
      " - 2s - loss: 5.9710e-04 - mean_squared_error: 5.9710e-04 - mean_absolute_error: 0.0184 - val_loss: 9.8194e-04 - val_mean_squared_error: 9.8194e-04 - val_mean_absolute_error: 0.0255\n",
      "Epoch 4/100\n",
      " - 2s - loss: 5.2769e-04 - mean_squared_error: 5.2769e-04 - mean_absolute_error: 0.0174 - val_loss: 6.7101e-04 - val_mean_squared_error: 6.7101e-04 - val_mean_absolute_error: 0.0199\n",
      "Epoch 5/100\n",
      " - 2s - loss: 4.6346e-04 - mean_squared_error: 4.6346e-04 - mean_absolute_error: 0.0162 - val_loss: 4.5102e-04 - val_mean_squared_error: 4.5102e-04 - val_mean_absolute_error: 0.0158\n",
      "Epoch 6/100\n",
      " - 2s - loss: 4.2423e-04 - mean_squared_error: 4.2423e-04 - mean_absolute_error: 0.0154 - val_loss: 4.3144e-04 - val_mean_squared_error: 4.3144e-04 - val_mean_absolute_error: 0.0154\n",
      "Epoch 7/100\n",
      " - 2s - loss: 3.8416e-04 - mean_squared_error: 3.8416e-04 - mean_absolute_error: 0.0147 - val_loss: 3.8119e-04 - val_mean_squared_error: 3.8119e-04 - val_mean_absolute_error: 0.0145\n",
      "Epoch 8/100\n",
      " - 2s - loss: 3.7244e-04 - mean_squared_error: 3.7244e-04 - mean_absolute_error: 0.0145 - val_loss: 6.2551e-04 - val_mean_squared_error: 6.2551e-04 - val_mean_absolute_error: 0.0195\n",
      "Epoch 9/100\n",
      " - 2s - loss: 3.5113e-04 - mean_squared_error: 3.5113e-04 - mean_absolute_error: 0.0140 - val_loss: 3.5370e-04 - val_mean_squared_error: 3.5370e-04 - val_mean_absolute_error: 0.0139\n",
      "Epoch 10/100\n",
      " - 3s - loss: 3.3360e-04 - mean_squared_error: 3.3360e-04 - mean_absolute_error: 0.0136 - val_loss: 3.5313e-04 - val_mean_squared_error: 3.5313e-04 - val_mean_absolute_error: 0.0136\n",
      "Epoch 11/100\n",
      " - 3s - loss: 3.1641e-04 - mean_squared_error: 3.1641e-04 - mean_absolute_error: 0.0133 - val_loss: 3.4587e-04 - val_mean_squared_error: 3.4587e-04 - val_mean_absolute_error: 0.0136\n",
      "Epoch 12/100\n",
      " - 3s - loss: 3.2192e-04 - mean_squared_error: 3.2192e-04 - mean_absolute_error: 0.0135 - val_loss: 4.8469e-04 - val_mean_squared_error: 4.8469e-04 - val_mean_absolute_error: 0.0168\n",
      "Epoch 13/100\n",
      " - 2s - loss: 3.0118e-04 - mean_squared_error: 3.0118e-04 - mean_absolute_error: 0.0130 - val_loss: 3.6135e-04 - val_mean_squared_error: 3.6135e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 14/100\n",
      " - 3s - loss: 3.0522e-04 - mean_squared_error: 3.0522e-04 - mean_absolute_error: 0.0131 - val_loss: 4.8793e-04 - val_mean_squared_error: 4.8793e-04 - val_mean_absolute_error: 0.0174\n",
      "Epoch 15/100\n",
      " - 3s - loss: 2.9345e-04 - mean_squared_error: 2.9345e-04 - mean_absolute_error: 0.0128 - val_loss: 7.2693e-04 - val_mean_squared_error: 7.2693e-04 - val_mean_absolute_error: 0.0223\n",
      "Epoch 16/100\n",
      " - 3s - loss: 2.8642e-04 - mean_squared_error: 2.8642e-04 - mean_absolute_error: 0.0127 - val_loss: 3.4376e-04 - val_mean_squared_error: 3.4376e-04 - val_mean_absolute_error: 0.0137\n",
      "Epoch 17/100\n",
      " - 3s - loss: 2.8844e-04 - mean_squared_error: 2.8844e-04 - mean_absolute_error: 0.0127 - val_loss: 3.1328e-04 - val_mean_squared_error: 3.1328e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 18/100\n",
      " - 3s - loss: 2.7343e-04 - mean_squared_error: 2.7343e-04 - mean_absolute_error: 0.0124 - val_loss: 5.2631e-04 - val_mean_squared_error: 5.2631e-04 - val_mean_absolute_error: 0.0185\n",
      "Epoch 19/100\n",
      " - 3s - loss: 2.6582e-04 - mean_squared_error: 2.6582e-04 - mean_absolute_error: 0.0122 - val_loss: 6.2081e-04 - val_mean_squared_error: 6.2081e-04 - val_mean_absolute_error: 0.0203\n",
      "Epoch 20/100\n",
      " - 2s - loss: 2.7011e-04 - mean_squared_error: 2.7011e-04 - mean_absolute_error: 0.0123 - val_loss: 5.1749e-04 - val_mean_squared_error: 5.1749e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 21/100\n",
      " - 3s - loss: 2.7152e-04 - mean_squared_error: 2.7152e-04 - mean_absolute_error: 0.0123 - val_loss: 3.9912e-04 - val_mean_squared_error: 3.9912e-04 - val_mean_absolute_error: 0.0151\n",
      "Epoch 22/100\n",
      " - 3s - loss: 2.5899e-04 - mean_squared_error: 2.5899e-04 - mean_absolute_error: 0.0120 - val_loss: 3.8411e-04 - val_mean_squared_error: 3.8411e-04 - val_mean_absolute_error: 0.0152\n",
      "Epoch 00022: early stopping\n",
      "Training data error: 690.44 MSE\n",
      "Test data error: 722.18 MSE\n",
      "Training data error: 23.31 MAE\n",
      "Test data error: 23.73 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26847 samples, validate on 4738 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.0119 - mean_squared_error: 0.0119 - mean_absolute_error: 0.0773 - val_loss: 0.0070 - val_mean_squared_error: 0.0070 - val_mean_absolute_error: 0.0614\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0048 - mean_squared_error: 0.0048 - mean_absolute_error: 0.0511 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_mean_absolute_error: 0.0568\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0045 - mean_squared_error: 0.0045 - mean_absolute_error: 0.0488 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0555\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0481 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0550\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0475 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0551\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0470 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0548\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0042 - mean_squared_error: 0.0042 - mean_absolute_error: 0.0467 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_mean_absolute_error: 0.0545\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0041 - mean_squared_error: 0.0041 - mean_absolute_error: 0.0463 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0533\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0040 - mean_squared_error: 0.0040 - mean_absolute_error: 0.0460 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0524\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0040 - mean_squared_error: 0.0040 - mean_absolute_error: 0.0455 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0530\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0453 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0521\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0451 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0526\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0448 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0519\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0447 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0517\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0444 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0524\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0443 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0514\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0440 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0521\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0439 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0511\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0437 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0518\n",
      "Epoch 20/100\n",
      " - 4s - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0437 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0516\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0436 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0521\n",
      "Epoch 00021: early stopping\n",
      "Training data error: 2392.40 MSE\n",
      "Test data error: 2606.74 MSE\n",
      "Training data error: 41.47 MAE\n",
      "Test data error: 43.16 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26719 samples, validate on 4716 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0104 - mean_squared_error: 0.0104 - mean_absolute_error: 0.0726 - val_loss: 0.0069 - val_mean_squared_error: 0.0069 - val_mean_absolute_error: 0.0637\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.0047 - mean_squared_error: 0.0047 - mean_absolute_error: 0.0511 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0579\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0043 - mean_squared_error: 0.0043 - mean_absolute_error: 0.0487 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0547\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0041 - mean_squared_error: 0.0041 - mean_absolute_error: 0.0474 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0541\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.0041 - mean_squared_error: 0.0041 - mean_absolute_error: 0.0469 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0534\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.0040 - mean_squared_error: 0.0040 - mean_absolute_error: 0.0464 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0528\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0039 - mean_squared_error: 0.0039 - mean_absolute_error: 0.0455 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0524\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0450 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0532\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0449 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0541\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0443 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0523\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0036 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0442 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0525\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0036 - mean_squared_error: 0.0036 - mean_absolute_error: 0.0436 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0527\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.0035 - mean_squared_error: 0.0035 - mean_absolute_error: 0.0434 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0517\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.0035 - mean_squared_error: 0.0035 - mean_absolute_error: 0.0431 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0545\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.0035 - mean_squared_error: 0.0035 - mean_absolute_error: 0.0431 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0533\n",
      "Epoch 00015: early stopping\n",
      "Training data error: 2369.30 MSE\n",
      "Test data error: 2744.64 MSE\n",
      "Training data error: 41.44 MAE\n",
      "Test data error: 44.29 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26597 samples, validate on 4694 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0134 - mean_squared_error: 0.0134 - mean_absolute_error: 0.0860 - val_loss: 0.0113 - val_mean_squared_error: 0.0113 - val_mean_absolute_error: 0.0806\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.0084 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0688 - val_loss: 0.0119 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0816\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0679 - val_loss: 0.0115 - val_mean_squared_error: 0.0115 - val_mean_absolute_error: 0.0805\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0675 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0791\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0671 - val_loss: 0.0119 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0812\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0668 - val_loss: 0.0116 - val_mean_squared_error: 0.0116 - val_mean_absolute_error: 0.0806\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0665 - val_loss: 0.0116 - val_mean_squared_error: 0.0116 - val_mean_absolute_error: 0.0800\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0663 - val_loss: 0.0113 - val_mean_squared_error: 0.0113 - val_mean_absolute_error: 0.0799\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0661 - val_loss: 0.0111 - val_mean_squared_error: 0.0111 - val_mean_absolute_error: 0.0789\n",
      "Epoch 00009: early stopping\n",
      "Training data error: 3474.56 MSE\n",
      "Test data error: 4015.56 MSE\n",
      "Training data error: 50.72 MAE\n",
      "Test data error: 54.04 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26342 samples, validate on 4649 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.0135 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0860 - val_loss: 0.0117 - val_mean_squared_error: 0.0117 - val_mean_absolute_error: 0.0819\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0681 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0808\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0080 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0669 - val_loss: 0.0120 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0813\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0664 - val_loss: 0.0112 - val_mean_squared_error: 0.0112 - val_mean_absolute_error: 0.0796\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0659 - val_loss: 0.0126 - val_mean_squared_error: 0.0126 - val_mean_absolute_error: 0.0827\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.0076 - mean_squared_error: 0.0076 - mean_absolute_error: 0.0654 - val_loss: 0.0118 - val_mean_squared_error: 0.0118 - val_mean_absolute_error: 0.0811\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0075 - mean_squared_error: 0.0075 - mean_absolute_error: 0.0650 - val_loss: 0.0125 - val_mean_squared_error: 0.0125 - val_mean_absolute_error: 0.0838\n",
      "Epoch 00007: early stopping\n",
      "Training data error: 3478.85 MSE\n",
      "Test data error: 4286.81 MSE\n",
      "Training data error: 51.10 MAE\n",
      "Test data error: 56.18 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 20)                9680      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 9,701\n",
      "Trainable params: 9,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vanilla_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
