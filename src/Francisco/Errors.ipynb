{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for Report and Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import math\n",
    "from keras.layers import LSTM, Bidirectional, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from keras import callbacks\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">2004</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">1</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">1</td>\n",
       "      <td>1</td>\n",
       "      <td>16853.0</td>\n",
       "      <td>126259.0</td>\n",
       "      <td>136233.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>6829.0</td>\n",
       "      <td>133088.0</td>\n",
       "      <td>136233.0</td>\n",
       "      <td>3124.0</td>\n",
       "      <td>75243.0</td>\n",
       "      <td>23339.0</td>\n",
       "      <td>90700.0</td>\n",
       "      <td>118378.0</td>\n",
       "      <td>20673.0</td>\n",
       "      <td>21791.0</td>\n",
       "      <td>65970.0</td>\n",
       "      <td>28752.0</td>\n",
       "      <td>30645.0</td>\n",
       "      <td>200946.0</td>\n",
       "      <td>82298.0</td>\n",
       "      <td>79830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16450.0</td>\n",
       "      <td>123313.0</td>\n",
       "      <td>133055.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>6596.0</td>\n",
       "      <td>129909.0</td>\n",
       "      <td>133055.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>67368.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>86699.0</td>\n",
       "      <td>112480.0</td>\n",
       "      <td>19666.0</td>\n",
       "      <td>21400.0</td>\n",
       "      <td>64600.0</td>\n",
       "      <td>27851.0</td>\n",
       "      <td>30461.0</td>\n",
       "      <td>195835.0</td>\n",
       "      <td>79827.0</td>\n",
       "      <td>77429.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1         2         3      4       5         6         7   \\\n",
       "2004 1 1 1  16853.0  126259.0  136233.0  484.0  6829.0  133088.0  136233.0   \n",
       "         2  16450.0  123313.0  133055.0  457.0  6596.0  129909.0  133055.0   \n",
       "\n",
       "                8        9        10       11        12       13       14  \\\n",
       "2004 1 1 1  3124.0  75243.0  23339.0  90700.0  118378.0  20673.0  21791.0   \n",
       "         2  2956.0  67368.0  22100.0  86699.0  112480.0  19666.0  21400.0   \n",
       "\n",
       "                 15       16       17        18       19       20  \n",
       "2004 1 1 1  65970.0  28752.0  30645.0  200946.0  82298.0  79830.0  \n",
       "         2  64600.0  27851.0  30461.0  195835.0  79827.0  77429.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = r\"../../Data/completeLoad.csv\"\n",
    "df = pd.read_csv(PATH)\n",
    "temp = df.set_index(['zone_id', 'year', 'month', 'day'])\n",
    "colname_to_int = {}\n",
    "for i in list(temp.columns):\n",
    "    colname_to_int[i] = int(i[1:])\n",
    "\n",
    "temp = temp.rename(columns=colname_to_int)\n",
    "temp = temp.stack()\n",
    "temp = temp.unstack(level=0)\n",
    "temp.columns.names = [None]\n",
    "temp.index.names = [None, None, None, None]\n",
    "df_zone = temp\n",
    "temp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naive_week_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24*7], Y[0:-24*7])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_day_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24], Y[0:-24])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_hour_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0, :].reshape(1, -1), Y[0:-1])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "mse_train_naive_hour, train_predict_naive_hour = get_naive_hour_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_hour, test_predict_naive_hour = get_naive_hour_predict_and_score_multi(test_X, test_Y)\n",
    "mse_train_naive_day, train_predict_naive_day = get_naive_day_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_day, test_predict_naive_day = get_naive_day_predict_and_score_multi(test_X, test_Y)\n",
    "mse_train_naive_week, train_predict_naive_week = get_naive_week_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_week, test_predict_naive_week = get_naive_week_predict_and_score_multi(test_X, test_Y)\n",
    "\n",
    "print(\"(Naive -1 hour) Training data error: %.2f MSE\" % mse_train_naive_hour)\n",
    "print(\"(Naive -1 hour) Test data error: %.2f MSE\" % mse_test_naive_hour)\n",
    "print(\"(Naive -1 day) Training data error: %.2f MSE\" % mse_train_naive_day)\n",
    "print(\"(Naive -1 day) Test data error: %.2f MSE\" % mse_test_naive_day)\n",
    "print(\"(Naive -1 week) Training data error: %.2f MSE\" % mse_train_naive_week)\n",
    "print(\"(Naive -1 week) Test data error: %.2f MSE\" % mse_test_naive_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naive_week_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24*7], Y[0:-24*7])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_day_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0:24], Y[0:-24])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "def get_naive_hour_predict_and_score_multi(X, Y):\n",
    "    # transform the prediction to the original scale.\n",
    "    pred = normalizer.inverse_transform(np.vstack((Y[0, :].reshape(1, -1), Y[0:-1])))\n",
    "    # transform also the label to the original scale for interpretability.\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE.\n",
    "    score = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, pred)\n",
    "\n",
    "mse_train_naive_hour, train_predict_naive_hour = get_naive_hour_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_hour, test_predict_naive_hour = get_naive_hour_predict_and_score_multi(test_X, test_Y)\n",
    "mse_train_naive_day, train_predict_naive_day = get_naive_day_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_day, test_predict_naive_day = get_naive_day_predict_and_score_multi(test_X, test_Y)\n",
    "mse_train_naive_week, train_predict_naive_week = get_naive_week_predict_and_score_multi(train_X, train_Y)\n",
    "mse_test_naive_week, test_predict_naive_week = get_naive_week_predict_and_score_multi(test_X, test_Y)\n",
    "\n",
    "print(\"(Naive -1 hour) Training data error: %.2f MSE\" % mse_train_naive_hour)\n",
    "print(\"(Naive -1 hour) Test data error: %.2f MSE\" % mse_test_naive_hour)\n",
    "print(\"(Naive -1 day) Training data error: %.2f MSE\" % mse_train_naive_day)\n",
    "print(\"(Naive -1 day) Test data error: %.2f MSE\" % mse_test_naive_day)\n",
    "print(\"(Naive -1 week) Training data error: %.2f MSE\" % mse_train_naive_week)\n",
    "print(\"(Naive -1 week) Test data error: %.2f MSE\" % mse_test_naive_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples training set: 31660\n",
      "Number of samples test set: 7916\n"
     ]
    }
   ],
   "source": [
    "# use data for zone 1.\n",
    "data = df_zone[1].values.reshape(-1, 1)\n",
    "\n",
    "# normalize data with min max normalization.\n",
    "normalizer = MinMaxScaler(feature_range = (0, 1))\n",
    "dataset = normalizer.fit_transform(data)\n",
    "\n",
    "# Using 80% of data for training, 20% for validation.\n",
    "TRAINING_PERCENT = 0.80\n",
    "\n",
    "train_size = int(len(dataset) * TRAINING_PERCENT)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(\"Number of samples training set: \" + str((len(train))))\n",
    "print(\"Number of samples test set: \" + str((len(test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_nstep(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        sample = dataset[i:(i + window_size), 0]\n",
    "        data_x.append(sample)\n",
    "        data_y.append(dataset[(i + window_size):(i + window_size + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26900 samples, validate on 4748 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.0040 - mean_squared_error: 0.0040 - mean_absolute_error: 0.0406 - val_loss: 4.5708e-04 - val_mean_squared_error: 4.5708e-04 - val_mean_absolute_error: 0.0158\n",
      "Epoch 2/100\n",
      " - 3s - loss: 3.2623e-04 - mean_squared_error: 3.2623e-04 - mean_absolute_error: 0.0136 - val_loss: 2.9174e-04 - val_mean_squared_error: 2.9174e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 3/100\n",
      " - 3s - loss: 2.1106e-04 - mean_squared_error: 2.1106e-04 - mean_absolute_error: 0.0108 - val_loss: 1.9707e-04 - val_mean_squared_error: 1.9707e-04 - val_mean_absolute_error: 0.0102\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.3697e-04 - mean_squared_error: 1.3697e-04 - mean_absolute_error: 0.0085 - val_loss: 1.4127e-04 - val_mean_squared_error: 1.4127e-04 - val_mean_absolute_error: 0.0085\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0222e-04 - mean_squared_error: 1.0222e-04 - mean_absolute_error: 0.0073 - val_loss: 1.2670e-04 - val_mean_squared_error: 1.2670e-04 - val_mean_absolute_error: 0.0080\n",
      "Epoch 6/100\n",
      " - 3s - loss: 8.6079e-05 - mean_squared_error: 8.6079e-05 - mean_absolute_error: 0.0066 - val_loss: 9.5692e-05 - val_mean_squared_error: 9.5692e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 7/100\n",
      " - 3s - loss: 7.9205e-05 - mean_squared_error: 7.9205e-05 - mean_absolute_error: 0.0064 - val_loss: 8.7688e-05 - val_mean_squared_error: 8.7688e-05 - val_mean_absolute_error: 0.0065\n",
      "Epoch 8/100\n",
      " - 3s - loss: 7.2403e-05 - mean_squared_error: 7.2403e-05 - mean_absolute_error: 0.0061 - val_loss: 8.1605e-05 - val_mean_squared_error: 8.1605e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 9/100\n",
      " - 3s - loss: 6.8445e-05 - mean_squared_error: 6.8445e-05 - mean_absolute_error: 0.0060 - val_loss: 8.5080e-05 - val_mean_squared_error: 8.5080e-05 - val_mean_absolute_error: 0.0065\n",
      "Epoch 10/100\n",
      " - 3s - loss: 6.7473e-05 - mean_squared_error: 6.7473e-05 - mean_absolute_error: 0.0060 - val_loss: 9.1831e-05 - val_mean_squared_error: 9.1831e-05 - val_mean_absolute_error: 0.0067\n",
      "Epoch 11/100\n",
      " - 3s - loss: 6.4958e-05 - mean_squared_error: 6.4958e-05 - mean_absolute_error: 0.0058 - val_loss: 9.0726e-05 - val_mean_squared_error: 9.0726e-05 - val_mean_absolute_error: 0.0069\n",
      "Epoch 12/100\n",
      " - 3s - loss: 6.3735e-05 - mean_squared_error: 6.3735e-05 - mean_absolute_error: 0.0058 - val_loss: 1.2113e-04 - val_mean_squared_error: 1.2113e-04 - val_mean_absolute_error: 0.0086\n",
      "Epoch 13/100\n",
      " - 3s - loss: 6.2794e-05 - mean_squared_error: 6.2794e-05 - mean_absolute_error: 0.0057 - val_loss: 7.1676e-05 - val_mean_squared_error: 7.1676e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 14/100\n",
      " - 3s - loss: 6.0770e-05 - mean_squared_error: 6.0770e-05 - mean_absolute_error: 0.0057 - val_loss: 8.1088e-05 - val_mean_squared_error: 8.1088e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 15/100\n",
      " - 5s - loss: 6.0231e-05 - mean_squared_error: 6.0231e-05 - mean_absolute_error: 0.0056 - val_loss: 6.9435e-05 - val_mean_squared_error: 6.9435e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 16/100\n",
      " - 3s - loss: 6.0694e-05 - mean_squared_error: 6.0694e-05 - mean_absolute_error: 0.0057 - val_loss: 8.3694e-05 - val_mean_squared_error: 8.3694e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 17/100\n",
      " - 3s - loss: 5.9696e-05 - mean_squared_error: 5.9696e-05 - mean_absolute_error: 0.0056 - val_loss: 6.8867e-05 - val_mean_squared_error: 6.8867e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 18/100\n",
      " - 4s - loss: 5.8936e-05 - mean_squared_error: 5.8936e-05 - mean_absolute_error: 0.0056 - val_loss: 6.7968e-05 - val_mean_squared_error: 6.7968e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 19/100\n",
      " - 3s - loss: 5.8900e-05 - mean_squared_error: 5.8900e-05 - mean_absolute_error: 0.0056 - val_loss: 8.7072e-05 - val_mean_squared_error: 8.7072e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 20/100\n",
      " - 3s - loss: 5.9167e-05 - mean_squared_error: 5.9167e-05 - mean_absolute_error: 0.0056 - val_loss: 6.8068e-05 - val_mean_squared_error: 6.8068e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 21/100\n",
      " - 3s - loss: 5.9023e-05 - mean_squared_error: 5.9023e-05 - mean_absolute_error: 0.0056 - val_loss: 6.8075e-05 - val_mean_squared_error: 6.8075e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 22/100\n",
      " - 3s - loss: 5.7785e-05 - mean_squared_error: 5.7785e-05 - mean_absolute_error: 0.0055 - val_loss: 6.7225e-05 - val_mean_squared_error: 6.7225e-05 - val_mean_absolute_error: 0.0058\n",
      "Epoch 23/100\n",
      " - 3s - loss: 5.7745e-05 - mean_squared_error: 5.7745e-05 - mean_absolute_error: 0.0055 - val_loss: 7.7901e-05 - val_mean_squared_error: 7.7901e-05 - val_mean_absolute_error: 0.0065\n",
      "Epoch 24/100\n",
      " - 3s - loss: 5.7394e-05 - mean_squared_error: 5.7394e-05 - mean_absolute_error: 0.0055 - val_loss: 8.6225e-05 - val_mean_squared_error: 8.6225e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 25/100\n",
      " - 3s - loss: 5.6888e-05 - mean_squared_error: 5.6888e-05 - mean_absolute_error: 0.0055 - val_loss: 7.9982e-05 - val_mean_squared_error: 7.9982e-05 - val_mean_absolute_error: 0.0067\n",
      "Epoch 26/100\n",
      " - 3s - loss: 5.6849e-05 - mean_squared_error: 5.6849e-05 - mean_absolute_error: 0.0055 - val_loss: 6.6547e-05 - val_mean_squared_error: 6.6547e-05 - val_mean_absolute_error: 0.0058\n",
      "Epoch 27/100\n",
      " - 3s - loss: 5.8109e-05 - mean_squared_error: 5.8109e-05 - mean_absolute_error: 0.0056 - val_loss: 8.1803e-05 - val_mean_squared_error: 8.1803e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 28/100\n",
      " - 3s - loss: 5.7910e-05 - mean_squared_error: 5.7910e-05 - mean_absolute_error: 0.0055 - val_loss: 7.4520e-05 - val_mean_squared_error: 7.4520e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 29/100\n",
      " - 3s - loss: 5.6135e-05 - mean_squared_error: 5.6135e-05 - mean_absolute_error: 0.0054 - val_loss: 7.9785e-05 - val_mean_squared_error: 7.9785e-05 - val_mean_absolute_error: 0.0067\n",
      "Epoch 30/100\n",
      " - 3s - loss: 5.5334e-05 - mean_squared_error: 5.5334e-05 - mean_absolute_error: 0.0054 - val_loss: 6.6908e-05 - val_mean_squared_error: 6.6908e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 31/100\n",
      " - 3s - loss: 5.5915e-05 - mean_squared_error: 5.5915e-05 - mean_absolute_error: 0.0054 - val_loss: 6.5014e-05 - val_mean_squared_error: 6.5014e-05 - val_mean_absolute_error: 0.0058\n",
      "Epoch 32/100\n",
      " - 3s - loss: 5.8098e-05 - mean_squared_error: 5.8098e-05 - mean_absolute_error: 0.0056 - val_loss: 7.0235e-05 - val_mean_squared_error: 7.0235e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 33/100\n",
      " - 3s - loss: 5.5462e-05 - mean_squared_error: 5.5462e-05 - mean_absolute_error: 0.0054 - val_loss: 6.8395e-05 - val_mean_squared_error: 6.8395e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 34/100\n",
      " - 3s - loss: 5.6598e-05 - mean_squared_error: 5.6598e-05 - mean_absolute_error: 0.0055 - val_loss: 6.6108e-05 - val_mean_squared_error: 6.6108e-05 - val_mean_absolute_error: 0.0058\n",
      "Epoch 35/100\n",
      " - 3s - loss: 5.6413e-05 - mean_squared_error: 5.6413e-05 - mean_absolute_error: 0.0055 - val_loss: 6.5798e-05 - val_mean_squared_error: 6.5798e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 36/100\n",
      " - 3s - loss: 5.6257e-05 - mean_squared_error: 5.6257e-05 - mean_absolute_error: 0.0055 - val_loss: 6.8004e-05 - val_mean_squared_error: 6.8004e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 00036: early stopping\n",
      "Training data error: 284.22 MSE\n",
      "Test data error: 309.81 MSE\n",
      "Training data error: 14.31 MAE\n",
      "Test data error: 14.98 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 10\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "#SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [['loss', 'val_loss'], ['mean_absolute_error', \n",
    "           'val_mean_absolute_error']]\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "for i, x in enumerate(metrics):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.plot(history.history[x[0]])\n",
    "    plt.plot(history.history[x[1]])\n",
    "    plt.legend(['Train', 'Val'], loc='best')\n",
    "    string_metric = (' ').join(x[0].split('_'))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.title('Model {}'.format(string_metric))\n",
    "    plt.ylabel(string_metric)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25917 samples, validate on 4574 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.0126 - mse: 0.0126 - mae: 0.0820 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0789\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0081 - mse: 0.0081 - mae: 0.0677 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0802\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0079 - mse: 0.0079 - mae: 0.0668 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0825\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0077 - mse: 0.0077 - mae: 0.0659 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0799\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0076 - mse: 0.0076 - mae: 0.0651 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0803\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0073 - mse: 0.0073 - mae: 0.0639 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0829\n",
      "Epoch 00006: early stopping\n",
      "Training data error: 3435.35 MSE\n",
      "Test data error: 4369.16 MSE\n",
      "Training data error: 50.11 MAE\n",
      "Test data error: 55.95 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 1000\n",
    "nstep = 168\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "#SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_rnn.save(\"./../../Data/Models/lstm_1000_168.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 1000\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "#SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_rnn.save(\"./../../Data/Models/lstm_100_24.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_nstep_bidir(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        ws_2 = int(window_size/2)\n",
    "        s1 = dataset[i:(i + ws_2), 0]\n",
    "        s2 = dataset[(i + ws_2 + nstep):(i + window_size + nstep), 0]\n",
    "        data_x.append(np.concatenate((s1, s2)))\n",
    "        data_y.append(dataset[(i + ws_2):(i + ws_2 + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_model_nstep_bidir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b10051d83e14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mvanilla_rnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model_nstep_bidir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvanilla_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_model_nstep_bidir' is not defined"
     ]
    }
   ],
   "source": [
    "def create_dataset_nstep_bidir(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        ws_2 = int(window_size/2)\n",
    "        s1 = dataset[i:(i + ws_2), 0]\n",
    "        s2 = dataset[(i + ws_2 + nstep):(i + window_size + nstep), 0]\n",
    "        data_x.append(np.concatenate((s1, s2)))\n",
    "        data_y.append(dataset[(i + ws_2):(i + ws_2 + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26196 samples, validate on 4623 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.0108 - mse: 0.0108 - mae: 0.0767 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0797\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.0082 - mse: 0.0082 - mae: 0.0677 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0790\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.0081 - mse: 0.0081 - mae: 0.0672 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0789\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.0079 - mse: 0.0079 - mae: 0.0665 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0796\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.0078 - mse: 0.0078 - mae: 0.0661 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0787\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.0077 - mse: 0.0077 - mae: 0.0654 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0790\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0074 - mse: 0.0074 - mae: 0.0644 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0801\n",
      "Epoch 00007: early stopping\n",
      "Training data error: 3388.78 MSE\n",
      "Test data error: 4105.26 MSE\n",
      "Training data error: 50.83 MAE\n",
      "Test data error: 55.60 MAE\n"
     ]
    }
   ],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 672\n",
    "nstep = 168\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "#SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_rnn.save(\"./../../Data/Models/lstm_672_168.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep_bidir(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(Bidirectional(LSTM(20, input_shape = (1, window_size))))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM Variant Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biriectional LSTM (Long Time Period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 4000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 4000\n",
    "nstep = 24*7*4\n",
    "train_X, train_Y = create_dataset_nstep_bidir(train, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_bidir(test, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep_bidir(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(GRU(20, input_shape = (1, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariable LSTM and Temperature Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = r\"../../Data/temperature_history.csv\"\n",
    "df_T = pd.read_csv(PATH)\n",
    "h_df_T = df_T.set_index(['station_id', 'year', 'month', 'day'])\n",
    "trans_dict = {}\n",
    "for i in list(h_df_T.columns):\n",
    "    trans_dict[i] = int(i[1:])\n",
    "h_df_T = h_df_T.rename(columns=trans_dict)\n",
    "h_df_T = h_df_T.stack()\n",
    "h_df_T = h_df_T.unstack(level=0)\n",
    "h_df_T.columns = h_df_T.columns.get_level_values(0)\n",
    "h_df_T.columns.names = [None]\n",
    "h_df_T.index.names = [None, None, None, None]\n",
    "\n",
    "PATH = r\"../../Data/temperature_solution.csv\"\n",
    "df_T_Sol = pd.read_csv(PATH)\n",
    "h_df_T_Sol = df_T_Sol.set_index(['station_id', 'year', 'month', 'day', 'hour'])\n",
    "h_df_T_Sol = h_df_T_Sol.drop(['datetime', 'date'], axis=1)\n",
    "h_df_T_Sol = h_df_T_Sol.unstack(level=0)\n",
    "h_df_T_Sol.columns = h_df_T_Sol.columns.get_level_values(1)\n",
    "h_df_T_Sol.columns.names = [None]\n",
    "h_df_T_Sol.index.names = [None, None, None, None]\n",
    "\n",
    "zone_T = pd.concat([h_df_T, h_df_T_Sol], axis=0, join='outer', ignore_index=False, keys=None, \n",
    "          levels=None, names=None, verify_integrity=True, copy=True)\n",
    "\n",
    "T_mean = zone_T.mean(axis=1)\n",
    "#temp['T'] = T_mean\n",
    "temp['T'] = pd.Series(np.concatenate([T_mean[:12].values, T_mean[0:-12].values]) , index = (T_mean.index))\n",
    "\n",
    "zone_T.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[[1, 'T']].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(temp[[1, 'T']])\n",
    "\n",
    "# Using 80% of data for training, 20% for validation.\n",
    "TRAINING_PERCENT = 0.80\n",
    "\n",
    "train_size = int(len(scaled) * TRAINING_PERCENT)\n",
    "test_size = len(scaled) - train_size\n",
    "train_multi, test_multi = scaled[0:train_size, :], scaled[train_size:len(scaled), :]\n",
    "print(\"Number of samples training set: \" + str((len(train_multi))))\n",
    "print(\"Number of samples test set: \" + str((len(test_multi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_nstep_multi(dataset, window_size = 1, nstep = 1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - window_size - nstep - 1):\n",
    "        sample = dataset[i:(i + window_size), :]\n",
    "        data_x.append(sample)\n",
    "        data_y.append(dataset[(i + window_size):(i + window_size + nstep), 0])\n",
    "    return(np.array(data_x), np.array(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 100\n",
    "nstep = 1\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 50\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 200\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_nstep(train_X, train_Y, window_size = 1, nstep = 1):\n",
    "    vanilla_rnn = Sequential()\n",
    "    vanilla_rnn.add(LSTM(20, input_shape = (2, window_size)))\n",
    "    vanilla_rnn.add(Dense(nstep))\n",
    "    vanilla_rnn.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "    return(vanilla_rnn)\n",
    "\n",
    "window_size = 500\n",
    "nstep = 24*7\n",
    "train_X, train_Y = create_dataset_nstep_multi(train_multi, window_size, nstep)\n",
    "test_X, test_Y = create_dataset_nstep_multi(test_multi, window_size, nstep)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[2], train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[2], test_X.shape[1]))\n",
    "\n",
    "vanilla_rnn = create_model_nstep(train_X, train_Y, window_size, nstep)\n",
    "SVG(model_to_dot(vanilla_rnn, show_shapes=True).create(prog='dot', format='svg'))\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = vanilla_rnn.fit(train_X, train_Y, epochs = 100, batch_size = 32, verbose = 2, validation_split=0.15, \n",
    "                          callbacks=[es])\n",
    "\n",
    "def get_predict_and_score_multi(model, X, Y):\n",
    "    # transform the prediction to the original scale\n",
    "    pred = normalizer.inverse_transform(model.predict(X))\n",
    "    # transform also the label to the original scale for interpretability\n",
    "    orig_data =normalizer.inverse_transform(Y)\n",
    "    # calculate RMSE\n",
    "    score = math.sqrt(mean_squared_error(orig_data, pred))\n",
    "    score2 = math.sqrt(mean_absolute_error(orig_data, pred))\n",
    "    return(score, score2, pred)\n",
    "\n",
    "mse_train, mae_train, train_predict = get_predict_and_score_multi(vanilla_rnn, train_X, train_Y)\n",
    "mse_test, mae_test, test_predict = get_predict_and_score_multi(vanilla_rnn, test_X, test_Y)\n",
    "print(\"Training data error: %.2f MSE\" % mse_train)\n",
    "print(\"Test data error: %.2f MSE\" % mse_test)\n",
    "print(\"Training data error: %.2f MAE\" % mae_train)\n",
    "print(\"Test data error: %.2f MAE\" % mae_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
