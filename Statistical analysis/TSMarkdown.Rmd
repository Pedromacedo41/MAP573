---
title: "Time series temperature/load"
author: "Ari Jóhannesson"
date: "10/31/2019"
output: 
  html_document:
    theme: cosmo
    highlight: tango
    toc: True
    toc_float: True
    code_folding: hide
---


```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = getwd())
knitr::opts_chunk$set(echo = T)
```

## Relationship between temperature and load

Read in the TS objects.We set the index as the dates and remove the time/date column and the X column. The temperature file has 11 zones and I assume that those 11 zones are the same as the first zones in the load TS.

```{r laodData}
library(grid)
library(gridExtra)
library(rmarkdown)

TS <- read.csv("../Data/Complete_TS.csv")
TST <- read.csv("../Data/TST.csv")

row.names(TST) <- TST$datetime
TST = subset(TST, select = -c(X, datetime))

row.names(TS) <- TS$datetime
TS = subset(TS, select = -c(X, datetime))

```

Because we have so many zones, we might want to simplify our data and only use the mean over the zones. If we do not do that, the temperature vs weight plot will have different clusters and the TS plot will also have more lines. A simple mean should be ok due to them having the same units.

```{r meanData}
TSmeans <- rowMeans(TS[1:29414, ])
TSTmeans <- rowMeans(TST[1:29414, ])
mean_temp <- mean(TSTmeans)
data <- as.data.frame(cbind(TSTmeans, TSmeans))
```

The figure shows some relations shipt between temperature and load but as temperature increases/decreases from the mean (around 56 °F), the energy load increases.

```{r plotLoadvsTemp}

plot(TSTmeans, TSmeans, 
     main = "Relationship between energy load and temperature", 
     xlab = "Temperature [F]", 
     ylab = "Load [xW]", 
     cex = 0.1,
     panel.first = grid(nx = NULL, ny = NULL, col = "red", lty = "dotted"))

```

On TS form...

```{r cscc}
#for mean every 24 hours-----------------------
days <- 365

D <- matrix(data=0,nrow=20,ncol=days)
colnames(D) <- c(as.character(1:days))

i <- 1
idx <- 1
while (idx<=days){
  
  daymean <- colMeans(TS[i:i+23,])
  D[1:20,idx] <- daymean
  
  i <- i+24
  idx <- idx+1
}

D <- t(D)
image(1:days, 1:20, D, xlab = "The first year [days]", ylab = "Zones", main = "'Heatmap' of zones for the first year")

#for all values---------------------
tsyearlength <- 365*23
TS_year <- as.matrix(TS[1:tsyearlength,1:20])
image(1:tsyearlength, 1:20, TS_year, xlab = "The first year [days]", ylab = "Zones", main = "'Heatmap' of zones for the first year")

```


```{r ssss}
#for mean every 24 hours - Standardized-----------------------
d_st <- matrix(data=0,nrow=20,ncol=1)
dim(D)
for (i in 1:dim(D)[2]){
  temp <- sd(D[,i])
  d_st[i] <- temp
}

for (i in 1:dim(D)[2]){ #skipta um zone
  for (j in 1:dim(D)[1]){ #dagar í einu zoni
    D[j,i] <- D[j,i]/d_st[i]
  }
}

image(1:days, 1:20, D, xlab = "The first year [days]", ylab = "Zones", main = "Standardized 'Heatmap' of zones for the first year")

ts_st <- matrix(data=0,nrow=20,ncol=1)
for (i in 1:dim(TS_year)[2]){
  temp <- sd(TS_year[,i])
  ts_st[i] <- temp
}

for (i in 1:dim(TS_year)[2]){ #skipta um zone
  for (j in 1:dim(TS_year)[1]){ #dagar í einu zoni
    TS_year[j,i] <- TS_year[j,i]/ts_st[i]
  }
}

image(1:tsyearlength, 1:20, TS_year, 
            xlab = "The first year [days]", 
            ylab = "Zones", main = "Standardized 'Heatmap' of zones for the first year")


```



```{r ssfsfs}
#Þetta er yfir allar klukkustundir en hitt var meðalhiti yfir dag
temp <- 23*365
TSmeans_year <- TSmeans[1:temp]
temp <- as.matrix(TSmeans_year)
image(x=1:length(TSmeans_year), y=1, z=temp, 
      ylab = NULL,
      xlab = "hours")

```

```{r ksfk}

```

```{r ts}
library(zoo)
library(xts)
library(ggplot2)


times <- as.POSIXct(row.names(data), format = "%Y-%m-%d %H:%M:")
timesNAomit <- na.omit(times) 
load.means.zoo <- zoo(
  x         = data$TSmeans,
  order.by  = timesNAomit,
  frequency = 24
)

temperature.means.zoo <- zoo(
  x         = data$TSTmeans,
  order.by  = timesNAomit,
  frequency = 24
)

load.zoo <- zoo(
  x         = TS,
  order.by  = timesNAomit,
  frequency = 24
)


mean.data <- cbind(load.means.zoo, temperature.means.zoo)

load.means.ts <- ts(TSmeans, start = as.numeric(times[1]), frequency = 24)


```


```{r histogramskkkkk}

## DAMSNssdfsfg


load.means.diff <- diff(load.means.ts)



d <- coredata(load.means.diff)
d <- as.data.frame(cbind(1:length(d), d))
p1 <- ggplot(d,aes(V1, d))+geom_line()+
      labs(title = "Difference in load between time steps", xlav="Time", ylab="Difference")



d <- as.matrix(load.means.diff)
bw <- 2 * IQR(d) / length(d)^(1/3) #Freedman-Diaconis rule
d <- as.data.frame(d)
p2 <- ggplot(d, aes(x = V1)) +
      labs(title= "Difference between each time step ",
           y="Count", 
           x = "Difference")+
      geom_histogram(binwidth = bw) 




d <- coredata(load.means.ts)
bw <- 2 * IQR(d) / length(d)^(1/3) #Freedman-Diaconis rule 
p3 <- ggplot(, mapping = aes(x = d)) +
      labs(title= "Histogram of load",
           y="Count", 
           x = "Load")+
      geom_histogram(binwidth = bw)

      
grid.arrange(p1, p2, p3, nrow = 3)
```



## Time series analyis

We use the zoo library because the ts library does not support hourly collected data. First, the dates/hours are formatted and then a TS object is made out of them. This is done for both load and temperature.
Then the data is plotted. The y axis og the ggplot has to be changed so that the left axis shows W and the right shows temeprature f.x.

```{r plotTimeSeries}

p1 <- ggplot(mean.data, aes(timesNAomit)) + 
      geom_line(aes(y = load.means.zoo)) + 
      labs(title= "Correlation of load and temperature (no units)",
      y="Load", x = "Year")

p2 <- ggplot(mean.data, aes(timesNAomit))+
      geom_line(aes(y = temperature.means.zoo))+
      labs(y="Temperature", x = "Year")
      
grid.arrange(p1, p2, nrow = 2)
```

# Forecast Library
## Autocorrelation

Here, we investigate how values in the time series are correlated to one another.
We do this for different amouts of lags to wether the data is seasonal.
In following figure we can see that at lag 1, the autocorrelation is highest (not far from 1).
When lags are increased the correlation between the variables decreases untill around 22-24, where the datas correlation increases a little.
In the ACF plot this can be more clearly seen.


```{r chunk 5, cache = TRUE}
library(forecast)
gglagplot(load.means.ts, do.lines = FALSE, set.lags = 1:30, cex=0.1, colour = FALSE)
```




If we go to even more lags the datas 24 hour periods can be seen better.

```{r chunk 4.3}
library(forecast)
p1 <- ggAcf(load.means.ts)
p2 <- ggAcf(load.means.ts, lag.max = 24*35)
grid.arrange(p1, p2, nrow = 2)
```



## Partial autocorrelation


There seems to be a seasonal period of 24 hours. Also, when lags are increased there seem to be another seasonal period of 7 days.
Now to partial autocorrelation.

```{r chunk 6}
p1 <- ggAcf(load.means.ts, type = "partial")
p2 <- ggAcf(load.means.ts, type = "partial", lag.max = 24*7)

p3 <- ggAcf(load.means.ts, type = "partial", lag.max = 24*7*4)

grid.arrange(p1, p2, p3,  ncol = 2, layout_matrix = rbind(c(1,2), c(3,3)))

```





There is a significant partial autocorrelation on lag 1, 2, 3, 13:17, 24,25, and 26. When the lag is higher, there seems to be partial autocorrelation every 24 hours and every 7 days, confirming a seasonal period of 24 hours as well as a weekly seasonal period.



```{r chunk 7}

p1 <- autoplot(load.means.zoo[1:24], main="24 hours from baseline")
p2 <- autoplot(load.means.zoo[1:24*7], main="week from baseline")
p3 <- autoplot(load.means.zoo[1:24*7*4], main="month from baseline")


grid.arrange(p1, p2, p3,  ncol = 2, layout_matrix = rbind(c(1,2), c(3,3)))
```

First plot:

Second plot: the roughness of the plot is due to the seasonal period of 24 hours. But on this plot we can see that the load is more at the end of the week.

Third plot: 



# Today
```{r chunk 8}

N_obs <- 31*24*5
D <- matrix(data=NA,nrow=N_obs,ncol=12)
colnames(D) <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")



years = c("2004-", "2005-", "2006-", "2007-", "2008-", "2009-") #2009 ekki í datasetti
months = c("01-", "02-", "03-", "04-", "05-", "06-", "07-", "08-", "09-", "10-", "11-", "12-", "01-")



MaxIndex <- 1

for (y in 1:5){ 
  year <- years[y]
  for (m in 1:12){
    MaxIndex_month <- 1
    month <- months[m]
    nextmonth <- months[m+1]
    
    if (m == 12)
    {
      nextyear <- years[y+1]
      temp_start <-  paste(c(year, month, "01"), collapse = "")
      temp_end  <-  paste(c(nextyear, nextmonth, "01"), collapse = "")
    }
    else{
      temp_start <-  paste(c(year, month, "01"), collapse = "")
      temp_end  <-  paste(c(year, nextmonth, "01"), collapse = "")
    }
    
    sDay <- temp_start
    eDay <-temp_end
    
    monthData <- coredata(window(load.means.zoo, start = as.POSIXct(sDay), end = as.POSIXct(eDay)))
    lengthMonth <- length(monthData)

    D[MaxIndex:(MaxIndex+lengthMonth-1),m] <-monthData[1:lengthMonth]
    
    if (lengthMonth > MaxIndex_month) {MaxIndex_month <- lengthMonth}
  }
  MaxIndex <- MaxIndex_month + MaxIndex
}


#Now boxplot with D
boxplot(D,
        main = "Average energy load over the zones vs months",
        na.action = NULL,
        xlab = "Months",
        ylab = "Energy load",
        col = "orange",
        border = "black")
      
```



```{r chunk 9}









#library(Rfast)
#mins <- colMins(D)
#maxs <- colMaxs(D)
#minmaxData <- cbind(mins,maxs)
#row.names(minmaxData) <- colnames(D)
#barplot(t(minmaxData), col=c("Blue","Red"), legend = c("Min load", "Max load"),
#        main = "Min-max load per month",
#        ylab = "Energy load")
```


